{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"FastADK: The Developer-Friendly Framework for AI Agents","text":"<p>FastADK is an open-source framework that dramatically improves the developer experience when building AI agents with Google's Agent Development Kit (ADK).</p>"},{"location":"#the-fastadk-advantage","title":"The FastADK Advantage","text":"<p>FastADK follows the proven pattern of FastAPI and other modern frameworks: providing high-level abstractions, declarative APIs, and developer-friendly tooling while leveraging the full power of the underlying platform.</p> <pre><code>from fastadk.core import Agent, BaseAgent, tool\n\n@Agent(\n    model=\"gemini-2.0-pro\", \n    description=\"Weather assistant that provides forecasts and recommendations\"\n)\nclass WeatherAgent(BaseAgent):\n    @tool\n    def get_weather(self, city: str) -&gt; dict:\n        \"\"\"Fetch current weather for a city.\"\"\"\n        # Your implementation here\n        return {\"city\": city, \"temp\": \"22\u00b0C\", \"condition\": \"sunny\"}\n\n    @tool(cache_ttl=300)  # Cache results for 5 minutes\n    def get_forecast(self, city: str, days: int = 5) -&gt; list:\n        \"\"\"Get weather forecast for multiple days.\"\"\"\n        # Your implementation here\n        return [\n            {\"day\": 1, \"condition\": \"sunny\", \"temp\": \"25\u00b0C\"},\n            {\"day\": 2, \"condition\": \"cloudy\", \"temp\": \"22\u00b0C\"},\n            # More forecast data...\n        ]\n</code></pre>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Declarative Syntax: Define agents with <code>@Agent</code> and tools with <code>@tool</code> decorators</li> <li>Automatic HTTP API: Serve your agents via FastAPI with zero additional code</li> <li>Memory Management: Built-in conversation memory with multiple backends</li> <li>Error Handling: Comprehensive exception framework with meaningful error messages</li> <li>Workflows: Compose multiple agents to solve complex problems</li> <li>Developer Tools: CLI for testing, debugging, and deployment</li> </ul>"},{"location":"#designed-for-developers","title":"Designed for Developers","text":"<p>FastADK is built by developers, for developers. We've focused on creating an intuitive, well-documented framework that makes agent development a joy.</p> <ul> <li>Minimal Boilerplate: Accomplish in 10 lines what would take 100+ lines in raw ADK</li> <li>IDE-Friendly: Complete type hints for excellent editor support</li> <li>Extensive Documentation: Tutorials, examples, and API references</li> <li>Production Ready: Built for performance, reliability, and scalability</li> </ul>"},{"location":"#installation","title":"Installation","text":"<pre><code># Install UV (recommended package manager for Python)\npip install uv\n\n# Install FastADK with UV\nuv pip install fastadk\n</code></pre> <p>FastADK is now available on PyPI, making installation simple and straightforward! We recommend using UV for significantly faster and more reliable package management.</p> <p>See full installation instructions \u2192</p>"},{"location":"#quick-example","title":"Quick Example","text":"<pre><code># app.py\nfrom fastadk.core import Agent, BaseAgent, tool\n\n@Agent(model=\"gemini-2.0-pro\")\nclass MathAgent(BaseAgent):\n    @tool\n    def add(self, a: float, b: float) -&gt; float:\n        \"\"\"Add two numbers together.\"\"\"\n        return a + b\n\n    @tool\n    def multiply(self, a: float, b: float) -&gt; float:\n        \"\"\"Multiply two numbers together.\"\"\"\n        return a * b\n\n# Run with: uv run app.py\n# Or serve HTTP API: uv run -m uvicorn app:app --reload\n</code></pre>"},{"location":"#next-steps","title":"Next Steps","text":"<ul> <li>Installation: Detailed installation instructions</li> <li>Quick Start: Create your first agent in minutes</li> <li>System Overview: Comprehensive explanation of FastADK's architecture and benefits</li> <li>Concepts: Learn about key FastADK concepts</li> <li>Examples: Real-world examples to learn from</li> </ul>"},{"location":"#join-the-community","title":"Join the Community","text":"<p>FastADK is an open-source project, and we welcome contributions of all kinds.</p> <ul> <li>GitHub: Star us, fork us, contribute!</li> <li>Discord: Join our community for discussions</li> <li>Twitter: Follow for updates</li> </ul>"},{"location":"#feedback-and-support","title":"Feedback and Support","text":"<p>We're always looking to improve FastADK based on your feedback! Here are some ways to get help or share your thoughts:</p> <ul> <li>GitHub Discussions: Ask questions, share ideas, or showcase what you've built</li> <li>GitHub Issues: Report bugs or request features</li> <li>Community Support: Get help from the community in our Discord server</li> <li>Email: Contact the core team directly</li> </ul> <p>Your feedback helps us prioritize features and improvements for future releases!</p>"},{"location":"PROJECT_CHARTER/","title":"FastADK Project Charter","text":""},{"location":"PROJECT_CHARTER/#project-vision","title":"Project Vision","text":"<p>FastADK is an open-source framework that dramatically improves developer experience when building AI agents with Google ADK. Following the proven pattern of FastAPI and FastMCP, FastADK provides high-level abstractions, declarative APIs, and developer-friendly tooling while leveraging the full power of the underlying platform.</p>"},{"location":"PROJECT_CHARTER/#mission-statement","title":"Mission Statement","text":"<p>\"Make AI agent development as simple and productive as web API development\"</p> <p>Transform agent development from manual ADK wiring to declarative Python classes with <code>@Agent</code> and <code>@tool</code> decorators, automatic HTTP serving, pluggable memory backends, and production-ready tooling.</p>"},{"location":"PROJECT_CHARTER/#core-objectives-key-results-okrs","title":"Core Objectives &amp; Key Results (OKRs)","text":""},{"location":"PROJECT_CHARTER/#objective-1-eliminate-developer-friction","title":"Objective 1: Eliminate Developer Friction","text":"<ul> <li>KR1: Reduce agent setup from 50+ lines of code to &lt;10 lines of code</li> <li>KR2: Achieve &lt;3 minutes from install to running agent</li> <li>KR3: 85% less boilerplate code compared to raw Google ADK</li> </ul>"},{"location":"PROJECT_CHARTER/#objective-2-build-thriving-developer-community","title":"Objective 2: Build Thriving Developer Community","text":"<ul> <li>KR1: &gt;100 active contributors within 6 months</li> <li>KR2: &gt;1000 GitHub stars within 3 months of v1.0 launch</li> <li>KR3: &gt;70% developer retention rate after 30 days</li> </ul>"},{"location":"PROJECT_CHARTER/#objective-3-establish-production-ready-platform","title":"Objective 3: Establish Production-Ready Platform","text":"<ul> <li>KR1: &gt;50 documented production deployments</li> <li>KR2: 99.9% uptime for managed cloud services</li> <li>KR3: Zero critical security vulnerabilities</li> </ul>"},{"location":"PROJECT_CHARTER/#objective-4-create-sustainable-ecosystem","title":"Objective 4: Create Sustainable Ecosystem","text":"<ul> <li>KR1: &gt;50 verified plugins within 12 months</li> <li>KR2: &gt;10 enterprise customers</li> <li>KR3: Sustainable revenue from cloud platform and services</li> </ul>"},{"location":"PROJECT_CHARTER/#success-metrics","title":"Success Metrics","text":""},{"location":"PROJECT_CHARTER/#technical-performance","title":"Technical Performance","text":"<ul> <li>API Response Time: 95<sup>th</sup> percentile &lt;500ms</li> <li>Memory Efficiency: &lt;80MB baseline memory usage</li> <li>Performance Improvement: 40% faster than raw ADK implementations</li> <li>Test Coverage: &gt;90% with comprehensive integration tests</li> </ul>"},{"location":"PROJECT_CHARTER/#adoption-metrics","title":"Adoption Metrics","text":"<ul> <li>PyPI Downloads: &gt;25K monthly downloads by month 6</li> <li>Enterprise Adoption: &gt;10 companies with enterprise licenses</li> <li>Academic Adoption: Used in &gt;5 university courses</li> <li>Community Health: &gt;90% satisfaction score in developer surveys</li> </ul>"},{"location":"PROJECT_CHARTER/#strategic-positioning","title":"Strategic Positioning","text":"<p>\"FastAPI for AI Agents\" - The obvious choice for developers building intelligent applications.</p>"},{"location":"PROJECT_CHARTER/#competitive-advantages","title":"Competitive Advantages","text":"<ol> <li>First-Mover Advantage: First high-level framework for Google ADK</li> <li>Enterprise Ready: Built-in security, compliance, and scalability</li> <li>Ecosystem Play: Plugin marketplace and community-driven development</li> <li>Multi-Backend Support: Reduces vendor lock-in with provider abstraction</li> <li>Developer Experience: Interactive playground, tutorials, and comprehensive tooling</li> </ol>"},{"location":"PROJECT_CHARTER/#project-governance","title":"Project Governance","text":""},{"location":"PROJECT_CHARTER/#decision-making","title":"Decision Making","text":"<ul> <li>RFC Process: Major features and architectural decisions</li> <li>Community Council: Elected representatives for strategic decisions</li> <li>Maintainer Team: Core team with merge and release authority</li> </ul>"},{"location":"PROJECT_CHARTER/#open-source-model","title":"Open Source Model","text":"<ul> <li>License: MIT License for maximum adoption</li> <li>Commercial Services: Optional managed platform and enterprise features</li> <li>Community First: All core features remain open source</li> </ul>"},{"location":"PROJECT_CHARTER/#risk-management","title":"Risk Management","text":""},{"location":"PROJECT_CHARTER/#technical-risks","title":"Technical Risks","text":"<ul> <li>ADK API Changes: Mitigated by provider abstraction layer</li> <li>Performance Issues: Continuous benchmarking and optimization</li> <li>Security Vulnerabilities: Multi-layered security and automated scanning</li> </ul>"},{"location":"PROJECT_CHARTER/#business-risks","title":"Business Risks","text":"<ul> <li>Low Adoption: Superior DX and strong community engagement</li> <li>Competition: Unique features and rapid innovation cycle</li> <li>Sustainability: Multiple revenue streams and enterprise services</li> </ul>"},{"location":"PROJECT_CHARTER/#timeline-milestones","title":"Timeline &amp; Milestones","text":""},{"location":"PROJECT_CHARTER/#phase-0-week-1-project-foundation","title":"Phase 0 (Week 1): Project Foundation \u2705","text":"<ul> <li>Project charter and governance setup</li> <li>Development environment and CI/CD</li> <li>Repository structure and documentation</li> </ul>"},{"location":"PROJECT_CHARTER/#phase-05-week-2-market-validation","title":"Phase 0.5 (Week 2): Market Validation","text":"<ul> <li>User research and competitive analysis</li> <li>Technical feasibility proof-of-concept</li> <li>Risk assessment and mitigation planning</li> </ul>"},{"location":"PROJECT_CHARTER/#phase-1-weeks-3-5-mvp-vertical-slice","title":"Phase 1 (Weeks 3-5): MVP Vertical Slice","text":"<ul> <li>Core agent and tool abstractions</li> <li>Basic CLI and configuration system</li> <li>Performance baseline establishment</li> </ul>"},{"location":"PROJECT_CHARTER/#phase-2-weeks-6-9-core-framework-features","title":"Phase 2 (Weeks 6-9): Core Framework Features","text":"<ul> <li>HTTP API integration with FastAPI</li> <li>Plugin ecosystem and semantic memory</li> <li>Enterprise security framework</li> </ul>"},{"location":"PROJECT_CHARTER/#phase-3-weeks-10-13-advanced-orchestration","title":"Phase 3 (Weeks 10-13): Advanced Orchestration","text":"<ul> <li>Declarative workflows and multi-agent coordination</li> <li>Streaming capabilities and error resilience</li> <li>Production reliability features</li> </ul>"},{"location":"PROJECT_CHARTER/#phase-4-weeks-14-17-community-launch","title":"Phase 4 (Weeks 14-17): Community Launch","text":"<ul> <li>Comprehensive documentation and tutorials</li> <li>Interactive web playground</li> <li>Open source community launch</li> </ul>"},{"location":"PROJECT_CHARTER/#phase-5-week-18-enterprise-ecosystem","title":"Phase 5 (Week 18+): Enterprise Ecosystem","text":"<ul> <li>Managed cloud platform</li> <li>Plugin marketplace</li> <li>Professional services</li> </ul>"},{"location":"PROJECT_CHARTER/#stakeholder-commitment","title":"Stakeholder Commitment","text":"<p>This charter represents the commitment of the FastADK team to deliver a revolutionary framework for AI agent development. By focusing on developer experience, community building, and technical excellence, FastADK will establish the standard for declarative AI agent development.</p> <p>Approved by: [Team signatures and dates to be added]</p> <p>Last Updated: January 2025 Next Review: Quarterly Document Version: 1.0</p>"},{"location":"changelog/","title":"Changelog","text":"<p>For a complete list of changes, please refer to the CHANGELOG.md file in the repository root.</p>"},{"location":"changelog/#020-2025-07-09","title":"[0.2.0] - 2025-07-09","text":""},{"location":"changelog/#added","title":"Added","text":""},{"location":"changelog/#token-and-cost-tracking","title":"Token and Cost Tracking","text":"<ul> <li>Added <code>TokenUsage</code> data class to record prompt, completion, and total tokens</li> <li>Extended each provider client to capture usage from responses</li> <li>Created <code>CostCalculator</code> utility for estimating costs based on token usage</li> <li>Added <code>TokenBudget</code> component with configurable budgets and alerts</li> <li>Added structured logging for token usage and costs</li> <li>Added Prometheus metrics for token usage and cost estimation</li> </ul>"},{"location":"changelog/#context-management-and-memory-improvements","title":"Context Management and Memory Improvements","text":"<ul> <li>Added <code>ContextPolicy</code> abstract class with built-in policies (MostRecent, SummarizeOlder, HybridVectorRetrieval)</li> <li>Implemented <code>SummarizationService</code> for LLM-based conversation summarization</li> <li>Added vector store backend integration with <code>VectorMemoryBackend</code></li> <li>Implemented persistent memory backends for Redis and SQL</li> <li>Added configuration options for memory policies</li> </ul>"},{"location":"changelog/#scalability-and-performance-optimizations","title":"Scalability and Performance Optimizations","text":"<ul> <li>Improved async execution for all model and tool calls</li> <li>Enhanced <code>Workflow</code> class to support concurrent sub-tasks</li> <li>Implemented <code>CacheManager</code> with in-memory LRU and Redis options</li> <li>Added lazy tool execution logic to improve efficiency</li> <li>Created <code>BatchUtils</code> for common bulk operations</li> </ul>"},{"location":"changelog/#extensibility-and-integration","title":"Extensibility and Integration","text":"<ul> <li>Defined <code>ModelProviderABC</code> interface for custom providers</li> <li>Implemented <code>PluginManager</code> for discovering and loading custom modules</li> <li>Added Slack and Discord adapters for integration</li> <li>Added multi-agent orchestration API</li> <li>Included fine-tuning helper module</li> </ul>"},{"location":"changelog/#developer-experience-and-tooling","title":"Developer Experience and Tooling","text":"<ul> <li>Extended CLI with <code>repl</code>, <code>init</code>, and <code>config validate</code> commands</li> <li>Added verbose debugging with chain-of-thought capture</li> <li>Created <code>MockLLM</code> and <code>MockTool</code> classes for testing</li> <li>Added test scenario decorators for structured testing</li> <li>Added VSCode snippets and configuration support</li> <li>Implemented config reload endpoint</li> </ul>"},{"location":"changelog/#observability-and-monitoring","title":"Observability and Monitoring","text":"<ul> <li>Added structured JSON logging for all agent events</li> <li>Integrated OpenTelemetry for traces and spans</li> <li>Added Prometheus metrics endpoint</li> <li>Implemented redaction filter for sensitive data</li> </ul>"},{"location":"changelog/#uiux-and-documentation","title":"UI/UX and Documentation","text":"<ul> <li>Added cookbook, plugin guide, and performance tuning documentation</li> <li>Expanded examples folder with new agent templates</li> <li>Implemented project scaffolding with <code>fastadk init</code></li> <li>Added Streamlit chat UI example</li> <li>Added community feedback links</li> </ul>"},{"location":"changelog/#changed","title":"Changed","text":"<ul> <li>Improved async performance and error handling</li> <li>Enhanced memory management for long conversations</li> <li>Optimized token usage and cost calculations</li> <li>Upgraded provider integrations with the latest APIs</li> </ul>"},{"location":"changelog/#fixed","title":"Fixed","text":"<ul> <li>Various bug fixes and stability improvements</li> <li>Fixed memory leaks in long-running conversations</li> <li>Addressed race conditions in async workflows</li> <li>Improved error reporting and exception handling</li> </ul>"},{"location":"changelog/#010-initial-release","title":"[0.1.0] - Initial Release","text":"<ul> <li>First public release of FastADK</li> <li>Basic agent functionality with OpenAI, Anthropic, and Google support</li> <li>Memory backend for conversations</li> <li>Tool integration system</li> <li>Command-line interface</li> </ul>"},{"location":"cookbook/","title":"FastADK Cookbook","text":"<p>This cookbook provides practical recipes for common tasks when working with FastADK. Each recipe includes step-by-step instructions and code snippets that you can adapt for your own projects.</p>"},{"location":"cookbook/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Basic Agent Setup</li> <li>Adding Custom Tools</li> <li>Working with Context and Memory</li> <li>Implementing Retry Logic</li> <li>Token and Cost Management</li> <li>Customizing Providers</li> <li>Multi-Agent Orchestration</li> <li>Deploying as an API</li> <li>Observability and Monitoring</li> <li>Testing Strategies</li> </ul>"},{"location":"cookbook/#basic-agent-setup","title":"Basic Agent Setup","text":""},{"location":"cookbook/#recipe-creating-a-simple-agent","title":"Recipe: Creating a Simple Agent","text":"<pre><code>from fastadk.core.agent import BaseAgent\n\nclass SimpleAgent(BaseAgent):\n    \"\"\"A simple FastADK agent.\"\"\"\n\n    _description = \"A basic demo agent\"\n    _model_name = \"gpt-3.5-turbo\"  # Or other models like \"gpt-4\", \"claude-2\", etc.\n    _provider = \"openai\"  # Or \"anthropic\", \"google\", etc.\n\n    async def run(self, prompt: str) -&gt; str:\n        \"\"\"Run the agent with the given prompt.\"\"\"\n        return await super().run(prompt)\n</code></pre>"},{"location":"cookbook/#recipe-running-your-agent","title":"Recipe: Running Your Agent","text":"<pre><code>import asyncio\nfrom your_module import SimpleAgent\n\nasync def main():\n    agent = SimpleAgent()\n    response = await agent.run(\"Tell me about artificial intelligence.\")\n    print(response)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"cookbook/#recipe-using-the-cli","title":"Recipe: Using the CLI","text":"<pre><code># Run your agent in interactive mode\nuv run -m fastadk run path/to/your_agent.py\n\n# Start a REPL session\nuv run -m fastadk repl --module path/to/your_agent.py\n\n# Serve your agent as an API\nuv run -m fastadk serve path/to/your_agent.py\n</code></pre>"},{"location":"cookbook/#adding-custom-tools","title":"Adding Custom Tools","text":""},{"location":"cookbook/#recipe-creating-a-custom-tool","title":"Recipe: Creating a Custom Tool","text":"<pre><code>from fastadk.core.agent import BaseAgent, tool\n\nclass WeatherAgent(BaseAgent):\n    \"\"\"An agent that can check the weather.\"\"\"\n\n    _description = \"Weather information assistant\"\n    _model_name = \"gpt-3.5-turbo\"\n    _provider = \"openai\"\n\n    @tool\n    async def get_weather(self, location: str, unit: str = \"celsius\") -&gt; str:\n        \"\"\"Get the current weather for a location.\n\n        Args:\n            location: City, state, or country\n            unit: Temperature unit (celsius or fahrenheit)\n\n        Returns:\n            Current weather information\n        \"\"\"\n        # In a real implementation, you would call a weather API\n        return f\"The weather in {location} is sunny and 25\u00b0{unit[0].upper()}\"\n</code></pre>"},{"location":"cookbook/#recipe-tool-with-error-handling","title":"Recipe: Tool with Error Handling","text":"<pre><code>import aiohttp\nfrom fastadk.core.agent import BaseAgent, tool\nfrom fastadk.core.exceptions import ToolError\n\nclass StockAgent(BaseAgent):\n    \"\"\"An agent that can check stock prices.\"\"\"\n\n    _description = \"Stock information assistant\"\n    _model_name = \"gpt-3.5-turbo\"\n    _provider = \"openai\"\n\n    @tool\n    async def get_stock_price(self, symbol: str) -&gt; str:\n        \"\"\"Get the current stock price for a company.\n\n        Args:\n            symbol: Stock ticker symbol (e.g., AAPL)\n\n        Returns:\n            Current stock price information\n        \"\"\"\n        try:\n            async with aiohttp.ClientSession() as session:\n                async with session.get(f\"https://api.example.com/stocks/{symbol}\") as response:\n                    if response.status != 200:\n                        raise ToolError(f\"Failed to get stock data: {response.status}\")\n                    data = await response.json()\n                    return f\"The current price of {symbol} is ${data['price']:.2f}\"\n        except aiohttp.ClientError as e:\n            raise ToolError(f\"Network error when fetching stock data: {str(e)}\")\n</code></pre>"},{"location":"cookbook/#working-with-context-and-memory","title":"Working with Context and Memory","text":""},{"location":"cookbook/#recipe-custom-context-policy","title":"Recipe: Custom Context Policy","text":"<pre><code>from fastadk.core.agent import BaseAgent\nfrom fastadk.core.context_policy import ContextPolicy\nfrom fastadk.core.context import Context\n\nclass MostRecentPolicy(ContextPolicy):\n    \"\"\"Keep only the most recent N messages.\"\"\"\n\n    def __init__(self, max_messages: int = 10):\n        self.max_messages = max_messages\n\n    async def apply(self, context: Context) -&gt; Context:\n        \"\"\"Apply the policy to the context.\"\"\"\n        if len(context.messages) &lt;= self.max_messages:\n            return context\n\n        # Keep only the most recent messages\n        context.messages = context.messages[-self.max_messages:]\n        return context\n\nclass MyAgent(BaseAgent):\n    \"\"\"Agent with custom context policy.\"\"\"\n\n    _description = \"Agent with custom memory management\"\n    _model_name = \"gpt-3.5-turbo\"\n    _provider = \"openai\"\n\n    def __init__(self):\n        super().__init__()\n        self.context_policies = [MostRecentPolicy(max_messages=5)]\n</code></pre>"},{"location":"cookbook/#recipe-using-vector-memory","title":"Recipe: Using Vector Memory","text":"<pre><code>from fastadk.core.agent import BaseAgent\nfrom fastadk.memory.vector import VectorMemory\n\nclass KnowledgeAgent(BaseAgent):\n    \"\"\"Agent with vector memory for better recall.\"\"\"\n\n    _description = \"Knowledge base agent with semantic search\"\n    _model_name = \"gpt-4\"\n    _provider = \"openai\"\n\n    def __init__(self):\n        super().__init__()\n        # Initialize with vector memory\n        self.memory_backend = VectorMemory(\n            collection_name=\"knowledge_base\",\n            embedding_model=\"text-embedding-ada-002\"\n        )\n\n    async def initialize(self):\n        \"\"\"Add initial knowledge to the agent's memory.\"\"\"\n        await self.memory_backend.add(\"Python is a high-level programming language.\")\n        await self.memory_backend.add(\"FastADK is a framework for building AI agents.\")\n</code></pre>"},{"location":"cookbook/#recipe-using-redis-memory-backend","title":"Recipe: Using Redis Memory Backend","text":"<pre><code>from fastadk.core.agent import BaseAgent\nfrom fastadk.memory.redis import RedisMemory\n\nclass PersistentAgent(BaseAgent):\n    \"\"\"Agent with persistent memory using Redis.\"\"\"\n\n    _description = \"Agent with persistent memory\"\n    _model_name = \"gpt-3.5-turbo\"\n    _provider = \"openai\"\n\n    def __init__(self):\n        super().__init__()\n        # Initialize with Redis memory\n        self.memory_backend = RedisMemory(\n            redis_url=\"redis://localhost:6379/0\",\n            ttl_seconds=3600 * 24  # 24 hours\n        )\n</code></pre>"},{"location":"cookbook/#implementing-retry-logic","title":"Implementing Retry Logic","text":""},{"location":"cookbook/#recipe-automatic-retries-for-network-issues","title":"Recipe: Automatic Retries for Network Issues","text":"<pre><code>from fastadk.core.agent import BaseAgent\nfrom fastadk.core.retry import RetryStrategy, exponential_backoff\n\nclass ReliableAgent(BaseAgent):\n    \"\"\"Agent with robust retry logic.\"\"\"\n\n    _description = \"Agent with automatic retries\"\n    _model_name = \"gpt-3.5-turbo\"\n    _provider = \"openai\"\n\n    def __init__(self):\n        super().__init__()\n        # Configure retry strategy\n        self.retry_strategy = RetryStrategy(\n            max_retries=3,\n            backoff_func=exponential_backoff,\n            retry_on=[\n                \"connection_error\",\n                \"timeout_error\",\n                \"server_error\"\n            ]\n        )\n</code></pre>"},{"location":"cookbook/#token-and-cost-management","title":"Token and Cost Management","text":""},{"location":"cookbook/#recipe-setting-token-budgets","title":"Recipe: Setting Token Budgets","text":"<pre><code>from fastadk.core.agent import BaseAgent\nfrom fastadk.tokens.models import TokenBudget\n\nclass BudgetedAgent(BaseAgent):\n    \"\"\"Agent with token budget controls.\"\"\"\n\n    _description = \"Cost-controlled agent\"\n    _model_name = \"gpt-4\"\n    _provider = \"openai\"\n\n    def __init__(self):\n        super().__init__()\n        # Set a budget per conversation and per request\n        self.token_budget = TokenBudget(\n            max_tokens_per_session=10000,  # 10k tokens per conversation\n            max_tokens_per_request=2000,   # 2k tokens per request\n            action_on_exceed=\"warn\"        # or \"error\" to raise an exception\n        )\n</code></pre>"},{"location":"cookbook/#recipe-tracking-token-usage","title":"Recipe: Tracking Token Usage","text":"<pre><code>from fastadk.core.agent import BaseAgent\nfrom fastadk.observability.metrics import report_metric\n\nclass TrackedAgent(BaseAgent):\n    \"\"\"Agent that tracks token usage.\"\"\"\n\n    _description = \"Agent with token tracking\"\n    _model_name = \"gpt-3.5-turbo\"\n    _provider = \"openai\"\n\n    async def run(self, prompt: str) -&gt; str:\n        \"\"\"Run the agent and report token usage.\"\"\"\n        response = await super().run(prompt)\n\n        # Report token usage as metrics\n        if hasattr(self, \"_token_usage\"):\n            report_metric(\"prompt_tokens\", self._token_usage.prompt_tokens)\n            report_metric(\"completion_tokens\", self._token_usage.completion_tokens)\n            report_metric(\"total_tokens\", self._token_usage.total_tokens)\n\n            # Estimate cost\n            cost = self._token_usage.estimate_cost()\n            report_metric(\"estimated_cost\", cost)\n\n        return response\n</code></pre>"},{"location":"cookbook/#customizing-providers","title":"Customizing Providers","text":""},{"location":"cookbook/#recipe-using-multiple-providers","title":"Recipe: Using Multiple Providers","text":"<pre><code>from fastadk.core.agent import BaseAgent\nfrom fastadk.providers.litellm import LiteLLMProvider\n\nclass MultiProviderAgent(BaseAgent):\n    \"\"\"Agent that can use different LLM providers.\"\"\"\n\n    _description = \"Multi-provider agent\"\n\n    def __init__(self, provider_name: str, model_name: str):\n        super().__init__()\n        self._provider = provider_name\n        self._model_name = model_name\n\n        # Configure LiteLLM provider for flexibility\n        self.model = LiteLLMProvider(\n            model_name=self._model_name,\n            provider=self._provider\n        )\n\n# Usage examples:\n# agent1 = MultiProviderAgent(\"openai\", \"gpt-4\")\n# agent2 = MultiProviderAgent(\"anthropic\", \"claude-2\")\n# agent3 = MultiProviderAgent(\"google\", \"gemini-pro\")\n</code></pre>"},{"location":"cookbook/#recipe-creating-a-custom-provider","title":"Recipe: Creating a Custom Provider","text":"<pre><code>from typing import Dict, Any\nfrom fastadk.core.agent import BaseAgent\nfrom fastadk.providers.base import ModelProvider\n\nclass MyCustomProvider(ModelProvider):\n    \"\"\"Custom LLM provider implementation.\"\"\"\n\n    def __init__(self, api_key: str, **kwargs):\n        super().__init__(**kwargs)\n        self.api_key = api_key\n        # Initialize your custom client here\n\n    async def generate(self, prompt: str, **kwargs) -&gt; str:\n        \"\"\"Generate a response from the LLM.\"\"\"\n        # Implement your custom API call here\n        # ...\n        return \"Response from custom provider\"\n\n    async def stream(self, prompt: str, **kwargs) -&gt; AsyncGenerator[str, None]:\n        \"\"\"Stream a response from the LLM.\"\"\"\n        # Implement streaming logic\n        # ...\n        yield \"Streaming response from custom provider\"\n\n    async def health_check(self) -&gt; Dict[str, Any]:\n        \"\"\"Check if the provider is healthy.\"\"\"\n        return {\"status\": \"ok\", \"latency_ms\": 150}\n\nclass CustomAgent(BaseAgent):\n    \"\"\"Agent using a custom provider.\"\"\"\n\n    _description = \"Agent with custom LLM provider\"\n\n    def __init__(self, api_key: str):\n        super().__init__()\n        self.model = MyCustomProvider(api_key=api_key)\n</code></pre>"},{"location":"cookbook/#multi-agent-orchestration","title":"Multi-Agent Orchestration","text":""},{"location":"cookbook/#recipe-creating-a-workflow-with-multiple-agents","title":"Recipe: Creating a Workflow with Multiple Agents","text":"<pre><code>from fastadk.core.agent import BaseAgent\nfrom fastadk.core.workflow import Workflow\n\nclass ResearchAgent(BaseAgent):\n    \"\"\"Agent for research tasks.\"\"\"\n    _description = \"Research assistant\"\n    _model_name = \"gpt-4\"\n    _provider = \"openai\"\n\nclass WritingAgent(BaseAgent):\n    \"\"\"Agent for writing tasks.\"\"\"\n    _description = \"Writing assistant\"\n    _model_name = \"gpt-4\"\n    _provider = \"openai\"\n\nclass ProjectManager:\n    \"\"\"Orchestrates multiple agents in a workflow.\"\"\"\n\n    def __init__(self):\n        self.research_agent = ResearchAgent()\n        self.writing_agent = WritingAgent()\n        self.workflow = Workflow()\n\n    async def create_report(self, topic: str) -&gt; str:\n        \"\"\"Create a complete report on a topic.\"\"\"\n        # Define workflow steps\n        research_step = self.workflow.add_step(\n            self.research_agent.run,\n            args=[f\"Research key facts about {topic}\"]\n        )\n\n        outline_step = self.workflow.add_step(\n            self.writing_agent.run,\n            args=[f\"Create an outline for a report on {topic} using this research: {research_step.result}\"],\n            depends_on=[research_step]\n        )\n\n        writing_step = self.workflow.add_step(\n            self.writing_agent.run,\n            args=[f\"Write a full report following this outline: {outline_step.result}\"],\n            depends_on=[outline_step]\n        )\n\n        # Execute the workflow\n        results = await self.workflow.execute()\n        return results[writing_step.id]\n</code></pre>"},{"location":"cookbook/#deploying-as-an-api","title":"Deploying as an API","text":""},{"location":"cookbook/#recipe-creating-a-fastapi-endpoint","title":"Recipe: Creating a FastAPI Endpoint","text":"<pre><code>from fastapi import FastAPI, HTTPException\nfrom pydantic import BaseModel\nfrom typing import Dict, Any\nfrom fastadk.core.agent import BaseAgent\n\n# Define your agent\nclass MyAgent(BaseAgent):\n    \"\"\"Example agent for API deployment.\"\"\"\n    _description = \"API-deployed agent\"\n    _model_name = \"gpt-3.5-turbo\"\n    _provider = \"openai\"\n\n# Initialize FastAPI and the agent\napp = FastAPI(title=\"FastADK Agent API\")\nagent = MyAgent()\n\n# Define request and response models\nclass QueryRequest(BaseModel):\n    prompt: str\n    session_id: str = None\n\nclass QueryResponse(BaseModel):\n    response: str\n    usage: Dict[str, Any] = None\n\n@app.post(\"/query\", response_model=QueryResponse)\nasync def query_agent(request: QueryRequest):\n    \"\"\"Process a query with the agent.\"\"\"\n    try:\n        response = await agent.run(request.prompt)\n\n        # Include token usage if available\n        usage = None\n        if hasattr(agent, \"_token_usage\"):\n            usage = {\n                \"prompt_tokens\": agent._token_usage.prompt_tokens,\n                \"completion_tokens\": agent._token_usage.completion_tokens,\n                \"total_tokens\": agent._token_usage.total_tokens\n            }\n\n        return QueryResponse(response=response, usage=usage)\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n</code></pre>"},{"location":"cookbook/#recipe-using-fastadks-built-in-api-server","title":"Recipe: Using FastADK's Built-in API Server","text":"<pre><code># agent.py\nfrom fastadk.core.agent import BaseAgent\n\nclass MyApiAgent(BaseAgent):\n    \"\"\"Agent designed for API deployment.\"\"\"\n    _description = \"API service agent\"\n    _model_name = \"gpt-3.5-turbo\"\n    _provider = \"openai\"\n\n# Command to run the API server:\n# uv run -m fastadk serve agent.py\n</code></pre>"},{"location":"cookbook/#observability-and-monitoring","title":"Observability and Monitoring","text":""},{"location":"cookbook/#recipe-setting-up-structured-logging","title":"Recipe: Setting Up Structured Logging","text":"<pre><code>from fastadk.core.agent import BaseAgent\nfrom fastadk.observability.logger import setup_logging\n\n# Configure logging\nsetup_logging(\n    level=\"INFO\",\n    format=\"json\",\n    log_to_file=True,\n    log_file_path=\"./logs/agent.log\"\n)\n\nclass MonitoredAgent(BaseAgent):\n    \"\"\"Agent with enhanced logging.\"\"\"\n    _description = \"Observable agent\"\n    _model_name = \"gpt-3.5-turbo\"\n    _provider = \"openai\"\n</code></pre>"},{"location":"cookbook/#recipe-adding-opentelemetry-tracing","title":"Recipe: Adding OpenTelemetry Tracing","text":"<pre><code>from fastadk.core.agent import BaseAgent\nfrom fastadk.observability.tracing import setup_tracing\n\n# Configure tracing\nsetup_tracing(\n    service_name=\"my-fastadk-agent\",\n    exporter=\"otlp\",  # or \"console\", \"jaeger\", etc.\n    endpoint=\"http://collector:4317\"\n)\n\nclass TracedAgent(BaseAgent):\n    \"\"\"Agent with OpenTelemetry tracing.\"\"\"\n    _description = \"Traced agent\"\n    _model_name = \"gpt-3.5-turbo\"\n    _provider = \"openai\"\n</code></pre>"},{"location":"cookbook/#recipe-exporting-prometheus-metrics","title":"Recipe: Exporting Prometheus Metrics","text":"<pre><code>from fastadk.core.agent import BaseAgent\nfrom fastadk.observability.metrics import setup_metrics, report_metric\n\n# Configure metrics\nsetup_metrics(\n    service_name=\"my-fastadk-agent\",\n    export_to_prometheus=True,\n    prometheus_port=8000\n)\n\nclass MetricsAgent(BaseAgent):\n    \"\"\"Agent that exports metrics.\"\"\"\n    _description = \"Metrics-enabled agent\"\n    _model_name = \"gpt-3.5-turbo\"\n    _provider = \"openai\"\n\n    async def run(self, prompt: str) -&gt; str:\n        \"\"\"Run the agent and record metrics.\"\"\"\n        start_time = time.time()\n        response = await super().run(prompt)\n\n        # Record custom metrics\n        execution_time = time.time() - start_time\n        report_metric(\"agent_execution_time_seconds\", execution_time)\n        report_metric(\"agent_requests_total\", 1)\n\n        return response\n</code></pre>"},{"location":"cookbook/#testing-strategies","title":"Testing Strategies","text":""},{"location":"cookbook/#recipe-unit-testing-with-mock-llm","title":"Recipe: Unit Testing with Mock LLM","text":"<pre><code>import pytest\nfrom fastadk.core.agent import BaseAgent\nfrom fastadk.testing.utils import MockLLMProvider\n\nclass SimpleAgent(BaseAgent):\n    \"\"\"Simple agent for testing.\"\"\"\n    _description = \"Test agent\"\n    _model_name = \"gpt-3.5-turbo\"\n    _provider = \"openai\"\n\n@pytest.fixture\ndef mock_agent():\n    \"\"\"Create an agent with a mock LLM provider.\"\"\"\n    agent = SimpleAgent()\n    # Replace the real provider with a mock\n    agent.model = MockLLMProvider(\n        responses=[\"This is a mocked response.\"]\n    )\n    return agent\n\n@pytest.mark.asyncio\nasync def test_agent_run(mock_agent):\n    \"\"\"Test that the agent returns the expected response.\"\"\"\n    response = await mock_agent.run(\"Hello, agent!\")\n    assert response == \"This is a mocked response.\"\n    assert mock_agent.model.call_count == 1\n</code></pre>"},{"location":"cookbook/#recipe-integration-testing-with-tool-mocks","title":"Recipe: Integration Testing with Tool Mocks","text":"<pre><code>import pytest\nfrom fastadk.core.agent import BaseAgent, tool\nfrom fastadk.testing.utils import MockLLMProvider, mock_tool\n\nclass WeatherAgent(BaseAgent):\n    \"\"\"Agent with a weather tool.\"\"\"\n    _description = \"Weather agent\"\n    _model_name = \"gpt-3.5-turbo\"\n    _provider = \"openai\"\n\n    @tool\n    async def get_weather(self, location: str) -&gt; str:\n        \"\"\"Get weather for a location.\"\"\"\n        # In production, this would call a real API\n        return f\"Sunny and 75\u00b0F in {location}\"\n\n@pytest.fixture\ndef mock_weather_agent():\n    \"\"\"Create an agent with mocked components.\"\"\"\n    agent = WeatherAgent()\n    # Mock the LLM provider\n    agent.model = MockLLMProvider(\n        responses=[\"The weather in Seattle is sunny.\"]\n    )\n    # Mock the weather tool\n    mock_tool(agent, \"get_weather\", lambda location: f\"Mocked weather for {location}\")\n    return agent\n\n@pytest.mark.asyncio\nasync def test_weather_agent(mock_weather_agent):\n    \"\"\"Test the weather agent with mocked components.\"\"\"\n    response = await mock_weather_agent.run(\"What's the weather in Seattle?\")\n    assert \"sunny\" in response.lower()\n    # Verify the tool was called\n    assert mock_weather_agent.tools_used == [\"get_weather\"]\n</code></pre> <p>These recipes should help you get started with common FastADK patterns and practices. For more detailed information on specific components, refer to the relevant sections in the API documentation.</p> <p>Do you have a useful pattern or recipe that should be included here? Share it with us on GitHub Discussions or consider contributing to our documentation!</p>"},{"location":"system-overview/","title":"FastADK System Overview","text":"<p>FastADK is a comprehensive framework that dramatically simplifies and accelerates the development of AI agents. This document provides a detailed explanation of the system's architecture, components, workflows, and benefits in version 0.2.0.</p>"},{"location":"system-overview/#what-is-fastadk","title":"What is FastADK?","text":"<p>FastADK (Fast Agent Development Kit) is a developer-friendly Python framework that provides high-level abstractions, declarative APIs, and intuitive tooling to make AI agent development more efficient, maintainable, and enjoyable.</p> <p>The framework creates a layer of ergonomic abstractions over various LLM providers (OpenAI, Anthropic, Google Gemini), enabling developers to design, test, and deploy tool-using LLM agents with minimal boilerplate code.</p> <p>FastADK is designed as an open-source project with the potential for optional commercial add-ons in the future. It targets Python 3.10+ and leverages familiar libraries in the Python ecosystem, including FastAPI for web serving, Pydantic for data validation, and specialized modules for memory management and observability.</p>"},{"location":"system-overview/#key-features-in-version-020","title":"Key Features in Version 0.2.0","text":"<p>The 0.2.0 release introduces significant improvements across all aspects of the framework:</p>"},{"location":"system-overview/#token-and-cost-tracking","title":"Token and Cost Tracking","text":"<ul> <li>TokenUsage Tracking: Automatic tracking of prompt, completion, and total tokens</li> <li>Cost Calculation: Integrated cost estimation based on provider pricing</li> <li>Budget Management: Configurable per-session and per-query token budgets</li> <li>Usage Metrics: Prometheus metrics for token usage and cost monitoring</li> </ul>"},{"location":"system-overview/#advanced-memory-management","title":"Advanced Memory Management","text":"<ul> <li>Context Policies: Sliding window, summarization, and hybrid vector retrieval</li> <li>Vector Store Integration: FAISS, Pinecone, and other vector databases</li> <li>Persistent Backends: Redis and SQL database integration</li> <li>Summarization Service: LLM-powered conversation summarization</li> </ul>"},{"location":"system-overview/#scalability-and-performance","title":"Scalability and Performance","text":"<ul> <li>True Async: Non-blocking async execution for models and tools</li> <li>Parallel Workflows: Run sub-tasks concurrently with easy orchestration</li> <li>Caching: In-memory and Redis caching for responses and tools</li> <li>Lazy Tool Execution: Skip unnecessary tool calls when possible</li> <li>Batch Processing: Utilities for handling bulk operations</li> </ul>"},{"location":"system-overview/#extensibility-and-integration","title":"Extensibility and Integration","text":"<ul> <li>Plugin Architecture: Discover and load custom modules dynamically</li> <li>Adapter Interfaces: Discord and Slack integration adapters</li> <li>Multi-Agent Orchestration: Coordinate multiple specialized agents</li> <li>Fine-Tuning Helpers: Utilities for model customization</li> </ul>"},{"location":"system-overview/#developer-experience","title":"Developer Experience","text":"<ul> <li>Interactive REPL: Command-line REPL for agent development and testing</li> <li>Debugging Tools: Verbose logging and chain-of-thought capture</li> <li>Test Framework: Mock LLMs and tools for deterministic testing</li> <li>Project Scaffolding: <code>fastadk init</code> command for quick setup</li> <li>IDE Support: VSCode snippets and type hints</li> </ul>"},{"location":"system-overview/#observability","title":"Observability","text":"<ul> <li>Structured Logging: JSON logs for all agent events</li> <li>OpenTelemetry: Traces and spans for performance monitoring</li> <li>Prometheus Metrics: Endpoint for metrics collection</li> <li>Redaction Filter: Protect sensitive data in logs</li> </ul>"},{"location":"system-overview/#system-architecture","title":"System Architecture","text":"<p>FastADK follows a modular architecture designed for flexibility, extensibility, and performance.</p> <pre><code>graph TD\n    %% \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 User Layer \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    subgraph \"User Applications\"\n        direction TB\n        UA[Agent Implementations]\n    end\n\n    %% \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 FastADK Framework (vertical) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    subgraph \"FastADK Framework\"\n        direction TB   %% &lt;-- stack the six inner sections top-to-bottom\n\n        %% \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Core \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n        subgraph \"Core\"\n            direction TB\n            A[Agent System]\n            T[Tool Manager]\n            W[Workflow Engine]\n            CP[Context Policies]\n            PM[Plugin Manager]\n        end\n\n        %% \u2500\u2500\u2500\u2500\u2500\u2500\u2500 Infrastructure \u2500\u2500\u2500\u2500\u2500\u2500\u2500\n        subgraph \"Infrastructure\"\n            direction TB\n            O[Observability]\n            C[Configuration]\n            API[HTTP API]\n            CLI[CLI Tools]\n        end\n\n        %% \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Providers \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n        subgraph \"Providers\"\n            direction TB\n            PO[OpenAI]\n            PG[Gemini]\n            PA[Anthropic]\n            PL[LiteLLM]\n            PC[Custom]\n        end\n\n        %% \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Memory \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n        subgraph \"Memory\"\n            direction TB\n            MI[In-Memory]\n            MR[Redis]\n            MV[Vector Store]\n            MS[SQL]\n        end\n\n        %% \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Tokens \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n        subgraph \"Tokens\"\n            direction TB\n            TC[Counting]\n            TP[Pricing]\n            TBb[Budgeting]\n        end\n\n        %% \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Adapters \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n        subgraph \"Adapters\"\n            direction TB\n            AD[Discord]\n            AS[Slack]\n            AC[Custom]\n        end\n    end\n\n    %% \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 External Services \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    subgraph \"External Services\"\n        direction TB\n        LLM[LLM APIs]\n        DB[Databases]\n        MM[Metrics &amp; Monitoring]\n    end\n\n    %% \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Connections \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    UA --&gt; A\n    A --&gt; T &amp; W &amp; CP &amp; PM\n    A --&gt; O &amp; C &amp; API\n    A --&gt; PO &amp; PG &amp; PA &amp; PL &amp; PC\n    A --&gt; MI &amp; MR &amp; MV &amp; MS\n    A --&gt; TC\n    TC --&gt; TP &amp; TBb\n    A --&gt; AD &amp; AS &amp; AC\n\n    %% Provider \u2192 LLM\n    PO &amp; PG &amp; PA &amp; PL --&gt; LLM\n    %% Memory \u2192 DB\n    MR &amp; MV &amp; MS --&gt; DB\n    %% Observability \u2192 Metrics\n    O --&gt; MM\n</code></pre>"},{"location":"system-overview/#core-subsystems","title":"Core Subsystems","text":""},{"location":"system-overview/#1-agent-system","title":"1. Agent System","text":"<p>The Agent system is the central component that manages the lifecycle of agents, handles tool registration, manages context, and orchestrates the interaction between the user, LLM, and tools.</p> <pre><code>classDiagram\n    class BaseAgent {\n        +model: ModelProvider\n        +tool_manager: ToolManager\n        +plugin_manager: PluginManager\n        +config: Configuration\n        +async run(prompt: str): str\n        +async stream(prompt: str): AsyncGenerator\n        +register_tool(tool: Callable)\n        +_prepare_context(context: Context)\n        +_handle_response(response: str)\n        +_tool_executor(tool_name: str, args: dict)\n    }\n\n    class Agent {\n        &lt;&lt;decorator&gt;&gt;\n        +model: str\n        +provider: str\n        +description: str\n        +streaming: bool\n    }\n\n    class tool {\n        &lt;&lt;decorator&gt;&gt;\n        +name: str\n        +description: str\n        +required: List[str]\n        +cache_ttl: int\n        +retry: int\n    }\n\n    BaseAgent &lt;|-- UserAgent\n    Agent --&gt; UserAgent\n    tool --&gt; UserMethod\n</code></pre>"},{"location":"system-overview/#2-provider-system","title":"2. Provider System","text":"<p>The Provider system abstracts different LLM backends behind a unified interface, handling the specific details of each provider's API.</p> <pre><code>classDiagram\n    class ModelProviderABC {\n        &lt;&lt;abstract&gt;&gt;\n        +async generate(prompt: str, **kwargs): str\n        +async stream(prompt: str, **kwargs): AsyncGenerator\n        +count_tokens(text: str): int\n        +get_usage(response): TokenUsage\n        +health_check(): bool\n    }\n\n    ModelProviderABC &lt;|-- OpenAIProvider\n    ModelProviderABC &lt;|-- GeminiProvider\n    ModelProviderABC &lt;|-- AnthropicProvider\n    ModelProviderABC &lt;|-- LiteLLMProvider\n    ModelProviderABC &lt;|-- CustomProvider\n\n    class ProviderFactory {\n        +create(provider: str, model: str, **kwargs): ModelProviderABC\n        +register(name: str, provider_class: Type)\n    }\n\n    ProviderFactory --&gt; ModelProviderABC\n</code></pre>"},{"location":"system-overview/#3-memory-system","title":"3. Memory System","text":"<p>The Memory system manages conversation history and context, with pluggable backends for different storage options.</p> <pre><code>classDiagram\n    class MemoryBackend {\n        &lt;&lt;abstract&gt;&gt;\n        +async get(key: str): Any\n        +async set(key: str, value: Any)\n        +async delete(key: str)\n        +async exists(key: str): bool\n        +async list_keys(pattern: str): List[str]\n    }\n\n    MemoryBackend &lt;|-- InMemoryBackend\n    MemoryBackend &lt;|-- RedisBackend\n    MemoryBackend &lt;|-- SQLBackend\n    MemoryBackend &lt;|-- VectorMemoryBackend\n\n    class Context {\n        +messages: List[Message]\n        +add(role: str, content: str)\n        +add_system(content: str)\n        +add_user(content: str)\n        +add_assistant(content: str)\n        +to_string(): str\n        +clear()\n    }\n\n    class ContextPolicy {\n        &lt;&lt;abstract&gt;&gt;\n        +async apply(history: List[Message]): List[Message]\n    }\n\n    ContextPolicy &lt;|-- MostRecentPolicy\n    ContextPolicy &lt;|-- SummarizeOlderPolicy\n    ContextPolicy &lt;|-- HybridVectorRetrievalPolicy\n\n    Context --&gt; ContextPolicy\n</code></pre>"},{"location":"system-overview/#4-workflow-system","title":"4. Workflow System","text":"<p>The Workflow system enables the orchestration of multiple steps or agents to solve complex problems.</p> <pre><code>classDiagram\n    class Workflow {\n        +steps: List[Step]\n        +name: str\n        +async execute(input: Any): Any\n        +static sequence(*steps): Workflow\n        +static parallel(*steps): Workflow\n        +static conditional(condition, if_true, if_false): Workflow\n    }\n\n    class Step {\n        &lt;&lt;abstract&gt;&gt;\n        +name: str\n        +async execute(input: Any): Any\n    }\n\n    Step &lt;|-- FunctionStep\n    Step &lt;|-- AgentStep\n    Step &lt;|-- TransformStep\n    Step &lt;|-- WorkflowStep\n\n    Workflow o-- Step\n    WorkflowStep o-- Workflow\n</code></pre>"},{"location":"system-overview/#5-token-and-cost-tracking","title":"5. Token and Cost Tracking","text":"<p>The Token system tracks token usage and estimates costs across all LLM interactions.</p> <pre><code>classDiagram\n    class TokenUsage {\n        +prompt_tokens: int\n        +completion_tokens: int\n        +total_tokens: int\n        +model: str\n        +provider: str\n    }\n\n    class CostCalculator {\n        +static calculate(usage: TokenUsage, price_per_1k: Tuple = None): float\n    }\n\n    class TokenBudget {\n        +max_tokens_per_query: int\n        +max_tokens_per_session: int\n        +max_cost_per_query: float\n        +max_cost_per_session: float\n        +current_session_tokens: int\n        +current_session_cost: float\n        +on_exceed: str\n        +check(usage: TokenUsage): bool\n    }\n\n    TokenUsage --&gt; CostCalculator\n    TokenUsage --&gt; TokenBudget\n</code></pre>"},{"location":"system-overview/#6-observability-system","title":"6. Observability System","text":"<p>The Observability system provides visibility into agent behavior through logging, metrics, and tracing.</p> <pre><code>classDiagram\n    class Logger {\n        +debug(msg: str, **kwargs)\n        +info(msg: str, **kwargs)\n        +warning(msg: str, **kwargs)\n        +error(msg: str, **kwargs)\n        +configure(level: str, format: str)\n    }\n\n    class Metrics {\n        +counter(name: str, description: str): Counter\n        +gauge(name: str, description: str): Gauge\n        +histogram(name: str, description: str): Histogram\n        +configure(enable: bool, port: int)\n    }\n\n    class Tracing {\n        +start_span(name: str): Span\n        +add_event(name: str, **attributes)\n        +configure(enable: bool, exporter: str)\n    }\n\n    class RedactionFilter {\n        +patterns: List[str]\n        +redact(text: str): str\n        +add_pattern(pattern: str)\n    }\n\n    Logger --&gt; RedactionFilter\n</code></pre>"},{"location":"system-overview/#7-plugin-system","title":"7. Plugin System","text":"<p>The Plugin system enables extensibility through dynamically loaded plugins.</p> <pre><code>classDiagram\n    class PluginManager {\n        +plugins: Dict[str, Plugin]\n        +discover_plugins()\n        +register_plugin(plugin: Plugin)\n        +get_plugin(name: str): Plugin\n        +async emit_event(event: str, data: Dict)\n    }\n\n    class Plugin {\n        &lt;&lt;abstract&gt;&gt;\n        +name: str\n        +version: str\n        +initialize()\n        +async on_event(event: str, data: Dict)\n    }\n\n    PluginManager o-- Plugin\n    Plugin &lt;|-- ModelProviderPlugin\n    Plugin &lt;|-- MemoryBackendPlugin\n    Plugin &lt;|-- ToolsPlugin\n    Plugin &lt;|-- AdapterPlugin\n</code></pre>"},{"location":"system-overview/#user-workflows","title":"User Workflows","text":""},{"location":"system-overview/#basic-agent-workflow","title":"Basic Agent Workflow","text":"<pre><code>sequenceDiagram\n    participant User\n    participant Agent\n    participant Model\n    participant Tools\n\n    User-&gt;&gt;Agent: run(\"What's the weather in London?\")\n    Agent-&gt;&gt;Agent: Prepare context\n    Agent-&gt;&gt;Model: Generate response\n    Model--&gt;&gt;Agent: Structured response with tool call\n    Agent-&gt;&gt;Tools: Execute get_weather(\"London\")\n    Tools--&gt;&gt;Agent: Weather data\n    Agent-&gt;&gt;Model: Generate final response with tool results\n    Model--&gt;&gt;Agent: Human-readable response\n    Agent--&gt;&gt;User: \"The weather in London is currently sunny with 22\u00b0C\"\n</code></pre>"},{"location":"system-overview/#memory-and-context-management","title":"Memory and Context Management","text":"<pre><code>sequenceDiagram\n    participant User\n    participant Agent\n    participant ContextPolicy\n    participant Memory\n    participant Model\n\n    User-&gt;&gt;Agent: run(\"What did I ask earlier?\")\n    Agent-&gt;&gt;Memory: get_conversation_history()\n    Memory--&gt;&gt;Agent: Previous messages\n    Agent-&gt;&gt;ContextPolicy: apply(history)\n    ContextPolicy-&gt;&gt;ContextPolicy: Filter/transform messages\n    alt Too many tokens\n        ContextPolicy-&gt;&gt;Model: Summarize older messages\n        Model--&gt;&gt;ContextPolicy: Summary\n    end\n    ContextPolicy--&gt;&gt;Agent: Optimized context\n    Agent-&gt;&gt;Model: Generate with optimized context\n    Model--&gt;&gt;Agent: Response referencing previous interaction\n    Agent-&gt;&gt;Memory: store_message(response)\n    Agent--&gt;&gt;User: \"You asked about the weather in London\"\n</code></pre>"},{"location":"system-overview/#multi-agent-workflow","title":"Multi-Agent Workflow","text":"<pre><code>sequenceDiagram\n    participant User\n    participant Orchestrator\n    participant ResearchAgent\n    participant AnalysisAgent\n    participant SummaryAgent\n\n    User-&gt;&gt;Orchestrator: execute(\"Research renewable energy trends\")\n    Orchestrator-&gt;&gt;ResearchAgent: run(\"Find recent data on renewable energy\")\n    ResearchAgent--&gt;&gt;Orchestrator: Research findings\n    Orchestrator-&gt;&gt;AnalysisAgent: run(\"Analyze these findings\" + research)\n    AnalysisAgent--&gt;&gt;Orchestrator: Analysis results\n    Orchestrator-&gt;&gt;SummaryAgent: run(\"Summarize research and analysis\")\n    SummaryAgent--&gt;&gt;Orchestrator: Final summary\n    Orchestrator--&gt;&gt;User: Comprehensive report\n</code></pre>"},{"location":"system-overview/#http-api-workflow","title":"HTTP API Workflow","text":"<pre><code>sequenceDiagram\n    participant Client\n    participant FastAPI\n    participant Router\n    participant AgentRegistry\n    participant Agent\n\n    Client-&gt;&gt;FastAPI: POST /api/agents/weather-agent/run\n    FastAPI-&gt;&gt;Router: route_request()\n    Router-&gt;&gt;AgentRegistry: get_agent(\"weather-agent\")\n    AgentRegistry--&gt;&gt;Router: WeatherAgent instance\n    Router-&gt;&gt;Agent: run(request.prompt)\n    Agent--&gt;&gt;Router: Response\n    Router--&gt;&gt;FastAPI: JSON response\n    FastAPI--&gt;&gt;Client: 200 OK with agent response\n</code></pre>"},{"location":"system-overview/#implementation-example-patterns","title":"Implementation Example Patterns","text":""},{"location":"system-overview/#agent-definition","title":"Agent Definition","text":"<pre><code>from fastadk import Agent, BaseAgent, tool\nfrom typing import Dict, List\n\n@Agent(\n    model=\"gemini-1.5-pro\",\n    provider=\"gemini\",\n    description=\"Assistant that helps with restaurant recommendations\"\n)\nclass RestaurantAgent(BaseAgent):\n    def __init__(self):\n        super().__init__()\n        # Additional initialization\n        self.preferences = {}\n\n    @tool\n    def search_restaurants(self, cuisine: str, location: str, price_range: str = \"moderate\") -&gt; List[Dict]:\n        \"\"\"\n        Search for restaurants based on criteria.\n\n        Args:\n            cuisine: Type of food (e.g., Italian, Japanese, Indian)\n            location: City or neighborhood\n            price_range: Budget level (cheap, moderate, expensive)\n\n        Returns:\n            List of matching restaurants with details\n        \"\"\"\n        # Implementation details...\n        return [\n            {\n                \"name\": \"Sample Restaurant\",\n                \"cuisine\": cuisine,\n                \"location\": location,\n                \"price_range\": price_range,\n                \"rating\": 4.5\n            }\n        ]\n\n    @tool\n    def get_restaurant_details(self, restaurant_id: str) -&gt; Dict:\n        \"\"\"Get detailed information about a specific restaurant.\"\"\"\n        # Implementation details...\n        return {\n            \"id\": restaurant_id,\n            \"name\": \"Sample Restaurant\",\n            \"description\": \"A lovely place to dine\",\n            \"opening_hours\": \"9 AM - 10 PM\",\n            \"phone\": \"+1-234-567-8900\"\n        }\n\n    @tool\n    def save_preference(self, cuisine: str, rating: int) -&gt; str:\n        \"\"\"Save user food preference for future recommendations.\"\"\"\n        self.preferences[cuisine] = rating\n        return f\"Saved preference for {cuisine} with rating {rating}\"\n</code></pre>"},{"location":"system-overview/#memory-implementation","title":"Memory Implementation","text":"<pre><code>from fastadk import Agent, BaseAgent\nfrom fastadk.memory import VectorMemoryBackend\nfrom typing import List, Dict, Any\n\n@Agent(model=\"gemini-1.5-pro\")\nclass KnowledgeAgent(BaseAgent):\n    def __init__(self):\n        super().__init__()\n        # Initialize vector memory with embeddings\n        self.memory = VectorMemoryBackend(\n            embedding_model=\"text-embedding-3-small\",\n            embedding_provider=\"openai\",\n            dimension=512,\n            similarity_threshold=0.75\n        )\n\n    async def add_to_knowledge_base(self, text: str, metadata: Dict[str, Any] = None) -&gt; str:\n        \"\"\"Add information to the agent's knowledge base.\"\"\"\n        # Store text in vector memory with metadata\n        doc_id = await self.memory.store_embedding(\n            text=text,\n            metadata=metadata or {}\n        )\n        return f\"Added to knowledge base with ID: {doc_id}\"\n\n    async def retrieve_relevant_knowledge(self, query: str, limit: int = 5) -&gt; List[Dict]:\n        \"\"\"Retrieve relevant information from the knowledge base.\"\"\"\n        # Get semantically similar documents\n        results = await self.memory.search_embeddings(\n            query=query,\n            limit=limit\n        )\n        return results\n\n    @tool\n    async def answer_from_knowledge_base(self, question: str) -&gt; str:\n        \"\"\"Answer questions using the stored knowledge base.\"\"\"\n        # Get relevant context\n        context = await self.retrieve_relevant_knowledge(question)\n\n        # Prepare prompt with context\n        prompt = f\"Based on the following information:\\n\\n\"\n        for item in context:\n            prompt += f\"- {item['text']}\\n\\n\"\n        prompt += f\"Answer this question: {question}\"\n\n        # Generate response using the model with context\n        response = await self.model.generate(prompt)\n\n        return response\n</code></pre>"},{"location":"system-overview/#workflow-orchestration","title":"Workflow Orchestration","text":"<pre><code>from fastadk.core.workflow import Workflow, step, conditional, transform\nfrom typing import Dict, List, Any\n\n# Define workflow steps as functions with the @step decorator\n@step(name=\"Data Collection\")\nasync def collect_data(sources: List[str]) -&gt; Dict[str, Any]:\n    \"\"\"Collect data from multiple sources.\"\"\"\n    results = {}\n    for source in sources:\n        # Implementation details...\n        results[source] = {\"status\": \"collected\", \"data\": [...]}\n    return results\n\n@step(name=\"Data Validation\")\nasync def validate_data(data: Dict[str, Any]) -&gt; Dict[str, Any]:\n    \"\"\"Validate collected data for completeness and accuracy.\"\"\"\n    validation_results = {}\n    for source, content in data.items():\n        # Validation logic...\n        is_valid = True  # Example validation\n        validation_results[source] = {\n            \"is_valid\": is_valid,\n            \"data\": content[\"data\"] if is_valid else None,\n            \"errors\": [] if is_valid else [\"Data incomplete\"]\n        }\n    return validation_results\n\n@step(name=\"Data Processing\")\nasync def process_data(validated_data: Dict[str, Any]) -&gt; Dict[str, Any]:\n    \"\"\"Process only the validated data.\"\"\"\n    processed_results = {}\n    for source, content in validated_data.items():\n        if content[\"is_valid\"]:\n            # Processing logic...\n            processed_results[source] = {\n                \"processed\": True,\n                \"results\": [...]  # Processed data\n            }\n    return processed_results\n\n@transform(name=\"Report Generation\")\ndef generate_report(processing_results: Dict[str, Any]) -&gt; str:\n    \"\"\"Generate a final report from processing results.\"\"\"\n    report = \"Data Processing Report\\n=====================\\n\\n\"\n    for source, result in processing_results.items():\n        report += f\"Source: {source}\\n\"\n        report += f\"Status: {'Processed' if result.get('processed') else 'Failed'}\\n\"\n        report += f\"Results: {len(result.get('results', []))} items\\n\\n\"\n    return report\n\n# Create a workflow that combines these steps\ndata_workflow = Workflow.sequence(\n    collect_data,\n    validate_data,\n    process_data,\n    generate_report,\n    name=\"Data Pipeline Workflow\"\n)\n\n# Example usage\nasync def run_workflow():\n    sources = [\"database\", \"api\", \"files\"]\n    result = await data_workflow.execute(sources)\n    print(result)\n</code></pre>"},{"location":"system-overview/#observability-implementation","title":"Observability Implementation","text":"<pre><code>from fastadk import Agent, BaseAgent\nfrom fastadk.observability import configure_logging, configure_metrics, configure_tracing\nfrom fastadk.observability.redaction import RedactionFilter\n\n# Configure comprehensive observability\nconfigure_logging(\n    level=\"INFO\",\n    format=\"json\",\n    service_name=\"recommendation-agent\",\n    log_file=\"agent.log\"\n)\n\nconfigure_metrics(\n    enable=True,\n    port=9090,\n    service_name=\"recommendation-agent\"\n)\n\nconfigure_tracing(\n    enable=True,\n    exporter=\"jaeger\",\n    endpoint=\"http://jaeger:14268/api/traces\",\n    service_name=\"recommendation-agent\"\n)\n\n# Configure redaction for sensitive data\nredaction = RedactionFilter(patterns=[\n    r\"(api_key|key|token)=([a-zA-Z0-9-_.]+)\",\n    r\"(password|secret)=([^&amp;\\s]+)\",\n    r\"(credit_card|card_number)=(\\d{4}[\\s-]?\\d{4}[\\s-]?\\d{4}[\\s-]?\\d{4})\"\n])\n\n@Agent(model=\"gemini-1.5-pro\")\nclass ObservableAgent(BaseAgent):\n    async def run(self, prompt: str) -&gt; str:\n        # Use tracing to track the lifecycle of the request\n        from fastadk.observability.tracing import get_tracer\n        tracer = get_tracer()\n\n        with tracer.start_as_current_span(\"agent_run\") as span:\n            # Add attributes to the span\n            span.set_attribute(\"prompt.length\", len(prompt))\n            span.set_attribute(\"agent.model\", self.model_name)\n\n            # Add redaction for sensitive data\n            safe_prompt = redaction.redact(prompt)\n            span.set_attribute(\"prompt.redacted\", safe_prompt)\n\n            # Record metrics\n            from fastadk.observability.metrics import counter, histogram\n            counter(\"agent.requests_total\", \"Total number of agent requests\").inc()\n\n            # Execute with timing\n            with histogram(\"agent.execution_time\", \"Time to execute agent request\").time():\n                try:\n                    response = await super().run(prompt)\n\n                    # Record success\n                    counter(\"agent.success_total\", \"Successful agent requests\").inc()\n                    span.set_attribute(\"response.status\", \"success\")\n\n                    # Log information\n                    from fastadk.observability.logger import get_logger\n                    logger = get_logger()\n                    logger.info(\n                        \"Agent request successful\",\n                        extra={\n                            \"prompt_length\": len(prompt),\n                            \"response_length\": len(response),\n                            \"tools_used\": self.tools_used,\n                            \"token_count\": self.last_run_token_usage.total_tokens,\n                        }\n                    )\n\n                    return response\n                except Exception as e:\n                    # Record failure\n                    counter(\"agent.error_total\", \"Failed agent requests\").inc()\n                    span.set_attribute(\"response.status\", \"error\")\n                    span.set_attribute(\"error.type\", e.__class__.__name__)\n                    span.set_attribute(\"error.message\", str(e))\n\n                    # Log error\n                    from fastadk.observability.logger import get_logger\n                    logger = get_logger()\n                    logger.error(\n                        f\"Agent request failed: {str(e)}\",\n                        exc_info=True,\n                        extra={\"prompt_length\": len(prompt)}\n                    )\n\n                    raise\n</code></pre>"},{"location":"system-overview/#configuration-system","title":"Configuration System","text":"<p>FastADK uses a hierarchical configuration system that combines:</p> <ol> <li>Default values from the codebase</li> <li>Configuration files (YAML/TOML)</li> <li>Environment variables</li> <li>Runtime overrides</li> </ol> <p>This design enables flexible configuration across different environments, from development to production.</p> <pre><code>graph TD\n    A[Default Configuration] --&gt; E[Final Configuration]\n    B[Config Files] --&gt; E\n    C[Environment Variables] --&gt; E\n    D[Runtime Overrides] --&gt; E\n\n    subgraph \"Priority (Increasing)\"\n        A\n        B\n        C\n        D\n    end\n</code></pre>"},{"location":"system-overview/#configuration-example","title":"Configuration Example","text":"<pre><code># fastadk.yaml - Base configuration\nenvironment: development\nlog_level: info\n\nmodel:\n  provider: gemini\n  model_name: gemini-1.5-pro\n\nmemory:\n  backend_type: inmemory\n  ttl_seconds: 3600\n</code></pre> <pre><code># fastadk.production.yaml - Production overrides\nenvironment: production\nlog_level: warning\n\nmodel:\n  provider: openai\n  model_name: gpt-4\n\nmemory:\n  backend_type: redis\n  connection_string: ${REDIS_URL}\n</code></pre> <p>Environment variables can override any configuration:</p> <pre><code>export FASTADK_LOG_LEVEL=debug\nexport FASTADK_MODEL__PROVIDER=anthropic\nexport FASTADK_MODEL__MODEL_NAME=claude-3-opus-20240229\n</code></pre>"},{"location":"system-overview/#integration-options","title":"Integration Options","text":"<p>FastADK offers several integration patterns for different environments:</p>"},{"location":"system-overview/#1-standalone-scripts","title":"1. Standalone Scripts","text":"<p>For simple scripts, import and use agents directly:</p> <pre><code>from myagent import WeatherAgent\n\nasync def main():\n    agent = WeatherAgent()\n    result = await agent.run(\"What's the weather in Paris?\")\n    print(result)\n\nif __name__ == \"__main__\":\n    import asyncio\n    asyncio.run(main())\n</code></pre>"},{"location":"system-overview/#2-web-applications","title":"2. Web Applications","text":"<p>For web services, use the built-in FastAPI integration:</p> <pre><code>from fastapi import FastAPI\nfrom fastadk import create_app, registry\nfrom myagents import WeatherAgent, TranslationAgent\n\n# Register agents\nregistry.register(WeatherAgent)\nregistry.register(TranslationAgent)\n\n# Create FastAPI app with agents router\napp = create_app()\n\n# Add custom routes\n@app.get(\"/\")\ndef read_root():\n    return {\"message\": \"Welcome to FastADK API\"}\n</code></pre>"},{"location":"system-overview/#3-chatbots","title":"3. Chatbots","text":"<p>For chat platforms, use the adapter interfaces:</p> <pre><code>from fastadk.adapters.discord import DiscordAdapter\nfrom myagent import AssistantAgent\n\n# Connect agent to Discord\nadapter = DiscordAdapter(\n    agent=AssistantAgent(),\n    bot_token=\"DISCORD_BOT_TOKEN\",\n    guild_ids=[\"123456789\"],\n    channels=[\"general\", \"help\"]\n)\n\n# Start the bot\nif __name__ == \"__main__\":\n    import asyncio\n    asyncio.run(adapter.start())\n</code></pre>"},{"location":"system-overview/#4-batch-processing","title":"4. Batch Processing","text":"<p>For data processing workloads:</p> <pre><code>from fastadk.core.batch import BatchProcessor\nfrom myagent import DocumentProcessorAgent\n\n# Create batch processor\nprocessor = BatchProcessor(\n    agent=DocumentProcessorAgent(),\n    max_concurrent=10,\n    timeout=300\n)\n\n# Process batch of items\nasync def process_documents():\n    documents = [\n        {\"id\": \"doc1\", \"text\": \"Sample document 1\"},\n        {\"id\": \"doc2\", \"text\": \"Sample document 2\"},\n        # ...more documents\n    ]\n\n    results = await processor.process_batch(\n        items=documents,\n        process_fn=lambda doc: f\"Process document {doc['id']}: {doc['text']}\",\n        result_fn=lambda response, doc: {\"id\": doc[\"id\"], \"summary\": response}\n    )\n\n    return results\n</code></pre>"},{"location":"system-overview/#best-practices","title":"Best Practices","text":""},{"location":"system-overview/#1-agent-design","title":"1. Agent Design","text":"<ul> <li>Single Responsibility: Each agent should have a clear, focused purpose</li> <li>Tool Granularity: Create tools that do one thing well rather than monolithic tools</li> <li>Error Handling: Include error handling in tools and agent lifecycle hooks</li> <li>Documentation: Document tools thoroughly with clear descriptions and type hints</li> </ul>"},{"location":"system-overview/#2-performance-optimization","title":"2. Performance Optimization","text":"<ul> <li>Token Efficiency: Minimize tokens by using targeted prompts and context</li> <li>Caching: Use the caching system for repetitive operations</li> <li>Async Operations: Use async where possible to improve throughput</li> <li>Batching: Batch similar operations together</li> </ul>"},{"location":"system-overview/#3-testing-strategy","title":"3. Testing Strategy","text":"<ul> <li>Mock LLMs: Use <code>MockModel</code> for deterministic testing</li> <li>Scenario Testing: Create comprehensive test scenarios</li> <li>Integration Tests: Test full agent workflows end-to-end</li> <li>Performance Benchmarks: Monitor token usage and response times</li> </ul>"},{"location":"system-overview/#4-production-deployment","title":"4. Production Deployment","text":"<ul> <li>Observability: Enable structured logging, metrics, and tracing</li> <li>Health Checks: Implement health checks for agent services</li> <li>Rate Limiting: Protect against excessive usage</li> <li>Monitoring: Monitor token usage, costs, and performance</li> <li>CI/CD: Automate testing and deployment</li> </ul>"},{"location":"system-overview/#known-limitations-and-future-roadmap","title":"Known Limitations and Future Roadmap","text":""},{"location":"system-overview/#current-limitations","title":"Current Limitations","text":"<ul> <li>Tool Results Size: Large tool results may exceed context windows</li> <li>Streaming Consistency: Streaming behavior varies across providers</li> <li>Fine-Tuning Support: Limited to certain providers and models</li> <li>Cross-Agent Communication: Basic support for agent-to-agent communication</li> </ul>"},{"location":"system-overview/#roadmap","title":"Roadmap","text":"<ol> <li>Enhanced Vector Memory: More sophisticated retrieval algorithms</li> <li>Agentic Loops: Better support for recursive agent actions</li> <li>Automated Testing: AI-powered test generation</li> <li>Fine-Tuning UI: Visual interface for model customization</li> <li>Multi-Modal Support: Better handling of images, audio, and video</li> <li>Autonomous Agents: Long-running agents with planning capabilities</li> </ol>"},{"location":"system-overview/#conclusion","title":"Conclusion","text":"<p>FastADK provides a powerful, flexible, and developer-friendly framework for building AI agents. By abstracting away the complexities of agent development, it allows developers to focus on creating value rather than writing boilerplate code.</p> <p>The 0.2.0 release represents a significant step forward in capabilities, with comprehensive token tracking, advanced memory management, improved scalability, enhanced extensibility, better developer experience, and robust observability.</p> <p>Whether you're building a simple chatbot, a complex multi-agent system, or integrating AI capabilities into an existing application, FastADK provides the tools and patterns to make your development process faster, more reliable, and more enjoyable.</p>"},{"location":"system-overview/#next-steps","title":"Next Steps","text":"<ul> <li>Installation Guide: Get started with FastADK</li> <li>Quick Start: Build your first agent</li> <li>Examples: Explore real-world examples</li> <li>API Reference: Detailed documentation of the API</li> <li>Cookbook: Common patterns and recipes</li> </ul>"},{"location":"api/api/models/","title":"API Models Reference","text":"<p>This page documents the API models used in FastADK's HTTP API.</p>"},{"location":"api/api/models/#request-models","title":"Request Models","text":""},{"location":"api/api/models/#fastadk.api.models.AgentRequest","title":"<code>fastadk.api.models.AgentRequest</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Base model for agent API requests.</p> Source code in <code>src/fastadk/api/models.py</code> <pre><code>class AgentRequest(BaseModel):\n    \"\"\"Base model for agent API requests.\"\"\"\n\n    prompt: str = Field(..., description=\"The user's prompt or query for the agent\")\n    session_id: str | None = Field(\n        None, description=\"Session identifier for stateful conversations\"\n    )\n    options: dict[str, Any] = Field(\n        default_factory=dict, description=\"Additional options for the agent\"\n    )\n</code></pre>"},{"location":"api/api/models/#fastadk.api.models.AgentStreamRequest","title":"<code>fastadk.api.models.AgentStreamRequest</code>","text":"<p>               Bases: <code>AgentRequest</code></p> <p>Request model for streaming agent responses.</p> Source code in <code>src/fastadk/api/models.py</code> <pre><code>class AgentStreamRequest(AgentRequest):\n    \"\"\"Request model for streaming agent responses.\"\"\"\n\n    stream: bool = Field(True, description=\"Whether to stream the response\")\n</code></pre>"},{"location":"api/api/models/#fastadk.api.models.ToolRequest","title":"<code>fastadk.api.models.ToolRequest</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Request model for direct tool execution.</p> Source code in <code>src/fastadk/api/models.py</code> <pre><code>class ToolRequest(BaseModel):\n    \"\"\"Request model for direct tool execution.\"\"\"\n\n    tool_name: str = Field(..., description=\"Name of the tool to execute\")\n    parameters: dict[str, Any] = Field(\n        default_factory=dict, description=\"Parameters for the tool\"\n    )\n    session_id: str | None = Field(\n        None, description=\"Session identifier for stateful executions\"\n    )\n</code></pre>"},{"location":"api/api/models/#response-models","title":"Response Models","text":""},{"location":"api/api/models/#fastadk.api.models.AgentResponse","title":"<code>fastadk.api.models.AgentResponse</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Base model for agent API responses.</p> Source code in <code>src/fastadk/api/models.py</code> <pre><code>class AgentResponse(BaseModel):\n    \"\"\"Base model for agent API responses.\"\"\"\n\n    response: str = Field(..., description=\"The agent's response to the user\")\n    session_id: str = Field(\n        ..., description=\"Session identifier for stateful conversations\"\n    )\n    execution_time: float = Field(..., description=\"Execution time in seconds\")\n    tools_used: list[str] = Field(\n        default_factory=list, description=\"Tools used in processing this request\"\n    )\n    meta: dict[str, Any] = Field(\n        default_factory=dict, description=\"Additional metadata about the response\"\n    )\n</code></pre>"},{"location":"api/api/models/#fastadk.api.models.ToolResponse","title":"<code>fastadk.api.models.ToolResponse</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Response model for tool execution.</p> Source code in <code>src/fastadk/api/models.py</code> <pre><code>class ToolResponse(BaseModel):\n    \"\"\"Response model for tool execution.\"\"\"\n\n    tool_name: str = Field(..., description=\"Name of the tool that was executed\")\n    result: Any = Field(..., description=\"Result of the tool execution\")\n    execution_time: float = Field(..., description=\"Execution time in seconds\")\n    session_id: str | None = Field(\n        None, description=\"Session identifier for stateful executions\"\n    )\n</code></pre>"},{"location":"api/api/models/#fastadk.api.models.ErrorResponse","title":"<code>fastadk.api.models.ErrorResponse</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Error response model.</p> Source code in <code>src/fastadk/api/models.py</code> <pre><code>class ErrorResponse(BaseModel):\n    \"\"\"Error response model.\"\"\"\n\n    error: str = Field(..., description=\"Error message\")\n    error_type: str = Field(..., description=\"Type of error\")\n    status_code: int = Field(..., description=\"HTTP status code\")\n    details: dict[str, Any] = Field(\n        default_factory=dict, description=\"Additional error details\"\n    )\n</code></pre>"},{"location":"api/api/models/#tool-call-models","title":"Tool Call Models","text":""},{"location":"api/api/models/#fastadk.api.models.ToolCall","title":"<code>fastadk.api.models.ToolCall</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Model representing a tool call.</p> Source code in <code>src/fastadk/api/models.py</code> <pre><code>class ToolCall(BaseModel):\n    \"\"\"Model representing a tool call.\"\"\"\n\n    tool_name: str = Field(..., description=\"Name of the tool to call\")\n    parameters: dict[str, Any] = Field(\n        default_factory=dict, description=\"Parameters for the tool call\"\n    )\n    call_id: str = Field(..., description=\"Unique identifier for this tool call\")\n</code></pre>"},{"location":"api/api/models/#fastadk.api.models.ToolCallResult","title":"<code>fastadk.api.models.ToolCallResult</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Model representing the result of a tool call.</p> Source code in <code>src/fastadk/api/models.py</code> <pre><code>class ToolCallResult(BaseModel):\n    \"\"\"Model representing the result of a tool call.\"\"\"\n\n    tool_name: str = Field(..., description=\"Name of the tool that was called\")\n    result: Any = Field(..., description=\"Result of the tool call\")\n    call_id: str = Field(..., description=\"Identifier matching the original tool call\")\n    success: bool = Field(..., description=\"Whether the tool call was successful\")\n    error: str | None = Field(None, description=\"Error message if the call failed\")\n</code></pre>"},{"location":"api/api/models/#agent-information","title":"Agent Information","text":""},{"location":"api/api/models/#fastadk.api.models.AgentInfo","title":"<code>fastadk.api.models.AgentInfo</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Information about an agent.</p> Source code in <code>src/fastadk/api/models.py</code> <pre><code>class AgentInfo(BaseModel):\n    \"\"\"Information about an agent.\"\"\"\n\n    name: str = Field(..., description=\"Name of the agent\")\n    description: str = Field(..., description=\"Description of the agent\")\n    model: str = Field(..., description=\"The model used by the agent\")\n    provider: str = Field(..., description=\"The provider used by the agent\")\n    tools: list[dict[str, Any]] = Field(\n        default_factory=list, description=\"Tools available to the agent\"\n    )\n</code></pre>"},{"location":"api/api/models/#health-check","title":"Health Check","text":""},{"location":"api/api/models/#fastadk.api.models.HealthCheck","title":"<code>fastadk.api.models.HealthCheck</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Health check response.</p> Source code in <code>src/fastadk/api/models.py</code> <pre><code>class HealthCheck(BaseModel):\n    \"\"\"Health check response.\"\"\"\n\n    status: str = Field(..., description=\"Service status (ok, error)\")\n    version: str = Field(..., description=\"FastADK version\")\n    agents: int = Field(..., description=\"Number of registered agents\")\n    environment: str = Field(\n        ..., description=\"Current environment (development, production)\"\n    )\n    uptime: float = Field(..., description=\"Server uptime in seconds\")\n</code></pre>"},{"location":"api/api/models/#examples","title":"Examples","text":"<pre><code># Example of using the API models directly\nfrom fastadk.api.models import AgentRequest, AgentResponse\n\n# Create a request\nrequest = AgentRequest(\n    message=\"What's the weather in San Francisco?\",\n    session_id=\"user-123\",\n    parameters={\"temperature\": 0.7}\n)\n\n# Create a response\nresponse = AgentResponse(\n    message=\"The weather in San Francisco is currently 65\u00b0F and partly cloudy.\",\n    session_id=\"user-123\",\n    tools_used=[\"get_weather\"],\n    conversation_id=\"conv-456\"\n)\n</code></pre>"},{"location":"api/cli/main/","title":"CLI Reference","text":"<p>FastADK provides a command-line interface (CLI) for running agents, serving API endpoints, and managing your projects.</p>"},{"location":"api/cli/main/#main-commands","title":"Main Commands","text":""},{"location":"api/cli/main/#fastadk.cli.main.app","title":"<code>fastadk.cli.main.app = typer.Typer(name='fastadk', help='\ud83d\ude80 FastADK - The developer-friendly framework for building AI agents.', add_completion=False, no_args_is_help=True, pretty_exceptions_enable=False)</code>  <code>module-attribute</code>","text":""},{"location":"api/cli/main/#usage-examples","title":"Usage Examples","text":""},{"location":"api/cli/main/#running-an-agent","title":"Running an Agent","text":"<pre><code># Run an agent in interactive mode\nfastadk run weather_agent.py\n\n# Run with a specific agent class\nfastadk run multi_agent.py --agent-name WeatherAgent\n</code></pre>"},{"location":"api/cli/main/#serving-as-an-api","title":"Serving as an API","text":"<pre><code># Start an HTTP server with your agent\nfastadk serve weather_agent.py\n\n# Specify host and port\nfastadk serve weather_agent.py --host 0.0.0.0 --port 8080\n</code></pre>"},{"location":"api/cli/main/#getting-help","title":"Getting Help","text":"<pre><code># Display general help\nfastadk --help\n\n# Get help for a specific command\nfastadk run --help\n</code></pre>"},{"location":"api/cli/main/#environment-variables","title":"Environment Variables","text":"<p>The CLI respects the following environment variables:</p> Variable Description Default <code>FASTADK_ENV</code> Environment mode (development, production) development <code>FASTADK_LOG_LEVEL</code> Logging level INFO <code>FASTADK_CONFIG_PATH</code> Path to config file ./fastadk.yaml"},{"location":"api/core/agent/","title":"Agent API Reference","text":"<p>The Agent module is the core of FastADK, providing the main decorators and base classes for creating AI agents.</p>"},{"location":"api/core/agent/#agent-decorator","title":"Agent Decorator","text":""},{"location":"api/core/agent/#fastadk.core.agent.Agent","title":"<code>fastadk.core.agent.Agent(model='gemini-2.5-pro', description='', provider='gemini', **kwargs)</code>","text":"<pre><code>Agent(\n    model: str = ...,\n    description: str = ...,\n    provider: str = ...,\n    **kwargs: Any\n) -&gt; Callable[[type[C]], type[C]]\n</code></pre> <p>Decorator for creating FastADK agents.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>str</code> <p>The name of the model to use</p> <code>'gemini-2.5-pro'</code> <code>description</code> <code>str</code> <p>Description of the agent</p> <code>''</code> <code>provider</code> <code>str</code> <p>The provider to use (gemini, etc.)</p> <code>'gemini'</code> <code>**kwargs</code> <code>Any</code> <p>Additional configuration options</p> <code>{}</code> <p>Returns:</p> Type Description <code>Callable[[type[T]], type[T]]</code> <p>A decorator function that modifies the agent class</p> Source code in <code>src/fastadk/core/agent.py</code> <pre><code>def Agent(\n    model: str = \"gemini-2.5-pro\",\n    description: str = \"\",\n    provider: str = \"gemini\",\n    **kwargs: Any,\n) -&gt; Callable[[type[T]], type[T]]:\n    \"\"\"\n    Decorator for creating FastADK agents.\n\n    Args:\n        model: The name of the model to use\n        description: Description of the agent\n        provider: The provider to use (gemini, etc.)\n        **kwargs: Additional configuration options\n\n    Returns:\n        A decorator function that modifies the agent class\n    \"\"\"\n\n    def decorator(cls: type[T]) -&gt; type[T]:\n        # Store metadata on the class\n        # pylint: disable=protected-access\n        cls._model_name = model  # type: ignore\n        cls._description = description or cls.__doc__ or \"\"  # type: ignore\n        cls._provider = provider  # type: ignore\n\n        # Add any additional kwargs as class variables\n        for key, value in kwargs.items():\n            setattr(cls, f\"_{key}\", value)\n\n        # Register the agent class\n        if issubclass(\n            cls, BaseAgent\n        ):  # Make sure we only register BaseAgent subclasses\n            register_agent(cls)  # type: ignore\n\n        return cls\n\n    return decorator\n</code></pre>"},{"location":"api/core/agent/#tool-decorator","title":"Tool Decorator","text":""},{"location":"api/core/agent/#fastadk.core.agent.tool","title":"<code>fastadk.core.agent.tool(cache_ttl=0, timeout=30, retries=0, enabled=True, **kwargs)</code>","text":"<pre><code>tool(func: F) -&gt; F\n</code></pre><pre><code>tool(\n    *,\n    cache_ttl: int = ...,\n    timeout: int = ...,\n    retries: int = ...,\n    enabled: bool = ...,\n    **kwargs: Any\n) -&gt; Callable[[F], F]\n</code></pre> <p>Decorator for tool functions that can be used by agents.</p> <p>Parameters:</p> Name Type Description Default <code>cache_ttl</code> <code>int</code> <p>Time-to-live for cached results in seconds</p> <code>0</code> <code>timeout</code> <code>int</code> <p>Timeout in seconds</p> <code>30</code> <code>retries</code> <code>int</code> <p>Number of retries on failure</p> <code>0</code> <code>enabled</code> <code>bool</code> <p>Whether the tool is enabled</p> <code>True</code> <code>**kwargs</code> <code>Any</code> <p>Additional metadata for the tool</p> <code>{}</code> <p>Returns:</p> Type Description <code>Callable[[Callable[..., Any]], Callable[..., Any]]</code> <p>A decorator function that registers the tool</p> Source code in <code>src/fastadk/core/agent.py</code> <pre><code>def tool(\n    cache_ttl: int = 0,\n    timeout: int = 30,\n    retries: int = 0,\n    enabled: bool = True,\n    **kwargs: Any,\n) -&gt; Callable[[Callable[..., Any]], Callable[..., Any]]:\n    \"\"\"\n    Decorator for tool functions that can be used by agents.\n\n    Args:\n        cache_ttl: Time-to-live for cached results in seconds\n        timeout: Timeout in seconds\n        retries: Number of retries on failure\n        enabled: Whether the tool is enabled\n        **kwargs: Additional metadata for the tool\n\n    Returns:\n        A decorator function that registers the tool\n    \"\"\"\n    # Handle usage as @tool without parentheses\n    if callable(cache_ttl):\n        func = cache_ttl\n\n        # Create a decorator with default values and apply it\n        decorator_with_defaults = tool(cache_ttl=0, timeout=30, retries=0, enabled=True)\n        return decorator_with_defaults(func)\n\n    def decorator(func: Callable[..., Any]) -&gt; Callable[..., Any]:\n        # Get tool metadata from docstring and signature\n        description = func.__doc__ or \"\"\n        sig = inspect.signature(func)\n        parameters = {}\n        return_type = (\n            sig.return_annotation\n            if sig.return_annotation != inspect.Signature.empty\n            else None\n        )\n\n        # Process parameters\n        for param_name, param in sig.parameters.items():\n            if param_name == \"self\":\n                continue\n\n            param_type = (\n                param.annotation if param.annotation != inspect.Signature.empty else Any\n            )\n            parameters[param_name] = {\n                \"type\": param_type,\n                \"required\": param.default == inspect.Parameter.empty,\n            }\n\n        # Create tool metadata\n        tool_metadata = {\n            \"description\": description,\n            \"cache_ttl\": cache_ttl,\n            \"timeout\": timeout,\n            \"retries\": retries,\n            \"enabled\": enabled,\n            \"parameters\": parameters,\n            \"return_type\": return_type,\n        }\n        tool_metadata.update(kwargs)\n\n        # Store metadata on the function\n        # pylint: disable=protected-access\n        func._is_tool = True  # type: ignore\n        func._tool_metadata = tool_metadata  # type: ignore\n\n        # For standalone functions (not methods), register now\n        if not any(param.name == \"self\" for param in sig.parameters.values()):\n            # This is a standalone function, not a method\n            # Register it with the global registry\n            name = kwargs.get(\"name\", func.__name__)\n            BaseAgent._tools[name] = ToolMetadata(\n                name=name,\n                description=description,\n                function=func,\n                cache_ttl=cache_ttl,\n                timeout=timeout,\n                retries=retries,\n                enabled=enabled,\n                parameters=parameters,\n                return_type=return_type,\n            )\n\n        @functools.wraps(func)\n        def wrapper(*args: Any, **kwargs: Any) -&gt; Any:\n            # If this is the first time the method is called through the instance\n            # make sure it's registered in the instance's tools dictionary\n            if (\n                args\n                and hasattr(args[0], \"tool_manager\")\n                and isinstance(args[0], BaseAgent)\n            ):\n                self_obj = args[0]\n                method_name = func.__name__\n\n                # Register the method in the instance's tools if not already there\n                if method_name not in self_obj.tool_manager.tools:\n                    self_obj.tool_manager.register_tool(\n                        ToolMetadata(\n                            name=method_name,\n                            description=description,\n                            function=getattr(self_obj, func.__name__),\n                            cache_ttl=cache_ttl,\n                            timeout=timeout,\n                            retries=retries,\n                            enabled=enabled,\n                            parameters=parameters,\n                            return_type=return_type,\n                        )\n                    )\n\n            # Execute the original function\n            return func(*args, **kwargs)\n\n        return wrapper\n\n    return decorator\n</code></pre>"},{"location":"api/core/agent/#baseagent-class","title":"BaseAgent Class","text":""},{"location":"api/core/agent/#fastadk.core.agent.BaseAgent","title":"<code>fastadk.core.agent.BaseAgent</code>","text":"<p>Base class for all FastADK agents.</p> <p>This class provides the core functionality for agent creation, tool management, and execution.</p> Source code in <code>src/fastadk/core/agent.py</code> <pre><code>class BaseAgent:\n    \"\"\"\n    Base class for all FastADK agents.\n\n    This class provides the core functionality for agent creation,\n    tool management, and execution.\n    \"\"\"\n\n    # Class variables for storing agent metadata\n    _tools: ClassVar[dict[str, ToolMetadata]] = {}\n    _model_name: ClassVar[str] = \"gemini-2.5-pro\"\n    _description: ClassVar[str] = \"A FastADK agent\"\n    _provider: ClassVar[str] = \"gemini\"\n    _system_message: ClassVar[str | None] = None\n\n    def __init__(self) -&gt; None:\n        \"\"\"Initialize the agent with configuration settings.\"\"\"\n        self.settings = get_settings()\n        self.session_id: str | None = None\n        self.memory_data: dict[str, Any] = {}\n        self.last_response: str = \"\"\n        self.tools_used: List[str] = []  # For backward compatibility\n\n        # Initialize token budget if tracking is enabled\n        self.token_budget: Optional[TokenBudget] = None\n        # Access actual attributes on the settings objects, not the Field definitions\n        if getattr(self.settings.model, \"track_tokens\", False):\n            token_budget_settings = self.settings.token_budget\n            self.token_budget = TokenBudget(\n                max_tokens_per_request=getattr(\n                    token_budget_settings, \"max_tokens_per_request\", None\n                ),\n                max_tokens_per_session=getattr(\n                    token_budget_settings, \"max_tokens_per_session\", None\n                ),\n                max_cost_per_request=getattr(\n                    token_budget_settings, \"max_cost_per_request\", None\n                ),\n                max_cost_per_session=getattr(\n                    token_budget_settings, \"max_cost_per_session\", None\n                ),\n                warn_at_percent=getattr(token_budget_settings, \"warn_at_percent\", 80.0),\n            )\n\n        # Create tool manager and initialize tools\n        self.tool_manager = ToolManager(self)\n        self._initialize_tools()\n\n        # For backward compatibility\n        self.tools = self.tool_manager.tools\n\n        # Initialize model provider\n        self._initialize_provider()\n\n        # Initialize plugins\n        self.plugin_manager = default_plugin_manager\n        self._active_plugins: Dict[str, Plugin] = {}\n        self._initialize_plugins()\n\n        logger.info(\n            \"Initialized agent %s with %d tools\",\n            self.__class__.__name__,\n            len(self.tool_manager.tools),\n        )\n\n        # Emit agent initialized event - ensure event loop is running or handle gracefully\n        try:\n            # Get running event loop and create task\n            asyncio.get_running_loop()\n            asyncio.create_task(\n                self.plugin_manager.emit_event(\n                    \"agent:initialized\",\n                    {\"agent\": self, \"agent_class\": self.__class__.__name__},\n                )\n            )\n        except RuntimeError:\n            # No running event loop, log this but don't fail initialization\n            logger.debug(\n                \"No running event loop for agent initialization event. This is normal in test environments.\"\n            )\n\n    def _initialize_tools(self) -&gt; None:\n        \"\"\"Initialize tools from class metadata and instance methods.\"\"\"\n        # First, register any class-level tools\n        if self._tools:\n            self.tool_manager.register_tools(self._tools)\n\n        # Add any instance methods decorated as tools\n        for name, method in inspect.getmembers(self, inspect.ismethod):\n            # pylint: disable=protected-access\n            if hasattr(method, \"_is_tool\") and method._is_tool:\n                metadata = getattr(method, \"_tool_metadata\", {})\n                self.tool_manager.register_tool(\n                    ToolMetadata(\n                        name=name,\n                        description=metadata.get(\"description\", method.__doc__ or \"\"),\n                        function=method,\n                        cache_ttl=metadata.get(\"cache_ttl\", 0),\n                        timeout=metadata.get(\"timeout\", 30),\n                        retries=metadata.get(\"retries\", 0),\n                        enabled=metadata.get(\"enabled\", True),\n                        parameters=metadata.get(\"parameters\", {}),\n                        return_type=metadata.get(\"return_type\", None),\n                    )\n                )\n\n    def _initialize_plugins(self) -&gt; None:\n        \"\"\"Initialize plugins for this agent.\"\"\"\n        # Check if the class supports plugins\n        supported_plugins = get_supported_plugins(self.__class__)\n\n        for plugin_class in supported_plugins:\n            try:\n                # Create plugin instance\n                plugin = plugin_class()\n\n                # Register the plugin\n                asyncio.create_task(\n                    self.plugin_manager.register_plugin_instance(plugin)\n                )\n\n                # Store for direct access\n                self._active_plugins[plugin.name] = plugin\n\n                # For agent-specific plugins, call the enhancement method\n                if isinstance(plugin, AgentPlugin):\n                    asyncio.create_task(plugin.on_agent_initialized(self))\n\n                logger.info(\n                    \"Initialized plugin %s for agent %s\",\n                    plugin.name,\n                    self.__class__.__name__,\n                )\n            except Exception as e:\n                logger.error(\n                    \"Error initializing plugin %s: %s\", plugin_class.__name__, str(e)\n                )\n\n    def register_plugin(self, plugin: Plugin) -&gt; None:\n        \"\"\"\n        Register a plugin with this agent.\n\n        Args:\n            plugin: The plugin to register\n        \"\"\"\n        if plugin.name in self._active_plugins:\n            logger.warning(\n                \"Plugin %s already registered with agent %s\",\n                plugin.name,\n                self.__class__.__name__,\n            )\n            return\n\n        # Register with plugin manager\n        asyncio.create_task(self.plugin_manager.register_plugin_instance(plugin))\n\n        # Store for direct access\n        self._active_plugins[plugin.name] = plugin\n\n        # For agent-specific plugins, call the enhancement method\n        if isinstance(plugin, AgentPlugin):\n            asyncio.create_task(plugin.on_agent_initialized(self))\n\n        logger.info(\n            \"Registered plugin %s with agent %s\", plugin.name, self.__class__.__name__\n        )\n\n    def _initialize_provider(self) -&gt; None:\n        \"\"\"Initialize the model provider based on configuration.\"\"\"\n        try:\n            # Create provider configuration\n            provider_config = {\n                \"model\": self._model_name,\n                \"system_message\": self._system_message,\n            }\n\n            # Create the provider instance using the factory\n            self.provider = ProviderFactory.create(self._provider, provider_config)\n\n            # Initialize the provider (will be done asynchronously on first run)\n            logger.info(\n                \"Provider %s registered for model %s\", self._provider, self._model_name\n            )\n        except Exception as exc:\n            logger.error(\"Failed to initialize provider: %s\", str(exc), exc_info=True)\n            raise ConfigurationError(f\"Failed to initialize provider: {exc}\") from exc\n\n    async def run(self, user_input: str) -&gt; str:\n        \"\"\"\n        Run the agent with the given user input.\n\n        This method processes the user input, potentially executes tools,\n        and returns a response from the agent.\n\n        Args:\n            user_input: The user's input message\n\n        Returns:\n            The agent's response as a string\n        \"\"\"\n        start_time = time.time()\n        self.tool_manager.reset()  # Reset tools used for this run\n\n        # Emit agent:run_started event\n        await self.plugin_manager.emit_event(\n            \"agent:run_started\",\n            {\n                \"agent\": self,\n                \"agent_class\": self.__class__.__name__,\n                \"input\": user_input,\n                \"timestamp\": start_time,\n            },\n        )\n\n        try:\n            # Call the on_start hook\n            self.on_start()\n\n            # Initialize the provider if needed\n            await self._ensure_provider_initialized()\n\n            # Generate response from the model\n            response = await self._generate_response(user_input)\n\n            # Call the on_finish hook\n            self.on_finish(response)\n\n            # Log execution time\n            execution_time = time.time() - start_time\n            logger.info(\"Agent execution completed in %.2fs\", execution_time)\n\n            # Emit agent:run_completed event\n            await self.plugin_manager.emit_event(\n                \"agent:run_completed\",\n                {\n                    \"agent\": self,\n                    \"agent_class\": self.__class__.__name__,\n                    \"input\": user_input,\n                    \"response\": response,\n                    \"duration\": execution_time,\n                    \"success\": True,\n                    \"timestamp\": time.time(),\n                },\n            )\n\n            return response\n        except Exception as exc:\n            # Call the on_error hook\n            self.on_error(exc)\n\n            execution_time = time.time() - start_time\n\n            # Emit agent:run_error event\n            await self.plugin_manager.emit_event(\n                \"agent:run_error\",\n                {\n                    \"agent\": self,\n                    \"agent_class\": self.__class__.__name__,\n                    \"input\": user_input,\n                    \"error\": str(exc),\n                    \"duration\": execution_time,\n                    \"timestamp\": time.time(),\n                },\n            )\n\n            logger.error(\"Error during agent execution: %s\", str(exc), exc_info=True)\n            raise AgentError(f\"Failed to process input: {exc}\") from exc\n\n    async def _ensure_provider_initialized(self) -&gt; None:\n        \"\"\"Ensure the provider is initialized.\"\"\"\n        try:\n            # Create a configuration dict for the provider\n            config = {\n                \"model\": self._model_name,\n                \"system_message\": self._system_message,\n            }\n\n            # Add any model-specific configuration from settings\n            if hasattr(self.settings, \"model\"):\n                model_settings = getattr(self.settings, \"model\", {})\n                for key, value in model_settings.__dict__.items():\n                    if key.startswith(\"_\"):\n                        continue\n                    config[key] = value\n\n            # Initialize the provider\n            await self.provider.initialize(config)\n        except Exception as exc:\n            logger.error(\"Failed to initialize provider: %s\", str(exc), exc_info=True)\n            raise ConfigurationError(f\"Failed to initialize provider: {exc}\") from exc\n\n    async def _generate_response(self, user_input: str) -&gt; str:\n        \"\"\"Generate a response from the model.\"\"\"\n        try:\n            # Check cache for this prompt if caching is enabled\n            cache_response = await self._check_cache(user_input)\n            if cache_response:\n                logger.info(\"Using cached response for input\")\n                self.last_response = cache_response\n                return cache_response\n\n            # Prepare messages for the provider\n            messages = self._prepare_messages(user_input)\n\n            # Set generation options\n            options = GenerateOptions(\n                temperature=getattr(self.settings.model, \"temperature\", 0.7),\n                max_tokens=getattr(self.settings.model, \"max_tokens\", 1000),\n                top_p=getattr(self.settings.model, \"top_p\", None),\n                top_k=getattr(self.settings.model, \"top_k\", None),\n                stop_sequences=getattr(self.settings.model, \"stop_sequences\", None),\n            )\n\n            # Emit LLM request event\n            start_time = time.time()\n            await self.plugin_manager.emit_event(\n                \"llm:request\",\n                {\n                    \"agent\": self,\n                    \"agent_class\": self.__class__.__name__,\n                    \"model\": self._model_name,\n                    \"provider\": self._provider,\n                    \"temperature\": options.temperature,\n                    \"max_tokens\": options.max_tokens,\n                    \"messages\": [msg.dict() for msg in messages],\n                    \"timestamp\": start_time,\n                },\n            )\n\n            # Generate response\n            result = await self.provider.generate(messages, options)\n            response_text = result.text\n\n            # Emit LLM response event\n            duration = time.time() - start_time\n            await self.plugin_manager.emit_event(\n                \"llm:response\",\n                {\n                    \"agent\": self,\n                    \"agent_class\": self.__class__.__name__,\n                    \"model\": self._model_name,\n                    \"provider\": self._provider,\n                    \"tokens\": result.prompt_tokens + result.completion_tokens,\n                    \"prompt_tokens\": result.prompt_tokens,\n                    \"completion_tokens\": result.completion_tokens,\n                    \"duration\": duration,\n                    \"timestamp\": time.time(),\n                },\n            )\n\n            # Track token usage if enabled\n            if (\n                getattr(self.settings.model, \"track_tokens\", False)\n                and self.token_budget\n            ):\n                custom_price = getattr(self.settings.model, \"custom_price_per_1k\", {})\n                # Convert GenerateResult to TokenUsage for tracking\n                from ..tokens.models import TokenUsage\n\n                token_usage = TokenUsage(\n                    prompt_tokens=result.prompt_tokens,\n                    completion_tokens=result.completion_tokens,\n                    model=self._model_name,\n                    provider=self._provider,\n                )\n\n                track_token_usage(token_usage, self.token_budget, custom_price)\n\n            # Cache the response\n            await self._cache_response(user_input, response_text)\n\n            # Store the response for potential tool skipping logic\n            self.last_response = response_text\n            return response_text\n        except Exception as exc:\n            logger.error(\"Error generating response: %s\", str(exc), exc_info=True)\n            raise AgentError(f\"Failed to generate response: {exc}\") from exc\n\n    def _prepare_messages(self, user_input: str) -&gt; List[Message]:\n        \"\"\"\n        Prepare messages for the provider.\n\n        Args:\n            user_input: The user's input message\n\n        Returns:\n            List of messages ready for the provider\n        \"\"\"\n        messages = []\n\n        # Add system message if available\n        if self._system_message:\n            messages.append(Message(role=\"system\", content=self._system_message))\n\n        # Add user message\n        messages.append(Message(role=\"user\", content=user_input))\n\n        return messages\n\n    async def _check_cache(self, user_input: str) -&gt; str | None:\n        \"\"\"\n        Check if we have a cached response for this input.\n\n        Args:\n            user_input: The user's input message\n\n        Returns:\n            Cached response if available, None otherwise\n        \"\"\"\n        try:\n            from .cache import default_cache_manager\n\n            # Only use cache if enabled for this model\n            cache_ttl = getattr(self.settings.model, \"response_cache_ttl\", 0)\n            if cache_ttl &lt;= 0:\n                return None\n\n            # Create a cache key from the model, provider, and input\n            cache_key = {\n                \"model\": self._model_name,\n                \"provider\": self._provider,\n                \"input\": user_input,\n            }\n\n            # Try to get from cache\n            cached_response = await default_cache_manager.get(cache_key)\n            return cached_response\n        except Exception as exc:\n            # Log but don't fail if cache check fails\n            logger.warning(\"Error checking cache: %s\", str(exc))\n            return None\n\n    async def _cache_response(self, user_input: str, response: str) -&gt; None:\n        \"\"\"\n        Cache a response for future use.\n\n        Args:\n            user_input: The user's input message\n            response: The model's response\n        \"\"\"\n        try:\n            from .cache import default_cache_manager\n\n            # Only cache if enabled for this model\n            cache_ttl = getattr(self.settings.model, \"response_cache_ttl\", 0)\n            if cache_ttl &lt;= 0:\n                return\n\n            # Create a cache key from the model, provider, and input\n            cache_key = {\n                \"model\": self._model_name,\n                \"provider\": self._provider,\n                \"input\": user_input,\n            }\n\n            # Cache the response\n            await default_cache_manager.set(cache_key, response, ttl=cache_ttl)\n        except Exception as exc:\n            # Log but don't fail if caching fails\n            logger.warning(\"Error caching response: %s\", str(exc))\n\n    async def execute_tool(\n        self,\n        tool_name: str,\n        skip_if_response_contains: list[str] | None = None,\n        **kwargs: Any,\n    ) -&gt; Any:\n        \"\"\"\n        Execute a tool by name with the given arguments.\n\n        Args:\n            tool_name: The name of the tool to execute\n            skip_if_response_contains: List of strings that, if found in the LLM response,\n                                        indicate the tool call can be skipped\n            **kwargs: Arguments to pass to the tool\n\n        Returns:\n            The result of the tool execution or a message indicating the tool was skipped\n        \"\"\"\n        # Emit tool called event\n        start_time = time.time()\n        await self.plugin_manager.emit_event(\n            \"tool:called\",\n            {\n                \"agent\": self,\n                \"agent_class\": self.__class__.__name__,\n                \"tool_name\": tool_name,\n                \"args\": kwargs,\n                \"timestamp\": start_time,\n            },\n        )\n\n        success = True\n        result = None\n\n        try:\n            # Delegate to the tool manager\n            result = await self.tool_manager.execute_tool(\n                tool_name, skip_if_response_contains, **kwargs\n            )\n\n            # For backward compatibility\n            if (\n                tool_name not in self.tools_used\n                and tool_name in self.tool_manager.tools_used\n            ):\n                self.tools_used.append(tool_name)\n        except Exception as e:\n            success = False\n            # Re-raise the exception\n            raise e\n        finally:\n            # Calculate duration\n            duration = time.time() - start_time\n\n            # Emit tool completed event\n            await self.plugin_manager.emit_event(\n                \"tool:completed\",\n                {\n                    \"agent\": self,\n                    \"agent_class\": self.__class__.__name__,\n                    \"tool_name\": tool_name,\n                    \"duration\": duration,\n                    \"success\": success,\n                    \"timestamp\": time.time(),\n                },\n            )\n\n        return result\n\n    def on_start(self) -&gt; None:\n        \"\"\"Hook called when the agent starts processing a request.\"\"\"\n\n    def on_finish(self, result: str) -&gt; None:\n        \"\"\"Hook called when the agent finishes processing a request.\"\"\"\n\n    def on_error(self, error: Exception) -&gt; None:\n        \"\"\"Hook called when the agent encounters an error.\"\"\"\n\n    def reset_token_budget(self) -&gt; None:\n        \"\"\"Reset the token budget session counters.\"\"\"\n        if self.token_budget:\n            self.token_budget.reset_session()\n            logger.info(\"Token budget session counters reset\")\n\n    def get_token_usage_stats(self) -&gt; Dict[str, Any]:\n        \"\"\"Get the current token usage statistics.\"\"\"\n        if self.token_budget:\n            return {\n                \"session_tokens_used\": self.token_budget.session_tokens_used,\n                \"session_cost\": self.token_budget.session_cost,\n                \"has_request_limit\": self.token_budget.max_tokens_per_request\n                is not None,\n                \"has_session_limit\": self.token_budget.max_tokens_per_session\n                is not None,\n                \"has_cost_limit\": (\n                    self.token_budget.max_cost_per_request is not None\n                    or self.token_budget.max_cost_per_session is not None\n                ),\n            }\n        return {\"token_tracking_enabled\": False}\n</code></pre>"},{"location":"api/core/agent/#fastadk.core.agent.BaseAgent.__init__","title":"<code>__init__()</code>","text":"<p>Initialize the agent with configuration settings.</p> Source code in <code>src/fastadk/core/agent.py</code> <pre><code>def __init__(self) -&gt; None:\n    \"\"\"Initialize the agent with configuration settings.\"\"\"\n    self.settings = get_settings()\n    self.session_id: str | None = None\n    self.memory_data: dict[str, Any] = {}\n    self.last_response: str = \"\"\n    self.tools_used: List[str] = []  # For backward compatibility\n\n    # Initialize token budget if tracking is enabled\n    self.token_budget: Optional[TokenBudget] = None\n    # Access actual attributes on the settings objects, not the Field definitions\n    if getattr(self.settings.model, \"track_tokens\", False):\n        token_budget_settings = self.settings.token_budget\n        self.token_budget = TokenBudget(\n            max_tokens_per_request=getattr(\n                token_budget_settings, \"max_tokens_per_request\", None\n            ),\n            max_tokens_per_session=getattr(\n                token_budget_settings, \"max_tokens_per_session\", None\n            ),\n            max_cost_per_request=getattr(\n                token_budget_settings, \"max_cost_per_request\", None\n            ),\n            max_cost_per_session=getattr(\n                token_budget_settings, \"max_cost_per_session\", None\n            ),\n            warn_at_percent=getattr(token_budget_settings, \"warn_at_percent\", 80.0),\n        )\n\n    # Create tool manager and initialize tools\n    self.tool_manager = ToolManager(self)\n    self._initialize_tools()\n\n    # For backward compatibility\n    self.tools = self.tool_manager.tools\n\n    # Initialize model provider\n    self._initialize_provider()\n\n    # Initialize plugins\n    self.plugin_manager = default_plugin_manager\n    self._active_plugins: Dict[str, Plugin] = {}\n    self._initialize_plugins()\n\n    logger.info(\n        \"Initialized agent %s with %d tools\",\n        self.__class__.__name__,\n        len(self.tool_manager.tools),\n    )\n\n    # Emit agent initialized event - ensure event loop is running or handle gracefully\n    try:\n        # Get running event loop and create task\n        asyncio.get_running_loop()\n        asyncio.create_task(\n            self.plugin_manager.emit_event(\n                \"agent:initialized\",\n                {\"agent\": self, \"agent_class\": self.__class__.__name__},\n            )\n        )\n    except RuntimeError:\n        # No running event loop, log this but don't fail initialization\n        logger.debug(\n            \"No running event loop for agent initialization event. This is normal in test environments.\"\n        )\n</code></pre>"},{"location":"api/core/agent/#fastadk.core.agent.BaseAgent.execute_tool","title":"<code>execute_tool(tool_name, skip_if_response_contains=None, **kwargs)</code>  <code>async</code>","text":"<p>Execute a tool by name with the given arguments.</p> <p>Parameters:</p> Name Type Description Default <code>tool_name</code> <code>str</code> <p>The name of the tool to execute</p> required <code>skip_if_response_contains</code> <code>list[str] | None</code> <p>List of strings that, if found in the LLM response,                         indicate the tool call can be skipped</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Arguments to pass to the tool</p> <code>{}</code> <p>Returns:</p> Type Description <code>Any</code> <p>The result of the tool execution or a message indicating the tool was skipped</p> Source code in <code>src/fastadk/core/agent.py</code> <pre><code>async def execute_tool(\n    self,\n    tool_name: str,\n    skip_if_response_contains: list[str] | None = None,\n    **kwargs: Any,\n) -&gt; Any:\n    \"\"\"\n    Execute a tool by name with the given arguments.\n\n    Args:\n        tool_name: The name of the tool to execute\n        skip_if_response_contains: List of strings that, if found in the LLM response,\n                                    indicate the tool call can be skipped\n        **kwargs: Arguments to pass to the tool\n\n    Returns:\n        The result of the tool execution or a message indicating the tool was skipped\n    \"\"\"\n    # Emit tool called event\n    start_time = time.time()\n    await self.plugin_manager.emit_event(\n        \"tool:called\",\n        {\n            \"agent\": self,\n            \"agent_class\": self.__class__.__name__,\n            \"tool_name\": tool_name,\n            \"args\": kwargs,\n            \"timestamp\": start_time,\n        },\n    )\n\n    success = True\n    result = None\n\n    try:\n        # Delegate to the tool manager\n        result = await self.tool_manager.execute_tool(\n            tool_name, skip_if_response_contains, **kwargs\n        )\n\n        # For backward compatibility\n        if (\n            tool_name not in self.tools_used\n            and tool_name in self.tool_manager.tools_used\n        ):\n            self.tools_used.append(tool_name)\n    except Exception as e:\n        success = False\n        # Re-raise the exception\n        raise e\n    finally:\n        # Calculate duration\n        duration = time.time() - start_time\n\n        # Emit tool completed event\n        await self.plugin_manager.emit_event(\n            \"tool:completed\",\n            {\n                \"agent\": self,\n                \"agent_class\": self.__class__.__name__,\n                \"tool_name\": tool_name,\n                \"duration\": duration,\n                \"success\": success,\n                \"timestamp\": time.time(),\n            },\n        )\n\n    return result\n</code></pre>"},{"location":"api/core/agent/#fastadk.core.agent.BaseAgent.get_token_usage_stats","title":"<code>get_token_usage_stats()</code>","text":"<p>Get the current token usage statistics.</p> Source code in <code>src/fastadk/core/agent.py</code> <pre><code>def get_token_usage_stats(self) -&gt; Dict[str, Any]:\n    \"\"\"Get the current token usage statistics.\"\"\"\n    if self.token_budget:\n        return {\n            \"session_tokens_used\": self.token_budget.session_tokens_used,\n            \"session_cost\": self.token_budget.session_cost,\n            \"has_request_limit\": self.token_budget.max_tokens_per_request\n            is not None,\n            \"has_session_limit\": self.token_budget.max_tokens_per_session\n            is not None,\n            \"has_cost_limit\": (\n                self.token_budget.max_cost_per_request is not None\n                or self.token_budget.max_cost_per_session is not None\n            ),\n        }\n    return {\"token_tracking_enabled\": False}\n</code></pre>"},{"location":"api/core/agent/#fastadk.core.agent.BaseAgent.on_error","title":"<code>on_error(error)</code>","text":"<p>Hook called when the agent encounters an error.</p> Source code in <code>src/fastadk/core/agent.py</code> <pre><code>def on_error(self, error: Exception) -&gt; None:\n    \"\"\"Hook called when the agent encounters an error.\"\"\"\n</code></pre>"},{"location":"api/core/agent/#fastadk.core.agent.BaseAgent.on_finish","title":"<code>on_finish(result)</code>","text":"<p>Hook called when the agent finishes processing a request.</p> Source code in <code>src/fastadk/core/agent.py</code> <pre><code>def on_finish(self, result: str) -&gt; None:\n    \"\"\"Hook called when the agent finishes processing a request.\"\"\"\n</code></pre>"},{"location":"api/core/agent/#fastadk.core.agent.BaseAgent.on_start","title":"<code>on_start()</code>","text":"<p>Hook called when the agent starts processing a request.</p> Source code in <code>src/fastadk/core/agent.py</code> <pre><code>def on_start(self) -&gt; None:\n    \"\"\"Hook called when the agent starts processing a request.\"\"\"\n</code></pre>"},{"location":"api/core/agent/#fastadk.core.agent.BaseAgent.register_plugin","title":"<code>register_plugin(plugin)</code>","text":"<p>Register a plugin with this agent.</p> <p>Parameters:</p> Name Type Description Default <code>plugin</code> <code>Plugin</code> <p>The plugin to register</p> required Source code in <code>src/fastadk/core/agent.py</code> <pre><code>def register_plugin(self, plugin: Plugin) -&gt; None:\n    \"\"\"\n    Register a plugin with this agent.\n\n    Args:\n        plugin: The plugin to register\n    \"\"\"\n    if plugin.name in self._active_plugins:\n        logger.warning(\n            \"Plugin %s already registered with agent %s\",\n            plugin.name,\n            self.__class__.__name__,\n        )\n        return\n\n    # Register with plugin manager\n    asyncio.create_task(self.plugin_manager.register_plugin_instance(plugin))\n\n    # Store for direct access\n    self._active_plugins[plugin.name] = plugin\n\n    # For agent-specific plugins, call the enhancement method\n    if isinstance(plugin, AgentPlugin):\n        asyncio.create_task(plugin.on_agent_initialized(self))\n\n    logger.info(\n        \"Registered plugin %s with agent %s\", plugin.name, self.__class__.__name__\n    )\n</code></pre>"},{"location":"api/core/agent/#fastadk.core.agent.BaseAgent.reset_token_budget","title":"<code>reset_token_budget()</code>","text":"<p>Reset the token budget session counters.</p> Source code in <code>src/fastadk/core/agent.py</code> <pre><code>def reset_token_budget(self) -&gt; None:\n    \"\"\"Reset the token budget session counters.\"\"\"\n    if self.token_budget:\n        self.token_budget.reset_session()\n        logger.info(\"Token budget session counters reset\")\n</code></pre>"},{"location":"api/core/agent/#fastadk.core.agent.BaseAgent.run","title":"<code>run(user_input)</code>  <code>async</code>","text":"<p>Run the agent with the given user input.</p> <p>This method processes the user input, potentially executes tools, and returns a response from the agent.</p> <p>Parameters:</p> Name Type Description Default <code>user_input</code> <code>str</code> <p>The user's input message</p> required <p>Returns:</p> Type Description <code>str</code> <p>The agent's response as a string</p> Source code in <code>src/fastadk/core/agent.py</code> <pre><code>async def run(self, user_input: str) -&gt; str:\n    \"\"\"\n    Run the agent with the given user input.\n\n    This method processes the user input, potentially executes tools,\n    and returns a response from the agent.\n\n    Args:\n        user_input: The user's input message\n\n    Returns:\n        The agent's response as a string\n    \"\"\"\n    start_time = time.time()\n    self.tool_manager.reset()  # Reset tools used for this run\n\n    # Emit agent:run_started event\n    await self.plugin_manager.emit_event(\n        \"agent:run_started\",\n        {\n            \"agent\": self,\n            \"agent_class\": self.__class__.__name__,\n            \"input\": user_input,\n            \"timestamp\": start_time,\n        },\n    )\n\n    try:\n        # Call the on_start hook\n        self.on_start()\n\n        # Initialize the provider if needed\n        await self._ensure_provider_initialized()\n\n        # Generate response from the model\n        response = await self._generate_response(user_input)\n\n        # Call the on_finish hook\n        self.on_finish(response)\n\n        # Log execution time\n        execution_time = time.time() - start_time\n        logger.info(\"Agent execution completed in %.2fs\", execution_time)\n\n        # Emit agent:run_completed event\n        await self.plugin_manager.emit_event(\n            \"agent:run_completed\",\n            {\n                \"agent\": self,\n                \"agent_class\": self.__class__.__name__,\n                \"input\": user_input,\n                \"response\": response,\n                \"duration\": execution_time,\n                \"success\": True,\n                \"timestamp\": time.time(),\n            },\n        )\n\n        return response\n    except Exception as exc:\n        # Call the on_error hook\n        self.on_error(exc)\n\n        execution_time = time.time() - start_time\n\n        # Emit agent:run_error event\n        await self.plugin_manager.emit_event(\n            \"agent:run_error\",\n            {\n                \"agent\": self,\n                \"agent_class\": self.__class__.__name__,\n                \"input\": user_input,\n                \"error\": str(exc),\n                \"duration\": execution_time,\n                \"timestamp\": time.time(),\n            },\n        )\n\n        logger.error(\"Error during agent execution: %s\", str(exc), exc_info=True)\n        raise AgentError(f\"Failed to process input: {exc}\") from exc\n</code></pre>"},{"location":"api/core/agent/#usage-examples","title":"Usage Examples","text":""},{"location":"api/core/agent/#basic-agent","title":"Basic Agent","text":"<pre><code>from fastadk.core import Agent, BaseAgent, tool\n\n@Agent(model=\"gemini-2.0-pro\")\nclass SimpleAgent(BaseAgent):\n    @tool\n    def greet(self, name: str) -&gt; str:\n        \"\"\"Greet a person by name.\"\"\"\n        return f\"Hello, {name}!\"\n</code></pre>"},{"location":"api/core/agent/#advanced-agent-configuration","title":"Advanced Agent Configuration","text":"<pre><code>@Agent(\n    model=\"gemini-2.0-pro\", \n    description=\"Advanced agent with configuration\",\n    max_tokens=1024,\n    temperature=0.7,\n    top_p=0.95,\n    max_retries=3,\n    memory_backend=\"redis\",\n    memory_ttl=3600,  # 1 hour\n    cache_enabled=True\n)\nclass AdvancedAgent(BaseAgent):\n    # Agent tools and methods...\n    pass\n</code></pre>"},{"location":"api/core/agent/#tool-configuration","title":"Tool Configuration","text":"<pre><code>@Agent(model=\"gemini-2.0-pro\")\nclass ToolConfigAgent(BaseAgent):\n    @tool\n    def simple_tool(self, param: str) -&gt; str:\n        \"\"\"Basic tool without special configuration.\"\"\"\n        return f\"Processed: {param}\"\n\n    @tool(\n        cache_ttl=300,  # Cache results for 5 minutes\n        timeout=10,     # Timeout after 10 seconds\n        retries=3,      # Retry up to 3 times on failure\n        retry_delay=1   # Wait 1 second between retries\n    )\n    def advanced_tool(self, param: str) -&gt; str:\n        \"\"\"Tool with caching, timeout, and retry configuration.\"\"\"\n        return f\"Advanced processing: {param}\"\n</code></pre>"},{"location":"api/core/agent/#lifecycle-methods","title":"Lifecycle Methods","text":"<pre><code>@Agent(model=\"gemini-2.0-pro\")\nclass LifecycleAgent(BaseAgent):\n    def on_initialize(self) -&gt; None:\n        \"\"\"Called when the agent is initialized.\"\"\"\n        self.logger.info(\"Agent initialized\")\n        self.setup_counter = 0\n\n    def on_message(self, message: str) -&gt; None:\n        \"\"\"Called before processing each message.\"\"\"\n        self.setup_counter += 1\n        self.logger.info(f\"Processing message. Counter: {self.setup_counter}\")\n\n    def on_finish(self, result: Any) -&gt; None:\n        \"\"\"Called after processing completes.\"\"\"\n        self.logger.info(f\"Processing finished with result: {result}\")\n</code></pre>"},{"location":"api/core/agent/#api-details","title":"API Details","text":""},{"location":"api/core/agent/#agent-parameters","title":"Agent Parameters","text":"Parameter Type Description <code>model</code> <code>str</code> The LLM model to use, e.g., \"gemini-2.0-pro\" <code>description</code> <code>str</code> A description of the agent's purpose <code>max_tokens</code> <code>int</code> Maximum tokens in the response <code>temperature</code> <code>float</code> Temperature for sampling (0.0-1.0) <code>top_p</code> <code>float</code> Nucleus sampling parameter (0.0-1.0) <code>top_k</code> <code>int</code> Top-k sampling parameter <code>max_retries</code> <code>int</code> Maximum LLM API call retries <code>memory_backend</code> <code>str</code> Memory backend type (\"inmemory\", \"redis\") <code>memory_ttl</code> <code>int</code> Time-to-live for memory entries in seconds <code>cache_enabled</code> <code>bool</code> Enable tool response caching <code>provider</code> <code>str</code> Backend provider (\"adk\", \"langchain\")"},{"location":"api/core/agent/#tool-parameters","title":"Tool Parameters","text":"Parameter Type Description <code>name</code> <code>str</code> Custom name for the tool (defaults to function name) <code>description</code> <code>str</code> Custom description (defaults to docstring) <code>cache_ttl</code> <code>int</code> Time-to-live for cached results in seconds <code>timeout</code> <code>float</code> Maximum execution time in seconds <code>retries</code> <code>int</code> Number of retry attempts on failure <code>retry_delay</code> <code>float</code> Initial delay between retries in seconds <code>enabled</code> <code>bool</code> Whether the tool is enabled"},{"location":"api/memory/base/","title":"Memory Base Classes","text":"<p>FastADK provides a flexible memory system with various backend options. This page documents the base classes and interfaces for memory management.</p>"},{"location":"api/memory/base/#memory-backend-base-class","title":"Memory Backend Base Class","text":""},{"location":"api/memory/base/#fastadk.memory.base.MemoryBackend","title":"<code>fastadk.memory.base.MemoryBackend</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for memory backends.</p> <p>All memory backends must implement these methods to provide consistent storage and retrieval functionality.</p> Source code in <code>src/fastadk/memory/base.py</code> <pre><code>class MemoryBackend(ABC):\n    \"\"\"\n    Abstract base class for memory backends.\n\n    All memory backends must implement these methods to provide\n    consistent storage and retrieval functionality.\n    \"\"\"\n\n    @abstractmethod\n    async def get(self, key: str) -&gt; MemoryEntry | None:\n        \"\"\"\n        Get a memory entry by key.\n\n        Args:\n            key: The key to look up\n\n        Returns:\n            The memory entry if found, otherwise None\n        \"\"\"\n\n    @abstractmethod\n    async def set(\n        self, key: str, data: Any, ttl_seconds: int | None = None\n    ) -&gt; MemoryEntry:\n        \"\"\"\n        Store a value in memory.\n\n        Args:\n            key: The key to store the data under\n            data: The data to store\n            ttl_seconds: Optional time-to-live in seconds\n\n        Returns:\n            The created memory entry\n        \"\"\"\n\n    @abstractmethod\n    async def delete(self, key: str) -&gt; bool:\n        \"\"\"\n        Delete a memory entry by key.\n\n        Args:\n            key: The key to delete\n\n        Returns:\n            True if the entry was deleted, False if it didn't exist\n        \"\"\"\n\n    @abstractmethod\n    async def exists(self, key: str) -&gt; bool:\n        \"\"\"\n        Check if a key exists in memory.\n\n        Args:\n            key: The key to check\n\n        Returns:\n            True if the key exists, False otherwise\n        \"\"\"\n\n    @abstractmethod\n    async def keys(self, pattern: str | None = None) -&gt; list[str]:\n        \"\"\"\n        Get all keys matching a pattern.\n\n        Args:\n            pattern: Optional pattern to match keys against\n\n        Returns:\n            List of matching keys\n        \"\"\"\n\n    @abstractmethod\n    async def clear(self, pattern: str | None = None) -&gt; int:\n        \"\"\"\n        Clear entries from memory.\n\n        Args:\n            pattern: Optional pattern to match keys against\n\n        Returns:\n            Number of entries cleared\n        \"\"\"\n\n    @abstractmethod\n    async def ttl(self, key: str) -&gt; float | None:\n        \"\"\"\n        Get the time-to-live for a key in seconds.\n\n        Args:\n            key: The key to check\n\n        Returns:\n            The TTL in seconds, or None if the key doesn't exist or has no expiration\n        \"\"\"\n\n    @abstractmethod\n    async def search_semantic(\n        self, query: str, limit: int = 10, threshold: float = 0.0\n    ) -&gt; list[MemoryEntry]:\n        \"\"\"\n        Search for semantically similar entries.\n\n        This is a placeholder for vector-based backends.\n        Basic backends can implement a simple search.\n\n        Args:\n            query: The search query\n            limit: Maximum number of results to return\n            threshold: Minimum similarity threshold (0.0 to 1.0)\n\n        Returns:\n            List of matching memory entries\n        \"\"\"\n\n    @abstractmethod\n    async def health_check(self) -&gt; bool:\n        \"\"\"\n        Check if the memory backend is healthy.\n\n        Returns:\n            True if healthy, False otherwise\n        \"\"\"\n</code></pre>"},{"location":"api/memory/base/#fastadk.memory.base.MemoryBackend.clear","title":"<code>clear(pattern=None)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Clear entries from memory.</p> <p>Parameters:</p> Name Type Description Default <code>pattern</code> <code>str | None</code> <p>Optional pattern to match keys against</p> <code>None</code> <p>Returns:</p> Type Description <code>int</code> <p>Number of entries cleared</p> Source code in <code>src/fastadk/memory/base.py</code> <pre><code>@abstractmethod\nasync def clear(self, pattern: str | None = None) -&gt; int:\n    \"\"\"\n    Clear entries from memory.\n\n    Args:\n        pattern: Optional pattern to match keys against\n\n    Returns:\n        Number of entries cleared\n    \"\"\"\n</code></pre>"},{"location":"api/memory/base/#fastadk.memory.base.MemoryBackend.delete","title":"<code>delete(key)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Delete a memory entry by key.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key to delete</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the entry was deleted, False if it didn't exist</p> Source code in <code>src/fastadk/memory/base.py</code> <pre><code>@abstractmethod\nasync def delete(self, key: str) -&gt; bool:\n    \"\"\"\n    Delete a memory entry by key.\n\n    Args:\n        key: The key to delete\n\n    Returns:\n        True if the entry was deleted, False if it didn't exist\n    \"\"\"\n</code></pre>"},{"location":"api/memory/base/#fastadk.memory.base.MemoryBackend.exists","title":"<code>exists(key)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Check if a key exists in memory.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key to check</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the key exists, False otherwise</p> Source code in <code>src/fastadk/memory/base.py</code> <pre><code>@abstractmethod\nasync def exists(self, key: str) -&gt; bool:\n    \"\"\"\n    Check if a key exists in memory.\n\n    Args:\n        key: The key to check\n\n    Returns:\n        True if the key exists, False otherwise\n    \"\"\"\n</code></pre>"},{"location":"api/memory/base/#fastadk.memory.base.MemoryBackend.get","title":"<code>get(key)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Get a memory entry by key.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key to look up</p> required <p>Returns:</p> Type Description <code>MemoryEntry | None</code> <p>The memory entry if found, otherwise None</p> Source code in <code>src/fastadk/memory/base.py</code> <pre><code>@abstractmethod\nasync def get(self, key: str) -&gt; MemoryEntry | None:\n    \"\"\"\n    Get a memory entry by key.\n\n    Args:\n        key: The key to look up\n\n    Returns:\n        The memory entry if found, otherwise None\n    \"\"\"\n</code></pre>"},{"location":"api/memory/base/#fastadk.memory.base.MemoryBackend.health_check","title":"<code>health_check()</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Check if the memory backend is healthy.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if healthy, False otherwise</p> Source code in <code>src/fastadk/memory/base.py</code> <pre><code>@abstractmethod\nasync def health_check(self) -&gt; bool:\n    \"\"\"\n    Check if the memory backend is healthy.\n\n    Returns:\n        True if healthy, False otherwise\n    \"\"\"\n</code></pre>"},{"location":"api/memory/base/#fastadk.memory.base.MemoryBackend.keys","title":"<code>keys(pattern=None)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Get all keys matching a pattern.</p> <p>Parameters:</p> Name Type Description Default <code>pattern</code> <code>str | None</code> <p>Optional pattern to match keys against</p> <code>None</code> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of matching keys</p> Source code in <code>src/fastadk/memory/base.py</code> <pre><code>@abstractmethod\nasync def keys(self, pattern: str | None = None) -&gt; list[str]:\n    \"\"\"\n    Get all keys matching a pattern.\n\n    Args:\n        pattern: Optional pattern to match keys against\n\n    Returns:\n        List of matching keys\n    \"\"\"\n</code></pre>"},{"location":"api/memory/base/#fastadk.memory.base.MemoryBackend.search_semantic","title":"<code>search_semantic(query, limit=10, threshold=0.0)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Search for semantically similar entries.</p> <p>This is a placeholder for vector-based backends. Basic backends can implement a simple search.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>The search query</p> required <code>limit</code> <code>int</code> <p>Maximum number of results to return</p> <code>10</code> <code>threshold</code> <code>float</code> <p>Minimum similarity threshold (0.0 to 1.0)</p> <code>0.0</code> <p>Returns:</p> Type Description <code>list[MemoryEntry]</code> <p>List of matching memory entries</p> Source code in <code>src/fastadk/memory/base.py</code> <pre><code>@abstractmethod\nasync def search_semantic(\n    self, query: str, limit: int = 10, threshold: float = 0.0\n) -&gt; list[MemoryEntry]:\n    \"\"\"\n    Search for semantically similar entries.\n\n    This is a placeholder for vector-based backends.\n    Basic backends can implement a simple search.\n\n    Args:\n        query: The search query\n        limit: Maximum number of results to return\n        threshold: Minimum similarity threshold (0.0 to 1.0)\n\n    Returns:\n        List of matching memory entries\n    \"\"\"\n</code></pre>"},{"location":"api/memory/base/#fastadk.memory.base.MemoryBackend.set","title":"<code>set(key, data, ttl_seconds=None)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Store a value in memory.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key to store the data under</p> required <code>data</code> <code>Any</code> <p>The data to store</p> required <code>ttl_seconds</code> <code>int | None</code> <p>Optional time-to-live in seconds</p> <code>None</code> <p>Returns:</p> Type Description <code>MemoryEntry</code> <p>The created memory entry</p> Source code in <code>src/fastadk/memory/base.py</code> <pre><code>@abstractmethod\nasync def set(\n    self, key: str, data: Any, ttl_seconds: int | None = None\n) -&gt; MemoryEntry:\n    \"\"\"\n    Store a value in memory.\n\n    Args:\n        key: The key to store the data under\n        data: The data to store\n        ttl_seconds: Optional time-to-live in seconds\n\n    Returns:\n        The created memory entry\n    \"\"\"\n</code></pre>"},{"location":"api/memory/base/#fastadk.memory.base.MemoryBackend.ttl","title":"<code>ttl(key)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Get the time-to-live for a key in seconds.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key to check</p> required <p>Returns:</p> Type Description <code>float | None</code> <p>The TTL in seconds, or None if the key doesn't exist or has no expiration</p> Source code in <code>src/fastadk/memory/base.py</code> <pre><code>@abstractmethod\nasync def ttl(self, key: str) -&gt; float | None:\n    \"\"\"\n    Get the time-to-live for a key in seconds.\n\n    Args:\n        key: The key to check\n\n    Returns:\n        The TTL in seconds, or None if the key doesn't exist or has no expiration\n    \"\"\"\n</code></pre>"},{"location":"api/memory/base/#memory-entry","title":"Memory Entry","text":""},{"location":"api/memory/base/#fastadk.memory.base.MemoryEntry","title":"<code>fastadk.memory.base.MemoryEntry</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>A single memory entry.</p> Source code in <code>src/fastadk/memory/base.py</code> <pre><code>class MemoryEntry(BaseModel):\n    \"\"\"A single memory entry.\"\"\"\n\n    key: str = Field(..., description=\"Unique key for this memory entry\")\n    data: Any = Field(..., description=\"The data stored in this memory entry\")\n    created_at: float = Field(\n        default_factory=time.time, description=\"Creation timestamp\"\n    )\n    expires_at: float | None = Field(\n        None, description=\"Expiration timestamp (None means no expiration)\"\n    )\n    metadata: dict[str, Any] = Field(\n        default_factory=dict, description=\"Additional metadata for this entry\"\n    )\n\n    def is_expired(self) -&gt; bool:\n        \"\"\"Check if this entry is expired.\"\"\"\n        if self.expires_at is None:\n            return False\n        return time.time() &gt; self.expires_at\n\n    def get_ttl(self) -&gt; float | None:\n        \"\"\"Get the remaining time-to-live in seconds.\"\"\"\n        if self.expires_at is None:\n            return None\n        remaining = self.expires_at - time.time()\n        return max(0.0, remaining)\n</code></pre>"},{"location":"api/memory/base/#fastadk.memory.base.MemoryEntry.get_ttl","title":"<code>get_ttl()</code>","text":"<p>Get the remaining time-to-live in seconds.</p> Source code in <code>src/fastadk/memory/base.py</code> <pre><code>def get_ttl(self) -&gt; float | None:\n    \"\"\"Get the remaining time-to-live in seconds.\"\"\"\n    if self.expires_at is None:\n        return None\n    remaining = self.expires_at - time.time()\n    return max(0.0, remaining)\n</code></pre>"},{"location":"api/memory/base/#fastadk.memory.base.MemoryEntry.is_expired","title":"<code>is_expired()</code>","text":"<p>Check if this entry is expired.</p> Source code in <code>src/fastadk/memory/base.py</code> <pre><code>def is_expired(self) -&gt; bool:\n    \"\"\"Check if this entry is expired.\"\"\"\n    if self.expires_at is None:\n        return False\n    return time.time() &gt; self.expires_at\n</code></pre>"},{"location":"api/memory/base/#usage-example","title":"Usage Example","text":"<pre><code>from fastadk.memory.base import MemoryBackend, MemoryEntry\nfrom typing import Dict, List, Optional, Any\nimport time\n\nclass CustomMemoryBackend(MemoryBackend):\n    \"\"\"A custom memory backend implementation.\"\"\"\n\n    def __init__(self):\n        self.storage = {}\n\n    async def set(self, key: str, value: Any, ttl: Optional[int] = None) -&gt; None:\n        \"\"\"Store a value with optional TTL.\"\"\"\n        expiry = time.time() + ttl if ttl else None\n        self.storage[key] = {\n            \"value\": value,\n            \"expiry\": expiry\n        }\n\n    async def get(self, key: str) -&gt; Any:\n        \"\"\"Retrieve a value by key.\"\"\"\n        if key not in self.storage:\n            return None\n\n        item = self.storage[key]\n        if item[\"expiry\"] and time.time() &gt; item[\"expiry\"]:\n            del self.storage[key]\n            return None\n\n        return item[\"value\"]\n\n    async def delete(self, key: str) -&gt; None:\n        \"\"\"Delete a value by key.\"\"\"\n        if key in self.storage:\n            del self.storage[key]\n\n    async def exists(self, key: str) -&gt; bool:\n        \"\"\"Check if a key exists.\"\"\"\n        if key not in self.storage:\n            return False\n\n        item = self.storage[key]\n        if item[\"expiry\"] and time.time() &gt; item[\"expiry\"]:\n            del self.storage[key]\n            return False\n\n        return True\n\n    async def keys(self, pattern: str = \"*\") -&gt; List[str]:\n        \"\"\"Get keys matching a pattern.\"\"\"\n        # Simple implementation without pattern matching\n        return list(self.storage.keys())\n\n    async def clear(self) -&gt; None:\n        \"\"\"Clear all values.\"\"\"\n        self.storage.clear()\n\n    async def clear_pattern(self, pattern: str) -&gt; None:\n        \"\"\"Clear all values matching a pattern.\"\"\"\n        # Simple implementation without pattern matching\n        keys_to_delete = [k for k in self.storage.keys() if pattern in k]\n        for key in keys_to_delete:\n            del self.storage[key]\n\n    async def ttl(self, key: str) -&gt; Optional[int]:\n        \"\"\"Get the remaining TTL for a key.\"\"\"\n        if key not in self.storage or not self.storage[key][\"expiry\"]:\n            return None\n\n        remaining = self.storage[key][\"expiry\"] - time.time()\n        return max(0, int(remaining))\n\n    async def health_check(self) -&gt; bool:\n        \"\"\"Check if the memory backend is healthy.\"\"\"\n        return True\n</code></pre>"},{"location":"api/testing/utils/","title":"Testing Utilities","text":"<p>FastADK provides testing utilities to make it easier to test your agents and tools.</p>"},{"location":"api/testing/utils/#agent-testing","title":"Agent Testing","text":""},{"location":"api/testing/utils/#fastadk.testing.utils.AgentTest","title":"<code>fastadk.testing.utils.AgentTest</code>","text":"<p>Base class for testing FastADK agents.</p> Source code in <code>src/fastadk/testing/utils.py</code> <pre><code>class AgentTest:\n    \"\"\"Base class for testing FastADK agents.\"\"\"\n\n    # Reference to the agent class being tested\n    agent_class: ClassVar[type[BaseAgent]]\n\n    # Actual agent instance\n    agent: BaseAgent\n\n    def __init_subclass__(cls, **kwargs: Any) -&gt; None:\n        \"\"\"Hook when a subclass is created.\"\"\"\n        super().__init_subclass__(**kwargs)\n\n        # Automatically register pytest fixtures for scenarios\n        for name, method in inspect.getmembers(cls, inspect.isfunction):\n            if hasattr(method, \"_scenario_name\"):\n                # Create a pytest fixture from this scenario\n                cls._register_scenario_fixture(cls.__name__, name, method)\n\n    @staticmethod\n    def _register_scenario_fixture(\n        class_name: str, scenario_name: str, scenario_method: Callable[..., Any]\n    ) -&gt; None:\n        \"\"\"Register a pytest fixture for a scenario method.\"\"\"\n        fixture_name = f\"{class_name}_{scenario_name}\"\n\n        @pytest.fixture(name=fixture_name)\n        async def _fixture() -&gt; dict[str, Any]:\n            # Create a new instance for each test\n            instance = globals()[class_name]()\n\n            if hasattr(instance, \"setup\"):\n                await instance.setup()\n\n            try:\n                result = await scenario_method(instance)\n                return {\n                    \"name\": scenario_method._scenario_name,  # type: ignore\n                    \"description\": getattr(\n                        scenario_method, \"_scenario_description\", \"\"\n                    ),\n                    \"result\": result,\n                    \"success\": True,\n                }\n            except Exception as e:\n                return {\n                    \"name\": scenario_method._scenario_name,  # type: ignore\n                    \"description\": getattr(\n                        scenario_method, \"_scenario_description\", \"\"\n                    ),\n                    \"error\": str(e),\n                    \"success\": False,\n                }\n            finally:\n                if hasattr(instance, \"teardown\"):\n                    await instance.teardown()\n\n        # The fixture is automatically registered with pytest due to the decorator\n\n    async def setup(self) -&gt; None:\n        \"\"\"Set up the test environment before each test.\"\"\"\n\n    async def teardown(self) -&gt; None:\n        \"\"\"Clean up the test environment after each test.\"\"\"\n\n    def assert_tools_used(self, tool_names: list[str]) -&gt; None:\n        \"\"\"Verify that specific tools were used during the test.\"\"\"\n        if not hasattr(self.agent, \"tools_used\"):\n            pytest.fail(\"Agent does not track tools used\")\n\n        for name in tool_names:\n            assert name in self.agent.tools_used, f\"Tool '{name}' was not used\"\n\n    def configure_mock_model(self, prompt: str, response: str) -&gt; None:\n        \"\"\"Configure the mock model to return a specific response for a prompt.\"\"\"\n        if not hasattr(self.agent, \"model\") or not isinstance(\n            self.agent.model, MockModel\n        ):\n            self.agent.model = MockModel()  # type: ignore\n\n        # Add the response to the model's response dictionary\n        self.agent.model.responses[prompt] = response  # type: ignore[attr-defined]\n\n    @classmethod\n    async def run_load_test(cls, scenario_name: str, **kwargs: Any) -&gt; dict[str, Any]:\n        \"\"\"Run a load test scenario with multiple concurrent users.\"\"\"\n        # Get the scenario method\n        scenario_method = None\n        for _name, method in inspect.getmembers(cls, inspect.isfunction):\n            if (\n                hasattr(method, \"_scenario_name\")\n                and method._scenario_name == scenario_name  # type: ignore\n                and hasattr(method, \"_is_load_test\")\n            ):\n                scenario_method = method\n                break\n\n        if not scenario_method:\n            raise ValueError(f\"No load test scenario found with name '{scenario_name}'\")\n\n        # Get load test config\n        config = {**scenario_method._load_test_config}  # type: ignore\n        config.update(kwargs)\n\n        concurrent_users = config.get(\"concurrent_users\", 10)\n\n        # Create tasks for each user\n        tasks = []\n        for _ in range(concurrent_users):\n            instance = cls()\n            await instance.setup()\n            tasks.append(scenario_method(instance))\n\n        # Run all tasks concurrently\n        results = await asyncio.gather(*tasks, return_exceptions=True)\n\n        # Process results\n        success_count = sum(1 for r in results if not isinstance(r, Exception))\n        failure_count = len(results) - success_count\n\n        return {\n            \"scenario\": scenario_name,\n            \"config\": config,\n            \"success_count\": success_count,\n            \"failure_count\": failure_count,\n            \"success_rate\": success_count / len(results) if results else 0,\n            \"results\": results,\n        }\n</code></pre>"},{"location":"api/testing/utils/#fastadk.testing.utils.AgentTest.__init_subclass__","title":"<code>__init_subclass__(**kwargs)</code>","text":"<p>Hook when a subclass is created.</p> Source code in <code>src/fastadk/testing/utils.py</code> <pre><code>def __init_subclass__(cls, **kwargs: Any) -&gt; None:\n    \"\"\"Hook when a subclass is created.\"\"\"\n    super().__init_subclass__(**kwargs)\n\n    # Automatically register pytest fixtures for scenarios\n    for name, method in inspect.getmembers(cls, inspect.isfunction):\n        if hasattr(method, \"_scenario_name\"):\n            # Create a pytest fixture from this scenario\n            cls._register_scenario_fixture(cls.__name__, name, method)\n</code></pre>"},{"location":"api/testing/utils/#fastadk.testing.utils.AgentTest.assert_tools_used","title":"<code>assert_tools_used(tool_names)</code>","text":"<p>Verify that specific tools were used during the test.</p> Source code in <code>src/fastadk/testing/utils.py</code> <pre><code>def assert_tools_used(self, tool_names: list[str]) -&gt; None:\n    \"\"\"Verify that specific tools were used during the test.\"\"\"\n    if not hasattr(self.agent, \"tools_used\"):\n        pytest.fail(\"Agent does not track tools used\")\n\n    for name in tool_names:\n        assert name in self.agent.tools_used, f\"Tool '{name}' was not used\"\n</code></pre>"},{"location":"api/testing/utils/#fastadk.testing.utils.AgentTest.configure_mock_model","title":"<code>configure_mock_model(prompt, response)</code>","text":"<p>Configure the mock model to return a specific response for a prompt.</p> Source code in <code>src/fastadk/testing/utils.py</code> <pre><code>def configure_mock_model(self, prompt: str, response: str) -&gt; None:\n    \"\"\"Configure the mock model to return a specific response for a prompt.\"\"\"\n    if not hasattr(self.agent, \"model\") or not isinstance(\n        self.agent.model, MockModel\n    ):\n        self.agent.model = MockModel()  # type: ignore\n\n    # Add the response to the model's response dictionary\n    self.agent.model.responses[prompt] = response  # type: ignore[attr-defined]\n</code></pre>"},{"location":"api/testing/utils/#fastadk.testing.utils.AgentTest.run_load_test","title":"<code>run_load_test(scenario_name, **kwargs)</code>  <code>async</code> <code>classmethod</code>","text":"<p>Run a load test scenario with multiple concurrent users.</p> Source code in <code>src/fastadk/testing/utils.py</code> <pre><code>@classmethod\nasync def run_load_test(cls, scenario_name: str, **kwargs: Any) -&gt; dict[str, Any]:\n    \"\"\"Run a load test scenario with multiple concurrent users.\"\"\"\n    # Get the scenario method\n    scenario_method = None\n    for _name, method in inspect.getmembers(cls, inspect.isfunction):\n        if (\n            hasattr(method, \"_scenario_name\")\n            and method._scenario_name == scenario_name  # type: ignore\n            and hasattr(method, \"_is_load_test\")\n        ):\n            scenario_method = method\n            break\n\n    if not scenario_method:\n        raise ValueError(f\"No load test scenario found with name '{scenario_name}'\")\n\n    # Get load test config\n    config = {**scenario_method._load_test_config}  # type: ignore\n    config.update(kwargs)\n\n    concurrent_users = config.get(\"concurrent_users\", 10)\n\n    # Create tasks for each user\n    tasks = []\n    for _ in range(concurrent_users):\n        instance = cls()\n        await instance.setup()\n        tasks.append(scenario_method(instance))\n\n    # Run all tasks concurrently\n    results = await asyncio.gather(*tasks, return_exceptions=True)\n\n    # Process results\n    success_count = sum(1 for r in results if not isinstance(r, Exception))\n    failure_count = len(results) - success_count\n\n    return {\n        \"scenario\": scenario_name,\n        \"config\": config,\n        \"success_count\": success_count,\n        \"failure_count\": failure_count,\n        \"success_rate\": success_count / len(results) if results else 0,\n        \"results\": results,\n    }\n</code></pre>"},{"location":"api/testing/utils/#fastadk.testing.utils.AgentTest.setup","title":"<code>setup()</code>  <code>async</code>","text":"<p>Set up the test environment before each test.</p> Source code in <code>src/fastadk/testing/utils.py</code> <pre><code>async def setup(self) -&gt; None:\n    \"\"\"Set up the test environment before each test.\"\"\"\n</code></pre>"},{"location":"api/testing/utils/#fastadk.testing.utils.AgentTest.teardown","title":"<code>teardown()</code>  <code>async</code>","text":"<p>Clean up the test environment after each test.</p> Source code in <code>src/fastadk/testing/utils.py</code> <pre><code>async def teardown(self) -&gt; None:\n    \"\"\"Clean up the test environment after each test.\"\"\"\n</code></pre>"},{"location":"api/testing/utils/#fastadk.testing.utils.scenario","title":"<code>fastadk.testing.utils.scenario(name, description='', **kwargs)</code>","text":"<p>Decorator for naming and documenting test scenarios.</p> Source code in <code>src/fastadk/testing/utils.py</code> <pre><code>def scenario(\n    name: str, description: str = \"\", **kwargs: Any\n) -&gt; Callable[[Callable[..., Any]], Callable[..., Any]]:\n    \"\"\"Decorator for naming and documenting test scenarios.\"\"\"\n\n    def decorator(func: Callable[..., Any]) -&gt; Callable[..., Any]:\n        # Store metadata directly on the function\n        func._scenario_name = name  # type: ignore\n        func._scenario_description = description  # type: ignore\n        # Add any other metadata\n        for key, value in kwargs.items():\n            setattr(func, f\"_scenario_{key}\", value)\n        return func\n\n    return decorator\n</code></pre>"},{"location":"api/testing/utils/#fastadk.testing.utils.load_test","title":"<code>fastadk.testing.utils.load_test(concurrent_users, duration, ramp_up='0s', **kwargs)</code>","text":"<p>Decorator for creating load test scenarios.</p> Source code in <code>src/fastadk/testing/utils.py</code> <pre><code>def load_test(\n    concurrent_users: int, duration: str, ramp_up: str = \"0s\", **kwargs: Any\n) -&gt; Callable[[Callable[..., Any]], Callable[..., Any]]:\n    \"\"\"Decorator for creating load test scenarios.\"\"\"\n\n    def decorator(func: Callable[..., Any]) -&gt; Callable[..., Any]:\n        # Store load test metadata\n        func._is_load_test = True  # type: ignore\n        func._load_test_config = {  # type: ignore\n            \"concurrent_users\": concurrent_users,\n            \"duration\": duration,\n            \"ramp_up\": ramp_up,\n            **kwargs,\n        }\n        return func\n\n    return decorator\n</code></pre>"},{"location":"api/testing/utils/#mock-models","title":"Mock Models","text":""},{"location":"api/testing/utils/#fastadk.testing.utils.MockModel","title":"<code>fastadk.testing.utils.MockModel</code>","text":"<p>Mock model for testing agents without calling real LLM APIs.</p> Source code in <code>src/fastadk/testing/utils.py</code> <pre><code>class MockModel:\n    \"\"\"Mock model for testing agents without calling real LLM APIs.\"\"\"\n\n    def __init__(\n        self,\n        responses: dict[str, str] | None = None,\n        default_response: str = \"Mock response\",\n    ) -&gt; None:\n        \"\"\"Initialize the mock model.\"\"\"\n        self.responses = responses or {}\n        self.default_response = default_response\n        self.invocations: list[dict[str, Any]] = []\n        self.last_prompt: str | None = None\n\n    def generate_content(self, prompt: str, **kwargs: Any) -&gt; MockResponse:\n        \"\"\"Simulate generating content from a prompt.\"\"\"\n        self.invocations.append({\"prompt\": prompt, \"params\": kwargs})\n        self.last_prompt = prompt\n\n        # Try to find a matching response\n        for pattern, response in self.responses.items():\n            if re.search(pattern, prompt, re.DOTALL):\n                return MockResponse(response)\n\n        return MockResponse(self.default_response)\n</code></pre>"},{"location":"api/testing/utils/#fastadk.testing.utils.MockModel.__init__","title":"<code>__init__(responses=None, default_response='Mock response')</code>","text":"<p>Initialize the mock model.</p> Source code in <code>src/fastadk/testing/utils.py</code> <pre><code>def __init__(\n    self,\n    responses: dict[str, str] | None = None,\n    default_response: str = \"Mock response\",\n) -&gt; None:\n    \"\"\"Initialize the mock model.\"\"\"\n    self.responses = responses or {}\n    self.default_response = default_response\n    self.invocations: list[dict[str, Any]] = []\n    self.last_prompt: str | None = None\n</code></pre>"},{"location":"api/testing/utils/#fastadk.testing.utils.MockModel.generate_content","title":"<code>generate_content(prompt, **kwargs)</code>","text":"<p>Simulate generating content from a prompt.</p> Source code in <code>src/fastadk/testing/utils.py</code> <pre><code>def generate_content(self, prompt: str, **kwargs: Any) -&gt; MockResponse:\n    \"\"\"Simulate generating content from a prompt.\"\"\"\n    self.invocations.append({\"prompt\": prompt, \"params\": kwargs})\n    self.last_prompt = prompt\n\n    # Try to find a matching response\n    for pattern, response in self.responses.items():\n        if re.search(pattern, prompt, re.DOTALL):\n            return MockResponse(response)\n\n    return MockResponse(self.default_response)\n</code></pre>"},{"location":"api/testing/utils/#fastadk.testing.utils.MockResponse","title":"<code>fastadk.testing.utils.MockResponse</code>","text":"<p>Mock response from an LLM API.</p> Source code in <code>src/fastadk/testing/utils.py</code> <pre><code>class MockResponse:\n    \"\"\"Mock response from an LLM API.\"\"\"\n\n    def __init__(self, text: str) -&gt; None:\n        self.text = text\n        self.content = text\n</code></pre>"},{"location":"api/testing/utils/#example-usage","title":"Example Usage","text":"<pre><code>import unittest\nfrom fastadk.testing.utils import AgentTestCase, AgentTester\nfrom fastadk.core import Agent, BaseAgent, tool\n\n@Agent(model=\"gemini-2.0-pro\")\nclass MathAgent(BaseAgent):\n    @tool\n    def add(self, a: float, b: float) -&gt; float:\n        \"\"\"Add two numbers together.\"\"\"\n        return a + b\n\n    @tool\n    def multiply(self, a: float, b: float) -&gt; float:\n        \"\"\"Multiply two numbers together.\"\"\"\n        return a * b\n\nclass TestMathAgent(AgentTestCase):\n    def setUp(self):\n        self.agent = MathAgent()\n        self.tester = AgentTester(self.agent)\n\n    def test_addition(self):\n        # Test that the agent can add numbers\n        response = self.tester.run(\"What is 2 + 3?\")\n\n        # Verify that the add tool was used\n        self.tester.assert_tool_used(\"add\")\n\n        # Verify the response contains the expected result\n        self.assertIn(\"5\", response)\n\n    def test_multiplication(self):\n        # Test that the agent can multiply numbers\n        response = self.tester.run(\"What is 4 times 7?\")\n\n        # Verify that the multiply tool was used\n        self.tester.assert_tool_used(\"multiply\")\n\n        # Verify the response contains the expected result\n        self.assertIn(\"28\", response)\n\nif __name__ == \"__main__\":\n    unittest.main()\n</code></pre>"},{"location":"api/testing/utils/#performance-testing","title":"Performance Testing","text":"<pre><code>from fastadk.testing.utils import PerformanceTester\n\ndef test_agent_performance():\n    agent = MyAgent()\n    tester = PerformanceTester(agent)\n\n    # Test response time\n    results = tester.measure_response_time(\n        queries=[\"What's the weather?\", \"Tell me a joke\"],\n        iterations=10\n    )\n\n    print(f\"Average response time: {results.average_time:.2f}s\")\n    print(f\"p95 response time: {results.p95_time:.2f}s\")\n\n    # Test memory usage\n    memory_results = tester.measure_memory_usage(\n        query=\"What's the meaning of life?\",\n        iterations=5\n    )\n\n    print(f\"Peak memory usage: {memory_results.peak_mb:.2f}MB\")\n</code></pre>"},{"location":"concepts/agents/","title":"Understanding Agents","text":"<p>Agents are the core building blocks in FastADK. This guide explains what agents are, how they work, and best practices for designing them.</p>"},{"location":"concepts/agents/#what-is-an-agent","title":"What is an Agent?","text":"<p>In FastADK, an agent is a Python class that:</p> <ol> <li>Is decorated with the <code>@Agent</code> decorator</li> <li>Inherits from <code>BaseAgent</code></li> <li>Contains one or more methods decorated with <code>@tool</code></li> </ol> <p>Agents encapsulate a language model (LLM) along with tools it can use to perform tasks. The agent knows how to:</p> <ul> <li>Process user inputs</li> <li>Decide which tools to use</li> <li>Execute tools with appropriate parameters</li> <li>Return coherent responses based on tool results</li> </ul>"},{"location":"concepts/agents/#agent-architecture","title":"Agent Architecture","text":"<p>An agent consists of several key components:</p> <ul> <li>Language Model: The underlying AI model (e.g., Gemini)</li> <li>Tools: Functions the agent can call to perform tasks</li> <li>Memory: Storage for conversation history and context</li> <li>Router: Logic for directing messages and responses</li> <li>Lifecycle Hooks: Methods called at different points in the agent's lifecycle</li> </ul>"},{"location":"concepts/agents/#creating-an-agent","title":"Creating an Agent","text":"<p>The simplest agent looks like this:</p> <pre><code>from fastadk.core import Agent, BaseAgent, tool\n\n@Agent(model=\"gemini-2.0-pro\")\nclass SimpleAgent(BaseAgent):\n    @tool\n    def hello(self, name: str) -&gt; str:\n        \"\"\"Say hello to someone.\"\"\"\n        return f\"Hello, {name}!\"\n</code></pre> <p>This agent can: - Parse user requests for greetings - Extract the name parameter - Return a formatted greeting</p>"},{"location":"concepts/agents/#agent-lifecycle","title":"Agent Lifecycle","text":"<p>When an agent processes a message, it goes through several stages:</p> <ol> <li>Initialization: The agent is created and configured</li> <li>Message Reception: A user message is received</li> <li>Context Building: Current and past messages are formatted for the LLM</li> <li>LLM Reasoning: The LLM decides which tools to call and with what parameters</li> <li>Tool Execution: The specified tools are executed</li> <li>Response Generation: Results are formatted into a final response</li> <li>Memory Update: The conversation history is updated</li> </ol> <p>You can hook into this lifecycle with methods like:</p> <pre><code>def on_initialize(self) -&gt; None:\n    \"\"\"Called when the agent is first created.\"\"\"\n\ndef on_message(self, message: str) -&gt; None:\n    \"\"\"Called when a new message is received.\"\"\"\n\ndef on_finish(self, result: Any) -&gt; None:\n    \"\"\"Called after processing completes.\"\"\"\n</code></pre>"},{"location":"concepts/agents/#agent-types","title":"Agent Types","text":"<p>FastADK supports three main agent archetypes:</p>"},{"location":"concepts/agents/#1-task-completion-agents","title":"1. Task-Completion Agents","text":"<p>Focused on completing specific tasks with structured inputs and outputs.</p> <pre><code>@Agent(model=\"gemini-2.0-pro\")\nclass DocumentSummarizer(BaseAgent):\n    @tool\n    def summarize_text(self, text: str, max_length: int = 100) -&gt; str:\n        \"\"\"Summarize text to specified maximum length.\"\"\"\n        # Implementation\n</code></pre>"},{"location":"concepts/agents/#2-tool-using-agents","title":"2. Tool-Using Agents","text":"<p>Capable of choosing from multiple tools to solve complex problems.</p> <pre><code>@Agent(model=\"gemini-2.0-pro\")\nclass ResearchAssistant(BaseAgent):\n    @tool\n    def search_web(self, query: str) -&gt; list:\n        \"\"\"Search the web for information.\"\"\"\n        # Implementation\n\n    @tool\n    def read_document(self, url: str) -&gt; str:\n        \"\"\"Extract text from a document.\"\"\"\n        # Implementation\n\n    @tool\n    def summarize(self, text: str) -&gt; str:\n        \"\"\"Summarize text.\"\"\"\n        # Implementation\n</code></pre>"},{"location":"concepts/agents/#3-conversational-agents","title":"3. Conversational Agents","text":"<p>Maintain conversation state and respond naturally over multiple turns.</p> <pre><code>@Agent(\n    model=\"gemini-2.0-pro\",\n    memory_backend=\"redis\",\n    memory_ttl=86400  # 24 hours\n)\nclass CustomerSupportAgent(BaseAgent):\n    @tool\n    def query_knowledge_base(self, query: str) -&gt; str:\n        \"\"\"Look up information in the knowledge base.\"\"\"\n        # Implementation\n\n    @tool\n    def get_customer_info(self, customer_id: str) -&gt; dict:\n        \"\"\"Retrieve customer information.\"\"\"\n        # Implementation\n</code></pre>"},{"location":"concepts/agents/#agent-configuration","title":"Agent Configuration","text":"<p>The <code>@Agent</code> decorator accepts many parameters to customize behavior:</p> <pre><code>@Agent(\n    model=\"gemini-2.0-pro\",\n    description=\"A helpful assistant for answering questions\",\n    temperature=0.7,\n    max_tokens=1024,\n    memory_backend=\"redis\",\n    cache_enabled=True\n)\n</code></pre> <p>Key configuration options include:</p> <ul> <li>Model selection: Different models have different capabilities</li> <li>Generation parameters: Control creativity, length, etc.</li> <li>Memory options: Choose storage backends and retention policies</li> <li>Caching: Enable caching for improved performance</li> </ul>"},{"location":"concepts/agents/#best-practices","title":"Best Practices","text":""},{"location":"concepts/agents/#agent-design","title":"Agent Design","text":"<ul> <li>Single Responsibility: Each agent should have a clear, focused purpose</li> <li>Meaningful Tools: Design tools that perform concrete, useful actions</li> <li>Clear Documentation: Write clear docstrings for agents and tools</li> <li>Parameter Validation: Validate inputs to prevent errors</li> <li>Appropriate Scoping: Don't try to do too much in a single agent</li> </ul>"},{"location":"concepts/agents/#tool-implementation","title":"Tool Implementation","text":"<ul> <li>Atomic Functions: Each tool should do one thing well</li> <li>Strong Typing: Use type hints for all parameters and return values</li> <li>Descriptive Names: Use clear, action-oriented names for tools</li> <li>Error Handling: Implement robust error handling and recovery</li> <li>Retry Logic: Add retry mechanisms for flaky operations</li> </ul>"},{"location":"concepts/agents/#performance-optimization","title":"Performance Optimization","text":"<ul> <li>Caching: Cache expensive operations with appropriate TTLs</li> <li>Batch Processing: Combine operations where possible</li> <li>Efficient Context: Keep context concise and relevant</li> <li>Memory Management: Implement proper summarization and cleanup</li> <li>Async Operations: Use async for I/O-bound operations</li> </ul>"},{"location":"concepts/agents/#advanced-agent-patterns","title":"Advanced Agent Patterns","text":""},{"location":"concepts/agents/#composition","title":"Composition","text":"<p>Agents can use other agents as tools:</p> <pre><code>@Agent(model=\"gemini-2.0-pro\")\nclass MetaAgent(BaseAgent):\n    def __init__(self):\n        super().__init__()\n        self.search_agent = SearchAgent()\n        self.analysis_agent = AnalysisAgent()\n\n    @tool\n    def research_topic(self, topic: str) -&gt; dict:\n        \"\"\"Research a topic using multiple specialized agents.\"\"\"\n        search_results = self.search_agent.run(f\"Find information about {topic}\")\n        analysis = self.analysis_agent.run(f\"Analyze this information: {search_results}\")\n        return {\"search\": search_results, \"analysis\": analysis}\n</code></pre>"},{"location":"concepts/agents/#specialization","title":"Specialization","text":"<p>Create specialized agents for specific domains:</p> <pre><code>@Agent(\n    model=\"gemini-2.0-pro\",\n    description=\"Medical diagnostic assistant with healthcare knowledge\"\n)\nclass MedicalAgent(BaseAgent):\n    # Medical-specific tools\n</code></pre>"},{"location":"concepts/agents/#multi-modal","title":"Multi-modal","text":"<p>Agents that can process and generate different types of content:</p> <pre><code>@Agent(model=\"gemini-2.0-pro\")\nclass ContentCreationAgent(BaseAgent):\n    @tool\n    def generate_image_prompt(self, description: str) -&gt; str:\n        \"\"\"Generate a detailed prompt for image generation.\"\"\"\n        # Implementation\n\n    @tool\n    def format_content(self, text: str, style: str) -&gt; str:\n        \"\"\"Format content according to a specific style.\"\"\"\n        # Implementation\n</code></pre>"},{"location":"concepts/error-handling/","title":"Error Handling in FastADK","text":"<p>Effective error handling is crucial for building robust and reliable AI agents. This document explains the error handling mechanisms in FastADK, including exception types, retry strategies, and best practices.</p>"},{"location":"concepts/error-handling/#exception-hierarchy","title":"Exception Hierarchy","text":"<p>FastADK provides a structured exception hierarchy to make error handling more predictable and manageable:</p> <pre><code>graph TD\n    A[FastADKError] --&gt; B[ProviderError]\n    A --&gt; C[ToolError]\n    A --&gt; D[ConfigurationError]\n    A --&gt; E[MemoryError]\n    A --&gt; F[WorkflowError]\n    B --&gt; G[RateLimitError]\n    B --&gt; H[AuthenticationError]\n    B --&gt; I[QuotaExceededError]\n    B --&gt; J[ModelNotFoundError]\n    B --&gt; K[ContentFilterError]\n    C --&gt; L[ToolExecutionError]\n    C --&gt; M[ToolTimeoutError]\n    D --&gt; N[ValidationError]\n    E --&gt; O[MemoryBackendError]\n    F --&gt; P[WorkflowExecutionError]\n    F --&gt; Q[StepError]\n</code></pre>"},{"location":"concepts/error-handling/#base-exceptions","title":"Base Exceptions","text":"<pre><code>from fastadk.core.exceptions import FastADKError, ProviderError, ToolError, ConfigurationError, MemoryError, WorkflowError\n\n# Base exception for all FastADK errors\nclass FastADKError(Exception):\n    \"\"\"Base class for all FastADK exceptions.\"\"\"\n    pass\n\n# Error related to LLM providers\nclass ProviderError(FastADKError):\n    \"\"\"Error occurred in a model provider.\"\"\"\n    pass\n\n# Error related to tool execution\nclass ToolError(FastADKError):\n    \"\"\"Error occurred during tool execution.\"\"\"\n    pass\n\n# Error related to configuration\nclass ConfigurationError(FastADKError):\n    \"\"\"Error in configuration or settings.\"\"\"\n    pass\n\n# Error related to memory operations\nclass MemoryError(FastADKError):\n    \"\"\"Error in memory operations.\"\"\"\n    pass\n\n# Error related to workflow execution\nclass WorkflowError(FastADKError):\n    \"\"\"Error occurred during workflow execution.\"\"\"\n    pass\n</code></pre>"},{"location":"concepts/error-handling/#provider-specific-exceptions","title":"Provider-Specific Exceptions","text":"<pre><code># Rate limit exceeded\nclass RateLimitError(ProviderError):\n    \"\"\"Provider rate limit exceeded.\"\"\"\n    pass\n\n# Authentication failed\nclass AuthenticationError(ProviderError):\n    \"\"\"Provider authentication failed.\"\"\"\n    pass\n\n# Quota or token limit exceeded\nclass QuotaExceededError(ProviderError):\n    \"\"\"Provider quota or token limit exceeded.\"\"\"\n    pass\n\n# Model not found\nclass ModelNotFoundError(ProviderError):\n    \"\"\"Requested model not found or unavailable.\"\"\"\n    pass\n\n# Content filtered by provider\nclass ContentFilterError(ProviderError):\n    \"\"\"Content was filtered by the provider's safety system.\"\"\"\n    pass\n</code></pre>"},{"location":"concepts/error-handling/#error-handling-in-tools","title":"Error Handling in Tools","text":"<p>Tools should use appropriate exceptions to indicate failures:</p> <pre><code>from fastadk import Agent, BaseAgent, tool\nfrom fastadk.core.exceptions import ToolError\n\n@Agent(model=\"gemini-1.5-pro\")\nclass WeatherAgent(BaseAgent):\n    @tool\n    def get_weather(self, city: str) -&gt; dict:\n        \"\"\"Get the current weather for a city.\"\"\"\n        try:\n            # Weather API call might fail\n            if not city:\n                raise ValueError(\"City name cannot be empty\")\n\n            # Implementation...\n            weather_data = self._call_weather_api(city)\n\n            if not weather_data:\n                raise ToolError(f\"No weather data found for city: {city}\")\n\n            return weather_data\n        except ConnectionError as e:\n            # Network error - could be temporary\n            raise ToolError(f\"Failed to connect to weather service: {str(e)}\") from e\n        except ValueError as e:\n            # Invalid input\n            raise ToolError(f\"Invalid input: {str(e)}\") from e\n        except Exception as e:\n            # Unexpected error\n            raise ToolError(f\"An unexpected error occurred: {str(e)}\") from e\n</code></pre>"},{"location":"concepts/error-handling/#retry-mechanism","title":"Retry Mechanism","text":"<p>FastADK includes a configurable retry system for handling transient failures:</p> <pre><code>from fastadk.core.retry import retry, RetryConfig\nfrom fastadk.core.exceptions import ToolError\n\n# Configure retry behavior\n@retry(\n    max_attempts=3,\n    retry_on=[ConnectionError, TimeoutError],\n    base_delay=1.0,\n    max_delay=10.0,\n    backoff_factor=2.0\n)\nasync def fetch_data_with_retry(url: str) -&gt; dict:\n    \"\"\"Fetch data with automatic retry on failure.\"\"\"\n    # Implementation that might fail\n\n# Using retry with a tool\n@tool\n@retry(max_attempts=3)\ndef call_external_api(endpoint: str, params: dict) -&gt; dict:\n    \"\"\"Call an external API with retry support.\"\"\"\n    # Implementation that might fail\n\n# Manual retry control\nasync def process_with_manual_retry(data: dict) -&gt; dict:\n    \"\"\"Process data with manual retry control.\"\"\"\n    retry_config = RetryConfig(\n        max_attempts=5,\n        retry_on=[ConnectionError, ToolError],\n        on_retry=lambda attempt, error: print(f\"Retry {attempt} after error: {error}\")\n    )\n\n    async def _operation():\n        # The operation that might fail\n\n    result = await retry_config.execute(_operation)\n    return result\n</code></pre>"},{"location":"concepts/error-handling/#graceful-degradation","title":"Graceful Degradation","text":"<p>Implement fallback mechanisms for graceful degradation:</p> <pre><code>@tool\nasync def get_stock_price(symbol: str) -&gt; float:\n    \"\"\"Get the current stock price for a symbol.\"\"\"\n    try:\n        # Primary data source\n        price = await self._fetch_from_primary_api(symbol)\n        return price\n    except Exception as primary_error:\n        try:\n            # Fallback to secondary data source\n            self.logger.warning(f\"Primary API failed, using fallback: {primary_error}\")\n            price = await self._fetch_from_secondary_api(symbol)\n            return price\n        except Exception as secondary_error:\n            # Both sources failed\n            self.logger.error(f\"All stock APIs failed: {secondary_error}\")\n            raise ToolError(f\"Could not retrieve stock price for {symbol}\") from secondary_error\n</code></pre>"},{"location":"concepts/error-handling/#error-handling-in-agents","title":"Error Handling in Agents","text":"<p>Implement error handling in agent lifecycle methods:</p> <pre><code>from fastadk import Agent, BaseAgent\nfrom fastadk.core.exceptions import FastADKError, ProviderError\n\n@Agent(model=\"gemini-1.5-pro\")\nclass RobustAgent(BaseAgent):\n    async def on_error(self, error: Exception, context: dict = None) -&gt; str:\n        \"\"\"Handle errors during agent execution.\"\"\"\n        # Log the error\n        self.logger.error(f\"Agent error: {str(error)}\", exc_info=True)\n\n        # Handle different error types\n        if isinstance(error, ProviderError):\n            return \"I'm having trouble connecting to my language model. Please try again in a moment.\"\n        elif isinstance(error, ToolError):\n            return \"I encountered an error while trying to perform that action. Can you provide more details or try a different approach?\"\n        else:\n            return \"I'm sorry, but I encountered an unexpected error. Please try again or contact support if the issue persists.\"\n\n    async def run(self, prompt: str) -&gt; str:\n        \"\"\"Override run to add custom error handling.\"\"\"\n        try:\n            return await super().run(prompt)\n        except FastADKError as e:\n            # Handle framework errors\n            return await self.on_error(e)\n        except Exception as e:\n            # Handle unexpected errors\n            self.logger.critical(f\"Unhandled exception: {str(e)}\", exc_info=True)\n            return \"I encountered a critical error and couldn't complete your request.\"\n</code></pre>"},{"location":"concepts/error-handling/#workflow-error-handling","title":"Workflow Error Handling","text":"<p>Handle errors in workflows to ensure robustness:</p> <pre><code>from fastadk.core.workflow import Workflow, step\nfrom fastadk.core.exceptions import WorkflowError, StepError\n\n@step(name=\"Risky Step\")\nasync def risky_step(data: dict) -&gt; dict:\n    \"\"\"A step that might fail.\"\"\"\n    # Implementation that might fail\n\n@step(name=\"Error Handler\")\nasync def error_handler(error: Exception, input_data: dict) -&gt; dict:\n    \"\"\"Handle errors from the workflow.\"\"\"\n    import logging\n    logging.error(f\"Workflow error: {str(error)}\")\n\n    # Return a fallback result\n    return {\"status\": \"error\", \"message\": str(error), \"fallback_data\": {...}}\n\n# Create a workflow with error handling\nworkflow = Workflow.sequence(\n    risky_step,\n    name=\"Robust Workflow\",\n    error_handler=error_handler\n)\n\n# Execute with error handling\ntry:\n    result = await workflow.execute(input_data)\nexcept WorkflowError as e:\n    # This will only be raised if the error handler itself fails\n    print(f\"Workflow failed: {str(e)}\")\n</code></pre>"},{"location":"concepts/error-handling/#logging-and-observability","title":"Logging and Observability","text":"<p>Integrate error handling with logging and observability:</p> <pre><code>from fastadk.observability import get_logger\nfrom fastadk.observability.metrics import counter\n\nlogger = get_logger(__name__)\nerror_counter = counter(\"agent_errors_total\", \"Total number of agent errors\")\n\n@tool\nasync def perform_operation(data: dict) -&gt; dict:\n    \"\"\"Perform an operation with comprehensive error handling.\"\"\"\n    try:\n        # Operation implementation\n        return result\n    except Exception as e:\n        # Log the error\n        logger.error(\n            \"Operation failed\",\n            extra={\n                \"error_type\": type(e).__name__,\n                \"error_message\": str(e),\n                \"input_data\": data,\n            },\n            exc_info=True\n        )\n\n        # Increment error metric\n        error_counter.inc(labels={\"error_type\": type(e).__name__})\n\n        # Re-raise as ToolError\n        raise ToolError(f\"Operation failed: {str(e)}\") from e\n</code></pre>"},{"location":"concepts/error-handling/#best-practices","title":"Best Practices","text":""},{"location":"concepts/error-handling/#1-use-specific-exceptions","title":"1. Use Specific Exceptions","text":"<p>Use the most specific exception type that applies:</p> <pre><code># Good: Specific exception\nif not api_key:\n    raise ConfigurationError(\"API key is required\")\n\n# Bad: Generic exception\nif not api_key:\n    raise Exception(\"Missing API key\")\n</code></pre>"},{"location":"concepts/error-handling/#2-include-context-in-error-messages","title":"2. Include Context in Error Messages","text":"<p>Provide useful context in error messages:</p> <pre><code># Good: Contextual error message\nraise ToolError(f\"Failed to process order #{order_id}: Invalid payment method '{payment_method}'\")\n\n# Bad: Vague error message\nraise ToolError(\"Processing failed\")\n</code></pre>"},{"location":"concepts/error-handling/#3-preserve-error-chains","title":"3. Preserve Error Chains","text":"<p>Use <code>from</code> to preserve the original exception in the chain:</p> <pre><code>try:\n    # Operation that might fail\nexcept ValueError as e:\n    # Good: Preserves original exception\n    raise ToolError(\"Invalid input value\") from e\n\n    # Bad: Loses original exception\n    # raise ToolError(\"Invalid input value\")\n</code></pre>"},{"location":"concepts/error-handling/#4-handle-different-error-types-differently","title":"4. Handle Different Error Types Differently","text":"<p>Implement specific handling for different error types:</p> <pre><code>try:\n    result = await api_call()\nexcept ConnectionError:\n    # Network error - retry\n    return await retry_with_backoff(api_call)\nexcept AuthenticationError:\n    # Auth error - refresh credentials\n    await refresh_credentials()\n    return await api_call()\nexcept RateLimitError:\n    # Rate limit - wait\n    await asyncio.sleep(30)\n    return await api_call()\nexcept Exception as e:\n    # Unknown error - log and propagate\n    logger.error(f\"Unexpected error: {str(e)}\")\n    raise\n</code></pre>"},{"location":"concepts/error-handling/#5-dont-catch-too-broadly","title":"5. Don't Catch Too Broadly","text":"<p>Avoid catching exceptions too broadly:</p> <pre><code># Good: Catch specific exceptions\ntry:\n    data = await fetch_data()\nexcept ConnectionError:\n    # Handle connection issues\nexcept ValueError:\n    # Handle value errors\n\n# Bad: Catch everything\ntry:\n    data = await fetch_data()\nexcept Exception:\n    # Too broad\n</code></pre>"},{"location":"concepts/error-handling/#6-use-finally-for-cleanup","title":"6. Use Finally for Cleanup","text":"<p>Use <code>finally</code> for cleanup operations:</p> <pre><code>resource = None\ntry:\n    resource = acquire_resource()\n    # Use resource\nfinally:\n    # Clean up regardless of success or failure\n    if resource:\n        release_resource(resource)\n</code></pre>"},{"location":"concepts/error-handling/#conclusion","title":"Conclusion","text":"<p>Effective error handling is essential for building robust and reliable AI agents. FastADK provides a comprehensive error handling system with structured exceptions, retry mechanisms, and observability integration. By following the best practices outlined in this document, you can create agents that gracefully handle errors and provide a consistent user experience even when things go wrong.</p>"},{"location":"concepts/memory/","title":"Memory in FastADK","text":"<p>Memory is a crucial component of LLM agents, enabling them to maintain context across multiple interactions and retrieve relevant information from past conversations. This document explains how memory works in FastADK, the different types of memory backends available, and best practices for implementing memory in your agents.</p>"},{"location":"concepts/memory/#memory-concepts","title":"Memory Concepts","text":"<p>Memory in FastADK serves several important purposes:</p> <ol> <li>Conversation History: Storing the back-and-forth between the user and agent</li> <li>Context Retention: Maintaining information across multiple turns</li> <li>Knowledge Storage: Storing factual information for later retrieval</li> <li>User Preferences: Remembering user-specific settings and preferences</li> <li>Task State: Tracking the state of ongoing tasks</li> </ol>"},{"location":"concepts/memory/#memory-architecture","title":"Memory Architecture","text":"<pre><code>graph TD\n    A[Agent] --&gt; B[Memory Interface]\n    B --&gt; C[Memory Backend]\n    C --&gt; D[In-Memory]\n    C --&gt; E[Redis]\n    C --&gt; F[Vector Store]\n    C --&gt; G[SQL Database]\n    B --&gt; H[Context Policies]\n    H --&gt; I[Most Recent]\n    H --&gt; J[Summarize Older]\n    H --&gt; K[Hybrid Vector Retrieval]\n</code></pre>"},{"location":"concepts/memory/#memory-interface","title":"Memory Interface","text":"<p>The core memory interface in FastADK is the <code>MemoryBackend</code> abstract class, which defines methods for storing and retrieving data:</p> <pre><code>class MemoryBackend:\n    \"\"\"Abstract base class for memory backends.\"\"\"\n\n    async def get(self, key: str) -&gt; Any:\n        \"\"\"Get a value from memory.\"\"\"\n        raise NotImplementedError\n\n    async def set(self, key: str, value: Any) -&gt; None:\n        \"\"\"Set a value in memory.\"\"\"\n        raise NotImplementedError\n\n    async def delete(self, key: str) -&gt; None:\n        \"\"\"Delete a value from memory.\"\"\"\n        raise NotImplementedError\n\n    async def exists(self, key: str) -&gt; bool:\n        \"\"\"Check if a key exists in memory.\"\"\"\n        raise NotImplementedError\n\n    async def list_keys(self, pattern: str = \"*\") -&gt; List[str]:\n        \"\"\"List all keys matching a pattern.\"\"\"\n        raise NotImplementedError\n</code></pre>"},{"location":"concepts/memory/#memory-backends","title":"Memory Backends","text":"<p>FastADK offers several memory backend implementations:</p>"},{"location":"concepts/memory/#inmemorybackend","title":"InMemoryBackend","text":"<p>A simple in-memory backend suitable for development, testing, and simple applications:</p> <pre><code>from fastadk.memory import InMemoryBackend\n\nmemory = InMemoryBackend()\nawait memory.set(\"user_name\", \"Alice\")\nname = await memory.get(\"user_name\")  # Returns \"Alice\"\n</code></pre>"},{"location":"concepts/memory/#redisbackend","title":"RedisBackend","text":"<p>A Redis-based backend suitable for production and distributed systems:</p> <pre><code>from fastadk.memory import RedisBackend\n\nmemory = RedisBackend(\n    connection_string=\"redis://localhost:6379/0\",\n    namespace=\"my-agent\",\n    ttl_seconds=3600  # 1 hour expiration\n)\nawait memory.set(\"user_preferences\", {\"theme\": \"dark\", \"language\": \"en\"})\nprefs = await memory.get(\"user_preferences\")\n</code></pre>"},{"location":"concepts/memory/#vectormemorybackend","title":"VectorMemoryBackend","text":"<p>A vector database backend for semantic search and retrieval:</p> <pre><code>from fastadk.memory import VectorMemoryBackend\n\nmemory = VectorMemoryBackend(\n    embedding_model=\"text-embedding-3-small\",\n    embedding_provider=\"openai\",\n    dimension=512,\n    similarity_threshold=0.7\n)\n\n# Store text with embeddings\nawait memory.store_embedding(\n    text=\"FastADK is a Python framework for building AI agents\",\n    metadata={\"source\": \"documentation\", \"topic\": \"overview\"}\n)\n\n# Search for semantically similar content\nresults = await memory.search_embeddings(\"Python frameworks for AI agents\", limit=5)\n</code></pre>"},{"location":"concepts/memory/#sqlbackend","title":"SQLBackend","text":"<p>A SQL-based backend for structured data storage:</p> <pre><code>from fastadk.memory import SQLBackend\n\nmemory = SQLBackend(\n    connection_string=\"sqlite:///agent_memory.db\",\n    table_name=\"memory\",\n    namespace=\"my-agent\"\n)\n</code></pre>"},{"location":"concepts/memory/#context-policies","title":"Context Policies","text":"<p>Context policies in FastADK control how conversation history is managed and presented to the LLM. They address the challenge of limited context windows in language models.</p>"},{"location":"concepts/memory/#mostrecentpolicy","title":"MostRecentPolicy","text":"<p>Keeps only the most recent N messages:</p> <pre><code>from fastadk.core.context_policy import MostRecentPolicy\n\npolicy = MostRecentPolicy(max_messages=10)\n</code></pre>"},{"location":"concepts/memory/#summarizeolderpolicy","title":"SummarizeOlderPolicy","text":"<p>Summarizes older messages when the context gets too large:</p> <pre><code>from fastadk.core.context_policy import SummarizeOlderPolicy\n\npolicy = SummarizeOlderPolicy(\n    threshold_tokens=3000,\n    summarizer=model_provider,  # Uses the agent's model to create summaries\n    keep_recent=5  # Always keep the 5 most recent messages without summarizing\n)\n</code></pre>"},{"location":"concepts/memory/#hybridvectorretrievalpolicy","title":"HybridVectorRetrievalPolicy","text":"<p>Combines recency with semantic relevance:</p> <pre><code>from fastadk.core.context_policy import HybridVectorRetrievalPolicy\n\npolicy = HybridVectorRetrievalPolicy(\n    embedding_model=\"text-embedding-3-small\",\n    embedding_provider=\"openai\",\n    recent_k=5,  # Keep 5 most recent messages\n    vector_k=10,  # Retrieve 10 most relevant messages\n    max_tokens=4000  # Total token budget\n)\n</code></pre>"},{"location":"concepts/memory/#implementing-memory-in-agents","title":"Implementing Memory in Agents","text":""},{"location":"concepts/memory/#basic-memory-usage","title":"Basic Memory Usage","text":"<pre><code>from fastadk import Agent, BaseAgent\nfrom fastadk.memory import InMemoryBackend\n\n@Agent(model=\"gemini-1.5-pro\")\nclass AssistantWithMemory(BaseAgent):\n    def __init__(self):\n        super().__init__()\n        self.memory = InMemoryBackend()\n\n    @tool\n    async def remember_name(self, name: str) -&gt; str:\n        \"\"\"Remember the user's name.\"\"\"\n        await self.memory.set(\"user_name\", name)\n        return f\"I'll remember that your name is {name}.\"\n\n    @tool\n    async def recall_name(self) -&gt; str:\n        \"\"\"Recall the user's name if previously stored.\"\"\"\n        name = await self.memory.get(\"user_name\")\n        if name:\n            return f\"Your name is {name}.\"\n        else:\n            return \"I don't know your name yet.\"\n</code></pre>"},{"location":"concepts/memory/#persistent-memory","title":"Persistent Memory","text":"<p>For agents that need to retain information across sessions:</p> <pre><code>from fastadk import Agent, BaseAgent\nfrom fastadk.memory import RedisBackend\n\n@Agent(model=\"gemini-1.5-pro\")\nclass PersistentAssistant(BaseAgent):\n    def __init__(self, user_id: str):\n        super().__init__()\n        self.user_id = user_id\n        self.memory = RedisBackend(\n            connection_string=\"redis://localhost:6379/0\",\n            namespace=f\"user:{user_id}\",\n            ttl_seconds=604800  # 1 week\n        )\n\n    async def on_start(self):\n        \"\"\"Called when agent starts processing a request.\"\"\"\n        # Load user preferences and history\n        self.preferences = await self.memory.get(\"preferences\") or {}\n        history_count = await self.memory.get(\"interaction_count\") or 0\n\n        if history_count &gt; 0:\n            # Personalize greeting based on history\n            return f\"Welcome back! This is your {history_count + 1}th interaction.\"\n\n    async def on_finish(self):\n        \"\"\"Called when agent finishes processing a request.\"\"\"\n        # Update interaction counter\n        count = await self.memory.get(\"interaction_count\") or 0\n        await self.memory.set(\"interaction_count\", count + 1)\n\n        # Store last interaction time\n        from datetime import datetime\n        await self.memory.set(\"last_interaction\", datetime.now().isoformat())\n</code></pre>"},{"location":"concepts/memory/#conversation-history-with-context-policies","title":"Conversation History with Context Policies","text":"<pre><code>from fastadk import Agent, BaseAgent\nfrom fastadk.memory import InMemoryBackend\nfrom fastadk.core.context_policy import SummarizeOlderPolicy\n\n@Agent(model=\"gemini-1.5-pro\")\nclass ContextAwareAgent(BaseAgent):\n    def __init__(self):\n        super().__init__()\n        self.memory = InMemoryBackend()\n\n        # Set up context policy\n        self.context_policy = SummarizeOlderPolicy(\n            threshold_tokens=3000,\n            summarizer=self.model,\n            keep_recent=5\n        )\n\n    async def _prepare_context(self, prompt: str) -&gt; str:\n        \"\"\"Override context preparation to apply context policy.\"\"\"\n        # Get conversation history\n        history = await self.memory.get(\"conversation\") or []\n\n        # Add current prompt to history\n        history.append({\"role\": \"user\", \"content\": prompt})\n\n        # Apply context policy\n        optimized_history = await self.context_policy.apply(history)\n\n        # Store updated history\n        await self.memory.set(\"conversation\", optimized_history)\n\n        # Return formatted context for the model\n        return self._format_context(optimized_history)\n</code></pre>"},{"location":"concepts/memory/#semantic-memory-with-vector-storage","title":"Semantic Memory with Vector Storage","text":"<pre><code>from fastadk import Agent, BaseAgent, tool\nfrom fastadk.memory import VectorMemoryBackend\nfrom typing import List, Dict\n\n@Agent(model=\"gemini-1.5-pro\")\nclass KnowledgeBaseAgent(BaseAgent):\n    def __init__(self):\n        super().__init__()\n        self.memory = VectorMemoryBackend(\n            embedding_model=\"text-embedding-3-small\",\n            embedding_provider=\"openai\",\n            similarity_threshold=0.7\n        )\n\n    @tool\n    async def add_to_knowledge(self, text: str, source: str = None) -&gt; str:\n        \"\"\"Add information to the knowledge base.\"\"\"\n        doc_id = await self.memory.store_embedding(\n            text=text,\n            metadata={\"source\": source, \"timestamp\": datetime.now().isoformat()}\n        )\n        return f\"Added to knowledge base with ID: {doc_id}\"\n\n    @tool\n    async def search_knowledge(self, query: str, limit: int = 5) -&gt; List[Dict]:\n        \"\"\"Search the knowledge base for relevant information.\"\"\"\n        results = await self.memory.search_embeddings(query, limit=limit)\n        return [\n            {\n                \"text\": item[\"text\"],\n                \"relevance\": item[\"score\"],\n                \"source\": item[\"metadata\"].get(\"source\", \"unknown\"),\n                \"timestamp\": item[\"metadata\"].get(\"timestamp\")\n            }\n            for item in results\n        ]\n\n    async def run(self, prompt: str) -&gt; str:\n        \"\"\"Override run to include relevant knowledge.\"\"\"\n        # Find relevant knowledge\n        knowledge = await self.search_knowledge(prompt)\n\n        # Prepare context with knowledge\n        context = \"Relevant information from my knowledge base:\\n\\n\"\n        for item in knowledge:\n            context += f\"- {item['text']}\\n\"\n        context += f\"\\nUser question: {prompt}\"\n\n        # Generate response with context\n        response = await self.model.generate(context)\n        return response\n</code></pre>"},{"location":"concepts/memory/#advanced-memory-patterns","title":"Advanced Memory Patterns","text":""},{"location":"concepts/memory/#hierarchical-memory","title":"Hierarchical Memory","text":"<p>A combination of different memory types for different purposes:</p> <pre><code>from fastadk import Agent, BaseAgent\nfrom fastadk.memory import InMemoryBackend, RedisBackend, VectorMemoryBackend\n\n@Agent(model=\"gemini-1.5-pro\")\nclass HierarchicalMemoryAgent(BaseAgent):\n    def __init__(self, user_id: str):\n        super().__init__()\n\n        # Short-term memory (conversation)\n        self.short_term = InMemoryBackend()\n\n        # Medium-term memory (user preferences, session state)\n        self.medium_term = RedisBackend(\n            connection_string=\"redis://localhost:6379/0\",\n            namespace=f\"user:{user_id}:session\",\n            ttl_seconds=3600  # 1 hour\n        )\n\n        # Long-term memory (knowledge, historical data)\n        self.long_term = VectorMemoryBackend(\n            embedding_model=\"text-embedding-3-small\",\n            embedding_provider=\"openai\"\n        )\n</code></pre>"},{"location":"concepts/memory/#memory-with-summarization","title":"Memory with Summarization","text":"<p>Periodically summarize conversation to save context space:</p> <pre><code>from fastadk import Agent, BaseAgent\nfrom fastadk.memory import InMemoryBackend\n\n@Agent(model=\"gemini-1.5-pro\")\nclass SummarizingAgent(BaseAgent):\n    def __init__(self):\n        super().__init__()\n        self.memory = InMemoryBackend()\n        self.max_messages = 10\n\n    async def _update_conversation(self, role: str, content: str):\n        \"\"\"Add message to conversation and summarize if needed.\"\"\"\n        conversation = await self.memory.get(\"conversation\") or []\n        conversation.append({\"role\": role, \"content\": content})\n\n        # If conversation is too long, summarize\n        if len(conversation) &gt; self.max_messages:\n            # Extract old messages to summarize\n            to_summarize = conversation[:-self.max_messages]\n            recent = conversation[-self.max_messages:]\n\n            # Create summary\n            summary_text = \"\\n\".join([f\"{m['role']}: {m['content']}\" for m in to_summarize])\n            summary_prompt = f\"Summarize this conversation:\\n{summary_text}\"\n            summary = await self.model.generate(summary_prompt)\n\n            # Replace old messages with summary\n            conversation = [{\"role\": \"system\", \"content\": f\"Previous conversation summary: {summary}\"}] + recent\n\n        # Store updated conversation\n        await self.memory.set(\"conversation\", conversation)\n</code></pre>"},{"location":"concepts/memory/#best-practices","title":"Best Practices","text":""},{"location":"concepts/memory/#memory-segmentation","title":"Memory Segmentation","text":"<p>Divide memory into logical segments based on purpose:</p> <pre><code># User profile information\nawait memory.set(\"profile:name\", \"Alice\")\nawait memory.set(\"profile:preferences\", {\"theme\": \"dark\"})\n\n# Conversation state\nawait memory.set(\"conversation:current_topic\", \"travel plans\")\nawait memory.set(\"conversation:messages\", [...])\n\n# Task-specific data\nawait memory.set(\"task:booking:destination\", \"Paris\")\nawait memory.set(\"task:booking:dates\", [\"2025-08-01\", \"2025-08-07\"])\n</code></pre>"},{"location":"concepts/memory/#ttl-management","title":"TTL Management","text":"<p>Set appropriate Time-To-Live (TTL) values for different types of data:</p> <pre><code># Short-lived session data (1 hour)\nawait memory.set(\"session:id\", \"abc123\", ttl_seconds=3600)\n\n# Medium-term preferences (1 week)\nawait memory.set(\"preferences\", {...}, ttl_seconds=604800)\n\n# Long-term knowledge (permanent)\nawait memory.set(\"knowledge:facts\", [...], ttl_seconds=None)\n</code></pre>"},{"location":"concepts/memory/#secure-storage","title":"Secure Storage","text":"<p>Be careful about storing sensitive information:</p> <pre><code># Store a reference or token, not the actual sensitive data\nawait memory.set(\"user:payment\", {\"token\": \"payment_token_123\", \"last4\": \"4242\"})\n\n# Or use encryption for sensitive data\nfrom cryptography.fernet import Fernet\nkey = Fernet.generate_key()\ncipher = Fernet(key)\nencrypted = cipher.encrypt(sensitive_data.encode())\nawait memory.set(\"encrypted:data\", encrypted)\n</code></pre>"},{"location":"concepts/memory/#performance-optimization","title":"Performance Optimization","text":"<p>Consider caching frequently accessed data:</p> <pre><code>async def get_user_profile(user_id: str) -&gt; Dict:\n    \"\"\"Get user profile with caching.\"\"\"\n    cache_key = f\"cache:user_profile:{user_id}\"\n\n    # Try to get from cache first\n    profile = await self.memory.get(cache_key)\n    if profile:\n        return profile\n\n    # If not in cache, fetch from database\n    profile = await database.get_user(user_id)\n\n    # Store in cache with expiration\n    await self.memory.set(cache_key, profile, ttl_seconds=300)  # 5 minutes\n\n    return profile\n</code></pre>"},{"location":"concepts/memory/#conclusion","title":"Conclusion","text":"<p>Memory is a fundamental component of effective AI agents, enabling them to maintain context, learn from past interactions, and provide personalized experiences. FastADK provides a flexible memory system with multiple backends and context policies to address a wide range of agent requirements.</p> <p>By choosing the right memory backend and implementing appropriate context policies, you can build agents that maintain coherent conversations, retrieve relevant information, and deliver increasingly personalized experiences over time.</p>"},{"location":"concepts/tools/","title":"Tools in FastADK","text":"<p>Tools are the primary way for agents to interact with external systems, data sources, and services. This document explains how tools work in FastADK, how to create them, and best practices for tool development.</p>"},{"location":"concepts/tools/#what-are-tools","title":"What Are Tools?","text":"<p>In the context of FastADK, a tool is a function that an agent can call to perform a specific task. Tools can:</p> <ul> <li>Fetch data from APIs or databases</li> <li>Perform calculations</li> <li>Manipulate data</li> <li>Interact with external systems</li> <li>Execute business logic</li> </ul> <p>Tools bridge the gap between the language model's reasoning capabilities and the ability to take actions in the real world.</p>"},{"location":"concepts/tools/#creating-tools","title":"Creating Tools","text":"<p>FastADK makes it easy to create tools using the <code>@tool</code> decorator:</p> <pre><code>from fastadk import Agent, BaseAgent, tool\nfrom typing import Dict, List\n\n@Agent(model=\"gemini-1.5-pro\")\nclass WeatherAgent(BaseAgent):\n    @tool\n    def get_weather(self, city: str, country: str = \"US\") -&gt; Dict:\n        \"\"\"\n        Get the current weather for a city.\n\n        Args:\n            city: The name of the city\n            country: The country code (default: \"US\")\n\n        Returns:\n            A dictionary containing weather information\n        \"\"\"\n        # Tool implementation goes here\n        return {\n            \"city\": city,\n            \"country\": country,\n            \"temperature\": 22.5,\n            \"condition\": \"Sunny\",\n            \"humidity\": 65\n        }\n</code></pre>"},{"location":"concepts/tools/#tool-features","title":"Tool Features","text":""},{"location":"concepts/tools/#type-hints","title":"Type Hints","text":"<p>FastADK uses Python type hints to validate inputs and outputs. This helps prevent errors and provides better documentation.</p> <pre><code>@tool\ndef calculate_area(length: float, width: float) -&gt; float:\n    \"\"\"Calculate the area of a rectangle.\"\"\"\n    return length * width\n</code></pre>"},{"location":"concepts/tools/#default-parameters","title":"Default Parameters","text":"<p>Tools can have default parameters to make them more flexible:</p> <pre><code>@tool\ndef search_products(\n    query: str,\n    category: str = \"all\",\n    max_results: int = 10,\n    sort_by: str = \"relevance\"\n) -&gt; List[Dict]:\n    \"\"\"Search for products in our catalog.\"\"\"\n    # Implementation\n</code></pre>"},{"location":"concepts/tools/#documentation","title":"Documentation","text":"<p>Good documentation is crucial for tools. The LLM uses the docstring to understand when and how to use the tool. Include:</p> <ul> <li>A clear description of what the tool does</li> <li>Parameter descriptions</li> <li>Return value information</li> <li>Examples if needed</li> </ul>"},{"location":"concepts/tools/#advanced-configuration","title":"Advanced Configuration","text":"<p>The <code>@tool</code> decorator accepts several configuration options:</p> <pre><code>@tool(\n    name=\"fetch_data\",               # Custom name (defaults to function name)\n    description=\"Fetch data from API\", # Override docstring description\n    required=[\"api_key\", \"query\"],   # Required parameters\n    cache_ttl=300,                   # Cache results for 5 minutes\n    retry=3,                         # Retry up to 3 times on failure\n    timeout=10,                      # Timeout after 10 seconds\n    rate_limit=100                   # Max calls per minute\n)\ndef fetch_data_from_api(api_key: str, query: str) -&gt; Dict:\n    \"\"\"Implementation details...\"\"\"\n</code></pre>"},{"location":"concepts/tools/#tool-categories","title":"Tool Categories","text":""},{"location":"concepts/tools/#data-retrieval-tools","title":"Data Retrieval Tools","text":"<p>These tools fetch information from databases, APIs, or other data sources.</p> <pre><code>@tool\nasync def search_database(query: str) -&gt; List[Dict]:\n    \"\"\"Search the database for records matching the query.\"\"\"\n    # Database connection and query logic\n</code></pre>"},{"location":"concepts/tools/#computational-tools","title":"Computational Tools","text":"<p>These tools perform calculations or transformations on data.</p> <pre><code>@tool\ndef analyze_sentiment(text: str) -&gt; Dict:\n    \"\"\"Analyze the sentiment of the provided text.\"\"\"\n    # Sentiment analysis logic\n</code></pre>"},{"location":"concepts/tools/#integration-tools","title":"Integration Tools","text":"<p>These tools integrate with external systems and APIs.</p> <pre><code>@tool\nasync def send_email(to: str, subject: str, body: str) -&gt; bool:\n    \"\"\"Send an email to the specified recipient.\"\"\"\n    # Email sending logic\n</code></pre>"},{"location":"concepts/tools/#user-interaction-tools","title":"User Interaction Tools","text":"<p>These tools facilitate interaction with users.</p> <pre><code>@tool\ndef format_response(data: Dict, format: str = \"text\") -&gt; str:\n    \"\"\"Format data for presentation to the user.\"\"\"\n    # Formatting logic\n</code></pre>"},{"location":"concepts/tools/#best-practices","title":"Best Practices","text":""},{"location":"concepts/tools/#make-tools-atomic","title":"Make Tools Atomic","text":"<p>Each tool should do one thing well. Instead of a single <code>manage_user</code> tool, consider separate tools for <code>create_user</code>, <code>update_user</code>, <code>delete_user</code>, etc.</p>"},{"location":"concepts/tools/#validate-inputs","title":"Validate Inputs","text":"<p>Even though FastADK provides basic type validation, consider adding additional validation in your tool implementation:</p> <pre><code>@tool\ndef transfer_money(from_account: str, to_account: str, amount: float) -&gt; Dict:\n    \"\"\"Transfer money between accounts.\"\"\"\n    if amount &lt;= 0:\n        raise ValueError(\"Amount must be positive\")\n    if from_account == to_account:\n        raise ValueError(\"Cannot transfer to the same account\")\n    # Transfer logic\n</code></pre>"},{"location":"concepts/tools/#handle-errors-gracefully","title":"Handle Errors Gracefully","text":"<p>Use FastADK's error handling to provide informative error messages:</p> <pre><code>from fastadk.core.exceptions import ToolError\n\n@tool\ndef fetch_data(url: str) -&gt; Dict:\n    \"\"\"Fetch data from a URL.\"\"\"\n    try:\n        # Fetch logic\n    except ConnectionError:\n        raise ToolError(\"Could not connect to the server. Please check the URL or try again later.\")\n    except Exception as e:\n        raise ToolError(f\"An error occurred: {str(e)}\")\n</code></pre>"},{"location":"concepts/tools/#provide-context-in-responses","title":"Provide Context in Responses","text":"<p>Include contextual information in your tool responses to help the agent understand the results:</p> <pre><code>@tool\ndef search_products(query: str, max_results: int = 5) -&gt; Dict:\n    \"\"\"Search for products in the catalog.\"\"\"\n    results = # Search logic\n\n    return {\n        \"query\": query,\n        \"total_matches\": len(all_results),\n        \"showing\": min(len(all_results), max_results),\n        \"results\": results[:max_results]\n    }\n</code></pre>"},{"location":"concepts/tools/#document-side-effects","title":"Document Side Effects","text":"<p>If your tool has side effects (like modifying a database or sending an email), clearly document this in the docstring:</p> <pre><code>@tool\ndef create_order(product_id: str, quantity: int, customer_id: str) -&gt; Dict:\n    \"\"\"\n    Create a new order in the system.\n\n    Note: This tool will charge the customer's account and initiate shipping.\n    \"\"\"\n    # Order creation logic\n</code></pre>"},{"location":"concepts/tools/#tool-patterns","title":"Tool Patterns","text":""},{"location":"concepts/tools/#chaining-tools","title":"Chaining Tools","text":"<p>Complex operations can be broken down into multiple tools that can be chained together:</p> <pre><code>@Agent(model=\"gemini-1.5-pro\")\nclass OrderProcessor(BaseAgent):\n    @tool\n    def check_inventory(self, product_id: str) -&gt; Dict:\n        \"\"\"Check if a product is in stock.\"\"\"\n        # Inventory check logic\n\n    @tool\n    def calculate_price(self, product_id: str, quantity: int) -&gt; Dict:\n        \"\"\"Calculate the total price including taxes and shipping.\"\"\"\n        # Price calculation logic\n\n    @tool\n    def process_payment(self, customer_id: str, amount: float) -&gt; Dict:\n        \"\"\"Process payment for an order.\"\"\"\n        # Payment processing logic\n\n    @tool\n    def create_order(self, product_id: str, quantity: int, customer_id: str) -&gt; Dict:\n        \"\"\"Create a new order after inventory and payment are confirmed.\"\"\"\n        # Order creation logic\n</code></pre>"},{"location":"concepts/tools/#tool-composition","title":"Tool Composition","text":"<p>You can create higher-level tools that use other tools:</p> <pre><code>@tool\nasync def complete_purchase(self, product_id: str, quantity: int, customer_id: str) -&gt; Dict:\n    \"\"\"Process a complete purchase flow.\"\"\"\n    # First check inventory\n    inventory = await self.check_inventory(product_id)\n    if not inventory[\"in_stock\"] or inventory[\"quantity\"] &lt; quantity:\n        return {\"success\": False, \"reason\": \"Not enough inventory\"}\n\n    # Calculate price\n    price_info = await self.calculate_price(product_id, quantity)\n\n    # Process payment\n    payment = await self.process_payment(customer_id, price_info[\"total\"])\n    if not payment[\"success\"]:\n        return {\"success\": False, \"reason\": f\"Payment failed: {payment['message']}\"}\n\n    # Create order\n    order = await self.create_order(product_id, quantity, customer_id)\n\n    return {\n        \"success\": True,\n        \"order_id\": order[\"id\"],\n        \"total\": price_info[\"total\"],\n        \"estimated_delivery\": order[\"estimated_delivery\"]\n    }\n</code></pre>"},{"location":"concepts/tools/#conclusion","title":"Conclusion","text":"<p>Tools are the primary way for FastADK agents to interact with the world and perform useful tasks. By designing tools carefully and following best practices, you can create agents that are capable of solving complex problems by combining reasoning with action.</p> <p>For practical examples of tool implementations, see the Examples section.</p>"},{"location":"concepts/workflows/","title":"Workflows in FastADK","text":"<p>Workflows in FastADK provide a powerful system for orchestrating complex processes involving multiple agents, tools, and processing steps. This document explains the workflow system's architecture, components, and patterns for implementing effective workflows.</p>"},{"location":"concepts/workflows/#introduction-to-workflows","title":"Introduction to Workflows","text":"<p>A workflow is a sequence of steps that process data and perform actions to achieve a complex goal. In the context of FastADK, workflows enable you to:</p> <ol> <li>Coordinate multiple agents for complex tasks</li> <li>Process data through a series of transformations</li> <li>Handle branching logic and conditional execution</li> <li>Run steps in parallel for improved performance</li> <li>Manage errors and retries at each step</li> </ol>"},{"location":"concepts/workflows/#workflow-architecture","title":"Workflow Architecture","text":"<pre><code>graph TD\n    A[Workflow] --&gt; B[Steps]\n    B --&gt; C[FunctionStep]\n    B --&gt; D[AgentStep]\n    B --&gt; E[TransformStep]\n    B --&gt; F[ConditionalStep]\n    B --&gt; G[ParallelStep]\n    B --&gt; H[SequentialStep]\n    B --&gt; I[WorkflowStep]\n    I --&gt; A\n</code></pre>"},{"location":"concepts/workflows/#core-components","title":"Core Components","text":""},{"location":"concepts/workflows/#workflow","title":"Workflow","text":"<p>The <code>Workflow</code> class is the main container that manages the execution of steps:</p> <pre><code>from fastadk.core.workflow import Workflow\n\n# Create a sequential workflow\nworkflow = Workflow.sequence(step1, step2, step3, name=\"My Workflow\")\n\n# Create a parallel workflow\nworkflow = Workflow.parallel(step1, step2, step3, name=\"Parallel Processing\")\n\n# Execute a workflow\nresult = await workflow.execute(input_data)\n</code></pre>"},{"location":"concepts/workflows/#step","title":"Step","text":"<p>A <code>Step</code> is a unit of work in a workflow. FastADK provides several built-in step types:</p> <pre><code>from fastadk.core.workflow import step, transform, conditional\n\n# Function step\n@step(name=\"Data Loader\")\nasync def load_data(source: str) -&gt; dict:\n    \"\"\"Load data from a source.\"\"\"\n    # Implementation...\n    return {\"source\": source, \"data\": [1, 2, 3]}\n\n# Transform step (synchronous)\n@transform(name=\"Formatter\")\ndef format_result(data: dict) -&gt; str:\n    \"\"\"Format the results for presentation.\"\"\"\n    return f\"Data from {data['source']}: {data['processed']}\"\n\n# Conditional step\n@conditional(name=\"Validator\")\ndef should_process(data: dict) -&gt; bool:\n    \"\"\"Determine if data should be processed.\"\"\"\n    return len(data.get(\"data\", [])) &gt; 0\n</code></pre>"},{"location":"concepts/workflows/#creating-workflows","title":"Creating Workflows","text":""},{"location":"concepts/workflows/#sequential-workflows","title":"Sequential Workflows","text":"<p>Sequential workflows execute steps one after another, passing the output of each step to the next:</p> <pre><code>from fastadk.core.workflow import Workflow, step\n\n@step(name=\"Fetch Data\")\nasync def fetch_data(query: str) -&gt; dict:\n    \"\"\"Fetch data based on a query.\"\"\"\n    # Implementation...\n    return {\"query\": query, \"results\": [...]}\n\n@step(name=\"Process Data\")\nasync def process_data(data: dict) -&gt; dict:\n    \"\"\"Process the fetched data.\"\"\"\n    results = data[\"results\"]\n    processed = [item * 2 for item in results]\n    return {\"query\": data[\"query\"], \"processed\": processed}\n\n@step(name=\"Format Results\")\nasync def format_results(data: dict) -&gt; str:\n    \"\"\"Format the processed data for presentation.\"\"\"\n    return f\"Results for '{data['query']}': {data['processed']}\"\n\n# Create a sequential workflow\ndata_workflow = Workflow.sequence(\n    fetch_data,\n    process_data,\n    format_results,\n    name=\"Data Processing Pipeline\"\n)\n\n# Execute the workflow\nresult = await data_workflow.execute(\"example query\")\n</code></pre>"},{"location":"concepts/workflows/#parallel-workflows","title":"Parallel Workflows","text":"<p>Parallel workflows execute multiple steps concurrently:</p> <pre><code>from fastadk.core.workflow import Workflow, step\n\n@step(name=\"Fetch Weather\")\nasync def fetch_weather(city: str) -&gt; dict:\n    \"\"\"Fetch weather data for a city.\"\"\"\n    # Implementation...\n    return {\"city\": city, \"weather\": \"sunny\", \"temp\": 22}\n\n@step(name=\"Fetch News\")\nasync def fetch_news(city: str) -&gt; dict:\n    \"\"\"Fetch news for a city.\"\"\"\n    # Implementation...\n    return {\"city\": city, \"headlines\": [\"Local event\", \"Sports update\"]}\n\n@step(name=\"Fetch Attractions\")\nasync def fetch_attractions(city: str) -&gt; dict:\n    \"\"\"Fetch tourist attractions for a city.\"\"\"\n    # Implementation...\n    return {\"city\": city, \"attractions\": [\"Museum\", \"Park\", \"Monument\"]}\n\n@step(name=\"Combine Results\")\nasync def combine_results(results: list) -&gt; dict:\n    \"\"\"Combine results from parallel steps.\"\"\"\n    weather, news, attractions = results\n    return {\n        \"city\": weather[\"city\"],\n        \"weather\": weather[\"weather\"],\n        \"temp\": weather[\"temp\"],\n        \"headlines\": news[\"headlines\"],\n        \"attractions\": attractions[\"attractions\"]\n    }\n\n# Create a workflow with parallel steps\ncity_info_workflow = Workflow.sequence(\n    Workflow.parallel(\n        fetch_weather,\n        fetch_news,\n        fetch_attractions\n    ),\n    combine_results,\n    name=\"City Information Workflow\"\n)\n\n# Execute the workflow\nresult = await city_info_workflow.execute(\"London\")\n</code></pre>"},{"location":"concepts/workflows/#conditional-workflows","title":"Conditional Workflows","text":"<p>Conditional workflows execute different steps based on conditions:</p> <pre><code>from fastadk.core.workflow import Workflow, step, conditional\n\n@step(name=\"Analyze Request\")\nasync def analyze_request(request: str) -&gt; dict:\n    \"\"\"Analyze a user request to determine the type.\"\"\"\n    if \"weather\" in request.lower():\n        type = \"weather\"\n    elif \"news\" in request.lower():\n        type = \"news\"\n    else:\n        type = \"unknown\"\n    return {\"request\": request, \"type\": type}\n\n@step(name=\"Get Weather\")\nasync def get_weather(data: dict) -&gt; dict:\n    \"\"\"Get weather information.\"\"\"\n    # Extract location from request\n    # Implementation...\n    return {\"response\": f\"The weather is sunny in Paris.\"}\n\n@step(name=\"Get News\")\nasync def get_news(data: dict) -&gt; dict:\n    \"\"\"Get news information.\"\"\"\n    # Implementation...\n    return {\"response\": f\"Latest headlines: New policy announced.\"}\n\n@step(name=\"Default Response\")\nasync def default_response(data: dict) -&gt; dict:\n    \"\"\"Provide a default response.\"\"\"\n    return {\"response\": f\"I'm not sure how to help with '{data['request']}'.\"}\n\n@conditional(name=\"Is Weather Request\")\ndef is_weather_request(data: dict) -&gt; bool:\n    \"\"\"Check if this is a weather request.\"\"\"\n    return data[\"type\"] == \"weather\"\n\n@conditional(name=\"Is News Request\")\ndef is_news_request(data: dict) -&gt; bool:\n    \"\"\"Check if this is a news request.\"\"\"\n    return data[\"type\"] == \"news\"\n\n# Create a conditional workflow\nrequest_workflow = Workflow.sequence(\n    analyze_request,\n    Workflow.conditional(\n        is_weather_request,\n        get_weather,\n        Workflow.conditional(\n            is_news_request,\n            get_news,\n            default_response\n        )\n    ),\n    name=\"Request Handler Workflow\"\n)\n\n# Execute the workflow\nresult = await request_workflow.execute(\"What's the weather in Paris?\")\n</code></pre>"},{"location":"concepts/workflows/#advanced-workflow-patterns","title":"Advanced Workflow Patterns","text":""},{"location":"concepts/workflows/#multi-agent-workflows","title":"Multi-Agent Workflows","text":"<p>Workflows can coordinate multiple agents for complex tasks:</p> <pre><code>from fastadk.core.workflow import Workflow, step\nfrom fastadk import Agent, BaseAgent\n\n@Agent(model=\"gemini-1.5-pro\", description=\"Researcher\")\nclass ResearchAgent(BaseAgent):\n    # Agent implementation...\n    pass\n\n@Agent(model=\"gemini-1.5-pro\", description=\"Analyst\")\nclass AnalysisAgent(BaseAgent):\n    # Agent implementation...\n    pass\n\n@Agent(model=\"gemini-1.5-pro\", description=\"Writer\")\nclass WriterAgent(BaseAgent):\n    # Agent implementation...\n    pass\n\n@step(name=\"Research Topic\")\nasync def research_topic(topic: str) -&gt; dict:\n    \"\"\"Research a topic to gather information.\"\"\"\n    agent = ResearchAgent()\n    research = await agent.run(f\"Research the following topic: {topic}\")\n    return {\"topic\": topic, \"research\": research}\n\n@step(name=\"Analyze Research\")\nasync def analyze_research(data: dict) -&gt; dict:\n    \"\"\"Analyze the research to identify key insights.\"\"\"\n    agent = AnalysisAgent()\n    analysis = await agent.run(\n        f\"Analyze this research on {data['topic']}:\\n\\n{data['research']}\"\n    )\n    return {\"topic\": data[\"topic\"], \"research\": data[\"research\"], \"analysis\": analysis}\n\n@step(name=\"Write Report\")\nasync def write_report(data: dict) -&gt; str:\n    \"\"\"Write a comprehensive report based on research and analysis.\"\"\"\n    agent = WriterAgent()\n    report = await agent.run(\n        f\"Write a report on {data['topic']} based on this research and analysis:\\n\\n\"\n        f\"Research:\\n{data['research']}\\n\\n\"\n        f\"Analysis:\\n{data['analysis']}\"\n    )\n    return report\n\n# Create a multi-agent workflow\nreport_workflow = Workflow.sequence(\n    research_topic,\n    analyze_research,\n    write_report,\n    name=\"Report Generation Workflow\"\n)\n\n# Execute the workflow\nreport = await report_workflow.execute(\"Impact of artificial intelligence on healthcare\")\n</code></pre>"},{"location":"concepts/workflows/#error-handling-in-workflows","title":"Error Handling in Workflows","text":"<p>Implement error handling for robust workflows:</p> <pre><code>from fastadk.core.workflow import Workflow, step\nfrom fastadk.core.exceptions import WorkflowError\n\n@step(name=\"Risky Operation\")\nasync def risky_operation(data: dict) -&gt; dict:\n    \"\"\"Perform an operation that might fail.\"\"\"\n    try:\n        # Implementation that might fail\n        if data.get(\"trigger_error\", False):\n            raise ValueError(\"Simulated error\")\n        return {\"status\": \"success\", \"result\": \"Operation completed\"}\n    except Exception as e:\n        # Log the error\n        import logging\n        logging.error(f\"Operation failed: {str(e)}\")\n        # Return error information\n        return {\"status\": \"error\", \"error\": str(e)}\n\n@step(name=\"Error Handler\")\nasync def handle_error(data: dict) -&gt; dict:\n    \"\"\"Handle errors from previous steps.\"\"\"\n    if data.get(\"status\") == \"error\":\n        # Implement recovery logic\n        return {\"status\": \"recovered\", \"result\": \"Used fallback method\"}\n    return data\n\n# Create a workflow with error handling\nrobust_workflow = Workflow.sequence(\n    risky_operation,\n    handle_error,\n    name=\"Error-Handling Workflow\"\n)\n\n# Execute the workflow\ntry:\n    result = await robust_workflow.execute({\"trigger_error\": True})\n    print(f\"Workflow completed with result: {result}\")\nexcept WorkflowError as e:\n    print(f\"Workflow failed: {str(e)}\")\n</code></pre>"},{"location":"concepts/workflows/#data-transformation-workflows","title":"Data Transformation Workflows","text":"<p>Create workflows focused on data transformation:</p> <pre><code>from fastadk.core.workflow import Workflow, step, transform\nfrom typing import List, Dict\n\n@step(name=\"Extract Data\")\nasync def extract_data(source: str) -&gt; List[Dict]:\n    \"\"\"Extract raw data from a source.\"\"\"\n    # Implementation...\n    return [\n        {\"id\": 1, \"raw_value\": 100},\n        {\"id\": 2, \"raw_value\": 200},\n        {\"id\": 3, \"raw_value\": 300}\n    ]\n\n@transform(name=\"Clean Data\")\ndef clean_data(items: List[Dict]) -&gt; List[Dict]:\n    \"\"\"Clean and validate the data.\"\"\"\n    return [\n        {**item, \"cleaned\": True}\n        for item in items\n        if item.get(\"raw_value\", 0) &gt; 0\n    ]\n\n@transform(name=\"Transform Data\")\ndef transform_data(items: List[Dict]) -&gt; List[Dict]:\n    \"\"\"Apply transformations to the data.\"\"\"\n    return [\n        {**item, \"transformed_value\": item[\"raw_value\"] * 1.5}\n        for item in items\n    ]\n\n@transform(name=\"Aggregate Data\")\ndef aggregate_data(items: List[Dict]) -&gt; Dict:\n    \"\"\"Aggregate the transformed data.\"\"\"\n    total = sum(item[\"transformed_value\"] for item in items)\n    count = len(items)\n    return {\n        \"total\": total,\n        \"count\": count,\n        \"average\": total / count if count &gt; 0 else 0,\n        \"items\": items\n    }\n\n# Create a data transformation workflow\netl_workflow = Workflow.sequence(\n    extract_data,\n    clean_data,\n    transform_data,\n    aggregate_data,\n    name=\"ETL Workflow\"\n)\n\n# Execute the workflow\nresult = await etl_workflow.execute(\"data_source\")\n</code></pre>"},{"location":"concepts/workflows/#workflow-composition-and-reuse","title":"Workflow Composition and Reuse","text":"<p>Workflows can be composed and reused as components in larger workflows:</p> <pre><code>from fastadk.core.workflow import Workflow, step, WorkflowStep\n\n# Define reusable workflows\ndata_processing_workflow = Workflow.sequence(\n    fetch_data,\n    process_data,\n    name=\"Data Processing\"\n)\n\nreporting_workflow = Workflow.sequence(\n    generate_charts,\n    compile_report,\n    name=\"Reporting\"\n)\n\n# Create a step that uses an existing workflow\n@step(name=\"Process Data Workflow\")\nasync def run_data_processing(input_data: dict) -&gt; dict:\n    \"\"\"Run the data processing workflow.\"\"\"\n    return await data_processing_workflow.execute(input_data)\n\n# Alternatively, use WorkflowStep directly\nprocess_data_step = WorkflowStep(\n    workflow=data_processing_workflow,\n    name=\"Process Data Workflow\"\n)\n\n# Compose into a larger workflow\nmaster_workflow = Workflow.sequence(\n    input_validation,\n    process_data_step,  # Using the workflow as a step\n    WorkflowStep(workflow=reporting_workflow, name=\"Generate Report\"),\n    send_notification,\n    name=\"End-to-End Process\"\n)\n\n# Execute the composed workflow\nresult = await master_workflow.execute(input_data)\n</code></pre>"},{"location":"concepts/workflows/#best-practices","title":"Best Practices","text":""},{"location":"concepts/workflows/#1-design-for-modularity","title":"1. Design for Modularity","text":"<p>Create small, focused steps that do one thing well. This makes workflows easier to understand, test, and maintain.</p> <pre><code># Good: Focused steps\n@step(name=\"Validate Input\")\nasync def validate_input(data: dict) -&gt; dict:\n    \"\"\"Validate input data structure.\"\"\"\n    # Validation logic...\n\n@step(name=\"Process Data\")\nasync def process_data(data: dict) -&gt; dict:\n    \"\"\"Process the validated data.\"\"\"\n    # Processing logic...\n\n# Bad: Monolithic step\n@step(name=\"Validate and Process\")\nasync def validate_and_process(data: dict) -&gt; dict:\n    \"\"\"Validate and process data.\"\"\"\n    # Validation and processing combined...\n</code></pre>"},{"location":"concepts/workflows/#2-handle-errors-gracefully","title":"2. Handle Errors Gracefully","text":"<p>Each step should handle its own errors or pass them up with clear context:</p> <pre><code>@step(name=\"Process Transaction\")\nasync def process_transaction(transaction: dict) -&gt; dict:\n    \"\"\"Process a financial transaction.\"\"\"\n    try:\n        # Processing logic...\n        return {\"status\": \"success\", \"transaction_id\": \"123\"}\n    except ConnectionError:\n        # Handle specific error\n        return {\"status\": \"error\", \"reason\": \"connection_failed\", \"retry\": True}\n    except ValueError as e:\n        # Handle validation error\n        return {\"status\": \"error\", \"reason\": \"validation_failed\", \"message\": str(e)}\n    except Exception as e:\n        # Log unexpected errors\n        import logging\n        logging.error(f\"Unexpected error: {str(e)}\")\n        return {\"status\": \"error\", \"reason\": \"unknown\", \"message\": str(e)}\n</code></pre>"},{"location":"concepts/workflows/#3-use-type-hints","title":"3. Use Type Hints","text":"<p>Add type hints to make workflows self-documenting and enable validation:</p> <pre><code>from typing import Dict, List, Union, Optional\n\n@step(name=\"Fetch User Data\")\nasync def fetch_user_data(user_id: str) -&gt; Dict[str, Union[str, List[str], Dict]]:\n    \"\"\"Fetch comprehensive user data.\"\"\"\n    # Implementation...\n    return {\n        \"user_id\": user_id,\n        \"name\": \"Alice Smith\",\n        \"email\": \"alice@example.com\",\n        \"preferences\": {\"theme\": \"dark\", \"notifications\": True},\n        \"groups\": [\"admin\", \"editor\"]\n    }\n</code></pre>"},{"location":"concepts/workflows/#4-design-for-observability","title":"4. Design for Observability","text":"<p>Include logging and monitoring in your workflows:</p> <pre><code>from fastadk.core.workflow import step\nimport logging\nfrom time import time\n\n@step(name=\"Data Processing\")\nasync def process_data(data: dict) -&gt; dict:\n    \"\"\"Process data with observability.\"\"\"\n    start_time = time()\n    logging.info(f\"Starting data processing for {data.get('id', 'unknown')}\")\n\n    try:\n        # Processing logic...\n        result = {\"processed\": True, \"data\": [...]}\n\n        # Record metrics\n        processing_time = time() - start_time\n        logging.info(f\"Data processing completed in {processing_time:.2f}s\")\n\n        return result\n    except Exception as e:\n        logging.error(f\"Data processing failed: {str(e)}\", exc_info=True)\n        raise\n</code></pre>"},{"location":"concepts/workflows/#5-optimize-for-performance","title":"5. Optimize for Performance","text":"<p>Consider using parallel execution for independent tasks:</p> <pre><code># Sequential execution (slower)\nsequential_workflow = Workflow.sequence(\n    fetch_user_data,\n    fetch_orders,\n    fetch_recommendations,\n    name=\"User Dashboard Sequential\"\n)\n\n# Parallel execution (faster)\nparallel_workflow = Workflow.sequence(\n    Workflow.parallel(\n        fetch_user_data,\n        fetch_orders,\n        fetch_recommendations\n    ),\n    combine_data,\n    name=\"User Dashboard Parallel\"\n)\n</code></pre>"},{"location":"concepts/workflows/#conclusion","title":"Conclusion","text":"<p>Workflows in FastADK provide a powerful system for orchestrating complex processes involving multiple steps, agents, and data transformations. By understanding the workflow architecture and applying best practices, you can build robust, maintainable, and efficient solutions for complex problems.</p> <p>Whether you're building data processing pipelines, multi-agent systems, or complex business processes, the workflow system offers the flexibility and power to implement your solution effectively.</p>"},{"location":"contributing/development-setup/","title":"Development Setup","text":"<p>This guide will help you set up your development environment for contributing to FastADK.</p>"},{"location":"contributing/development-setup/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure you have the following installed:</p> <ul> <li>Python 3.10 or higher</li> <li>uv - Fast Python package installer and resolver</li> <li>Git</li> </ul>"},{"location":"contributing/development-setup/#clone-the-repository","title":"Clone the Repository","text":"<pre><code>git clone https://github.com/Mathews-Tom/FastADK.git\ncd fastadk\n</code></pre>"},{"location":"contributing/development-setup/#setting-up-a-virtual-environment","title":"Setting Up a Virtual Environment","text":"<p>FastADK uses <code>uv</code> for dependency management. To set up your development environment:</p> <pre><code># Create and activate a virtual environment (optional if using uv)\npython -m venv .venv\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\n\n# Install dependencies including development dependencies\nuv sync --dev\n</code></pre>"},{"location":"contributing/development-setup/#environment-variables","title":"Environment Variables","text":"<p>Create a <code>.env</code> file in the root directory for local development:</p> <pre><code># .env\nOPENAI_API_KEY=your_openai_api_key\nANTHROPIC_API_KEY=your_anthropic_api_key\nGOOGLE_API_KEY=your_google_api_key\n</code></pre> <p>For running tests, these environment variables are not required as tests use mock providers.</p>"},{"location":"contributing/development-setup/#pre-commit-hooks","title":"Pre-commit Hooks","text":"<p>FastADK uses pre-commit hooks to ensure code quality. Install them with:</p> <pre><code>uv add pre-commit\npre-commit install\n</code></pre>"},{"location":"contributing/development-setup/#ide-setup","title":"IDE Setup","text":""},{"location":"contributing/development-setup/#vscode","title":"VSCode","text":"<p>FastADK includes VSCode settings in the <code>.vscode</code> directory. These settings configure:</p> <ul> <li>Black as the formatter</li> <li>Ruff for linting</li> <li>MyPy for type checking</li> </ul> <p>Install the recommended extensions when prompted by VSCode.</p>"},{"location":"contributing/development-setup/#pycharm","title":"PyCharm","text":"<p>If you're using PyCharm:</p> <ol> <li>Set the project interpreter to your virtual environment</li> <li>Enable Black as the formatter</li> <li>Configure Ruff for linting</li> <li>Enable type checking with MyPy</li> </ol>"},{"location":"contributing/development-setup/#running-tests","title":"Running Tests","text":"<p>Run the test suite with:</p> <pre><code>uv run pytest\n</code></pre> <p>Run with coverage:</p> <pre><code>uv run pytest --cov=fastadk\n</code></pre>"},{"location":"contributing/development-setup/#building-documentation","title":"Building Documentation","text":"<p>To build and serve the documentation locally:</p> <pre><code>uv run -m mkdocs serve\n</code></pre> <p>Then visit <code>http://127.0.0.1:8000/</code> to view the docs.</p>"},{"location":"contributing/development-setup/#development-workflow","title":"Development Workflow","text":"<ol> <li>Create a branch for your changes:</li> </ol> <pre><code>git checkout -b feature/your-feature-name\n</code></pre> <ol> <li>Make your changes</li> <li>Run quality checks:</li> </ol> <pre><code># Format code\nuv run ruff format .\nuv run black .\n\n# Lint code\nuv run ruff check .\n\n# Type check\nuv run mypy src tests\n\n# Run tests\nuv run pytest\n</code></pre> <ol> <li>Commit your changes following the Conventional Commits specification</li> <li>Push your branch and create a pull request</li> </ol>"},{"location":"contributing/development-setup/#troubleshooting","title":"Troubleshooting","text":""},{"location":"contributing/development-setup/#common-issues","title":"Common Issues","text":""},{"location":"contributing/development-setup/#package-not-found","title":"Package Not Found","text":"<p>If you're getting errors about packages not being found, try:</p> <pre><code>uv sync --dev\n</code></pre>"},{"location":"contributing/development-setup/#test-failures","title":"Test Failures","text":"<p>If tests are failing:</p> <ol> <li>Make sure your environment variables are set correctly</li> <li>Ensure you have the latest dependencies</li> <li>Check for conflicting package versions</li> </ol>"},{"location":"contributing/development-setup/#documentation-build-issues","title":"Documentation Build Issues","text":"<p>If <code>mkdocs build</code> fails:</p> <ol> <li>Ensure you have all dependencies installed</li> <li>Check for invalid links or references in markdown files</li> <li>Verify image paths are correct</li> </ol> <p>For further help, please open an issue on GitHub or reach out on Discord.</p>"},{"location":"contributing/guidelines/","title":"Contribution Guidelines","text":"<p>Thank you for considering contributing to FastADK! This document outlines the process for contributing to the project and the standards we follow.</p>"},{"location":"contributing/guidelines/#code-of-conduct","title":"Code of Conduct","text":"<p>By participating in this project, you agree to abide by our Code of Conduct.</p>"},{"location":"contributing/guidelines/#how-to-contribute","title":"How to Contribute","text":""},{"location":"contributing/guidelines/#reporting-bugs","title":"Reporting Bugs","text":"<ol> <li>Check Existing Issues: Before creating a new issue, check if it already exists.</li> <li>Use the Bug Report Template: When creating a new issue, use the bug report template.</li> <li>Be Specific: Include detailed information about your environment, steps to reproduce, and error messages.</li> <li>Minimal Example: If possible, provide a minimal code example that reproduces the issue.</li> </ol>"},{"location":"contributing/guidelines/#suggesting-enhancements","title":"Suggesting Enhancements","text":"<ol> <li>Use the Feature Request Template: When suggesting a feature, use the feature request template.</li> <li>Be Clear: Clearly describe the problem your feature would solve and how it would work.</li> <li>Consider Scope: Ensure your suggestion fits with the project's scope and goals.</li> </ol>"},{"location":"contributing/guidelines/#making-changes","title":"Making Changes","text":"<ol> <li>Fork the Repository: Create your own fork of the repository.</li> <li>Create a Branch: Create a branch for your changes from the <code>main</code> branch.</li> <li>Make Your Changes: Make your changes following our coding standards.</li> <li>Write Tests: Ensure your changes include appropriate tests.</li> <li>Run the Test Suite: Make sure all tests pass.</li> <li>Update Documentation: Update the documentation to reflect your changes.</li> <li>Submit a Pull Request: Submit a pull request with your changes.</li> </ol>"},{"location":"contributing/guidelines/#development-workflow","title":"Development Workflow","text":"<ol> <li>Setup Development Environment: Follow the Development Setup guide.</li> <li>Install Dependencies: Install development dependencies with <code>uv sync --dev</code>.</li> <li>Make Changes: Make your changes in small, focused commits.</li> <li>Write Tests: Write tests for any new functionality.</li> <li>Run Quality Checks: Run all quality checks before submitting your changes:</li> </ol> <pre><code># Format code\nuv run ruff format .\nuv run black .\n\n# Lint code\nuv run ruff check .\n\n# Type check\nuv run mypy src tests\n\n# Run tests\nuv run pytest tests/ -v --cov=fastadk\n</code></pre>"},{"location":"contributing/guidelines/#coding-standards","title":"Coding Standards","text":""},{"location":"contributing/guidelines/#python-style","title":"Python Style","text":"<ul> <li>Follow PEP 8 style guidelines.</li> <li>Use Black for code formatting.</li> <li>Follow PEP 257 for docstring conventions.</li> <li>Use Google-style docstrings.</li> </ul>"},{"location":"contributing/guidelines/#type-hints","title":"Type Hints","text":"<ul> <li>Use type hints for all function and method signatures.</li> <li>Follow PEP 484 for type hints.</li> <li>Run <code>mypy</code> to check type hints.</li> </ul>"},{"location":"contributing/guidelines/#imports","title":"Imports","text":"<ul> <li>Organize imports in the following order:</li> <li>Standard library imports</li> <li>Related third-party imports</li> <li>Local application/library-specific imports</li> <li>Sort imports alphabetically within each group.</li> <li>Use absolute imports for external packages and relative imports for internal modules.</li> </ul>"},{"location":"contributing/guidelines/#documentation","title":"Documentation","text":"<ul> <li>Document all public classes, methods, and functions.</li> <li>Keep documentation up-to-date with code changes.</li> <li>Use examples where appropriate.</li> </ul>"},{"location":"contributing/guidelines/#git-workflow","title":"Git Workflow","text":""},{"location":"contributing/guidelines/#branching-strategy","title":"Branching Strategy","text":"<ul> <li><code>main</code>: The primary branch, always stable and deployable.</li> <li><code>feature/*</code>: Feature branches for new features or enhancements.</li> <li><code>bugfix/*</code>: Bugfix branches for bug fixes.</li> <li><code>docs/*</code>: Documentation branches for documentation changes.</li> <li><code>refactor/*</code>: Refactoring branches for code refactoring.</li> </ul>"},{"location":"contributing/guidelines/#commit-messages","title":"Commit Messages","text":"<ul> <li>Follow the Conventional Commits specification.</li> <li>Use one of the following types:</li> <li><code>feat</code>: A new feature</li> <li><code>fix</code>: A bug fix</li> <li><code>docs</code>: Documentation changes</li> <li><code>style</code>: Changes that do not affect the meaning of the code</li> <li><code>refactor</code>: Code changes that neither fix a bug nor add a feature</li> <li><code>perf</code>: Performance improvements</li> <li><code>test</code>: Adding or modifying tests</li> <li><code>chore</code>: Changes to the build process or auxiliary tools</li> </ul> <p>Example:</p> <pre><code>feat: add semantic memory to agent context\n</code></pre>"},{"location":"contributing/guidelines/#pull-requests","title":"Pull Requests","text":"<ul> <li>Use the pull request template.</li> <li>Link related issues.</li> <li>Describe your changes clearly.</li> <li>Ensure all checks pass.</li> <li>Request a review from maintainers.</li> </ul>"},{"location":"contributing/guidelines/#release-process","title":"Release Process","text":"<ol> <li>Maintainers will periodically release new versions.</li> <li>Releases follow Semantic Versioning.</li> <li>Changelogs are generated automatically from commit messages.</li> <li>Releases are published to PyPI automatically via GitHub Actions.</li> </ol>"},{"location":"contributing/guidelines/#recognition","title":"Recognition","text":"<p>Contributors will be recognized in the following ways:</p> <ul> <li>Listed in the project's <code>CONTRIBUTORS.md</code> file.</li> <li>Mentioned in release notes for significant contributions.</li> <li>Given credit in the documentation for features they implemented.</li> </ul>"},{"location":"examples/","title":"FastADK Examples Index","text":"<p>This document provides an organized index of all examples available in the FastADK repository, making it easy to find the right example for your needs.</p>"},{"location":"examples/#basic-examples","title":"Basic Examples","text":"<p>These examples demonstrate fundamental FastADK concepts and are a great starting point:</p> <ul> <li>Weather Agent - Core agent functionality with real API integration (wttr.in)</li> <li>Exception Handling - Comprehensive exception handling and error management</li> <li>Token Tracking - Token usage tracking and cost estimation</li> <li>LiteLLM Integration - Integration with LiteLLM for provider flexibility</li> <li>Reasoning Demo - Chain-of-thought reasoning with visible tool selection</li> </ul>"},{"location":"examples/#advanced-examples","title":"Advanced Examples","text":"<p>These examples showcase more complex usage patterns and advanced features:</p> <ul> <li>Travel Assistant - Comprehensive example with memory, tools, API integration, lifecycle hooks</li> <li>Workflow Demo - Workflow orchestration with sequential/parallel flows</li> <li>Batch Processing - Efficient batch processing of multiple inputs</li> <li>Multi-Provider Reasoning - Using multiple providers based on available API keys</li> <li>Customer Support - Building a customer support assistant</li> <li>Finance Assistant - Financial data analysis and reporting assistant</li> </ul>"},{"location":"examples/#api-examples","title":"API Examples","text":"<p>These examples demonstrate integrating FastADK with APIs:</p> <ul> <li>HTTP Agent - Serving agents via HTTP API with FastAPI</li> </ul>"},{"location":"examples/#ui-examples","title":"UI Examples","text":"<p>These examples show how to build user interfaces for FastADK agents:</p> <ul> <li>Streamlit Chat App - Building interactive chat interfaces with Streamlit</li> </ul>"},{"location":"examples/#pattern-examples","title":"Pattern Examples","text":"<p>These examples demonstrate recommended patterns and practices:</p> <ul> <li>Tool Patterns - Different tool development patterns (async/sync, validation)</li> <li>Configuration Patterns - Configuration loading from YAML, environment, etc.</li> </ul>"},{"location":"examples/#training-examples","title":"Training Examples","text":"<p>These examples focus on model training and fine-tuning:</p> <ul> <li>Fine Tuning Example - Data format conversion and fine-tuning jobs</li> </ul>"},{"location":"examples/#getting-started","title":"Getting Started","text":"<p>To run these examples:</p> <ol> <li>Clone the FastADK repository</li> <li>Install dependencies: <code>uv add -e .</code></li> <li>Set up environment variables in <code>.env</code> (see <code>.env.example</code> in the examples directory)</li> <li>Run an example: <code>uv run python examples/basic/weather_agent.py</code></li> </ol>"},{"location":"examples/#contributing","title":"Contributing","text":"<p>If you'd like to contribute a new example, please follow our contribution guidelines and ensure your example follows the established patterns.</p>"},{"location":"examples/advanced/batch_processing_demo/","title":"Batch Processing Demo","text":"<p>This example demonstrates how to use FastADK's batch processing capabilities to efficiently process multiple inputs with AI agents. Batch processing is essential for applications that need to handle large volumes of data or requests.</p>"},{"location":"examples/advanced/batch_processing_demo/#overview","title":"Overview","text":"<p>The Batch Processing Demo shows how to:</p> <ol> <li>Process multiple inputs efficiently with parallel execution</li> <li>Configure parallelism with adjustable batch sizes</li> <li>Monitor and report progress during batch operations</li> <li>Apply post-processing to aggregate results</li> <li>Handle errors gracefully in batch contexts</li> </ol>"},{"location":"examples/advanced/batch_processing_demo/#key-features","title":"Key Features","text":""},{"location":"examples/advanced/batch_processing_demo/#batch-processor","title":"Batch Processor","text":"<p>The example uses FastADK's <code>BatchProcessor</code> to manage batch operations:</p> <pre><code>from fastadk.core.batch import BatchProcessor\nfrom sentiment_analysis_agent import SentimentAnalysisAgent\n\n# Create an agent for sentiment analysis\nagent = SentimentAnalysisAgent()\n\n# Create a batch processor with the agent\nprocessor = BatchProcessor(\n    agent=agent,\n    max_concurrent=5,  # Process up to 5 items in parallel\n    timeout=60,        # Timeout after 60 seconds per item\n    retry_attempts=2   # Retry failed items up to 2 times\n)\n</code></pre>"},{"location":"examples/advanced/batch_processing_demo/#parallel-processing","title":"Parallel Processing","text":"<p>The example demonstrates both sequential and parallel approaches:</p> <pre><code># Sequential processing (one at a time)\nasync def process_sequential(texts):\n    results = []\n    for text in texts:\n        result = await agent.run(f\"Analyze the sentiment of: {text}\")\n        results.append(result)\n    return results\n\n# Parallel processing with batch processor\nasync def process_parallel(texts):\n    results = await processor.process_batch(\n        items=texts,\n        process_fn=lambda text: f\"Analyze the sentiment of: {text}\",\n        result_fn=lambda response, text: {\n            \"text\": text,\n            \"sentiment\": extract_sentiment(response),\n            \"score\": extract_score(response)\n        }\n    )\n    return results\n</code></pre>"},{"location":"examples/advanced/batch_processing_demo/#progress-monitoring","title":"Progress Monitoring","text":"<p>The example shows how to track progress during batch operations:</p> <pre><code>async def process_with_progress(texts):\n    # Create a progress tracker\n    progress = {\"processed\": 0, \"total\": len(texts)}\n\n    # Define progress callback\n    def update_progress(result, item):\n        progress[\"processed\"] += 1\n        print(f\"Progress: {progress['processed']}/{progress['total']} ({progress['processed']/progress['total']*100:.1f}%)\")\n        return result\n\n    # Process batch with progress tracking\n    results = await processor.process_batch(\n        items=texts,\n        process_fn=lambda text: f\"Analyze the sentiment of: {text}\",\n        result_fn=update_progress\n    )\n\n    return results\n</code></pre>"},{"location":"examples/advanced/batch_processing_demo/#error-handling","title":"Error Handling","text":"<p>The example demonstrates how to handle errors during batch processing:</p> <pre><code>async def process_with_error_handling(texts):\n    results = []\n    errors = []\n\n    # Define error handler\n    def handle_error(error, item):\n        errors.append({\"item\": item, \"error\": str(error)})\n        return None  # Return None for failed items\n\n    # Process batch with error handling\n    batch_results = await processor.process_batch(\n        items=texts,\n        process_fn=lambda text: f\"Analyze the sentiment of: {text}\",\n        error_fn=handle_error\n    )\n\n    # Filter out None results (from errors)\n    results = [r for r in batch_results if r is not None]\n\n    return {\n        \"successful\": results,\n        \"failed\": errors,\n        \"success_rate\": len(results) / len(texts) if texts else 0\n    }\n</code></pre>"},{"location":"examples/advanced/batch_processing_demo/#performance-comparison","title":"Performance Comparison","text":"<p>The example includes code to compare the performance of sequential vs. parallel processing:</p> <pre><code>import time\nimport asyncio\n\nasync def performance_comparison(texts):\n    # Measure sequential processing time\n    start_time = time.time()\n    sequential_results = await process_sequential(texts)\n    sequential_time = time.time() - start_time\n\n    # Measure parallel processing time\n    start_time = time.time()\n    parallel_results = await process_parallel(texts)\n    parallel_time = time.time() - start_time\n\n    # Calculate speedup\n    speedup = sequential_time / parallel_time if parallel_time &gt; 0 else float('inf')\n\n    return {\n        \"sequential_time\": sequential_time,\n        \"parallel_time\": parallel_time,\n        \"speedup\": speedup,\n        \"sequential_results\": len(sequential_results),\n        \"parallel_results\": len(parallel_results)\n    }\n</code></pre>"},{"location":"examples/advanced/batch_processing_demo/#implementation-details","title":"Implementation Details","text":""},{"location":"examples/advanced/batch_processing_demo/#sentiment-analysis-agent","title":"Sentiment Analysis Agent","text":"<p>The example uses a sentiment analysis agent:</p> <pre><code>from fastadk import Agent, BaseAgent, tool\nfrom typing import Dict\n\n@Agent(model=\"gemini-1.5-pro\")\nclass SentimentAnalysisAgent(BaseAgent):\n    @tool\n    def analyze_sentiment(self, text: str) -&gt; Dict:\n        \"\"\"\n        Analyze the sentiment of the given text.\n\n        Args:\n            text: The text to analyze\n\n        Returns:\n            Dictionary containing sentiment (positive, negative, neutral) and score\n        \"\"\"\n        # This is a tool definition - the LLM will implement the analysis\n        pass\n</code></pre>"},{"location":"examples/advanced/batch_processing_demo/#batch-configuration","title":"Batch Configuration","text":"<p>The example demonstrates how to configure batch processing parameters:</p> <pre><code># Configure different batch sizes to find optimal performance\nasync def optimize_batch_size(texts, batch_sizes=[1, 5, 10, 20]):\n    results = {}\n\n    for batch_size in batch_sizes:\n        # Create processor with current batch size\n        processor = BatchProcessor(\n            agent=SentimentAnalysisAgent(),\n            max_concurrent=batch_size\n        )\n\n        # Measure processing time\n        start_time = time.time()\n        await processor.process_batch(\n            items=texts,\n            process_fn=lambda text: f\"Analyze the sentiment of: {text}\"\n        )\n        processing_time = time.time() - start_time\n\n        # Store result\n        results[batch_size] = {\n            \"batch_size\": batch_size,\n            \"processing_time\": processing_time,\n            \"items_per_second\": len(texts) / processing_time\n        }\n\n    # Find optimal batch size\n    optimal_batch_size = max(results.items(), key=lambda x: x[1][\"items_per_second\"])[0]\n\n    return {\n        \"optimal_batch_size\": optimal_batch_size,\n        \"all_results\": results\n    }\n</code></pre>"},{"location":"examples/advanced/batch_processing_demo/#results-aggregation","title":"Results Aggregation","text":"<p>The example shows how to aggregate results from batch processing:</p> <pre><code>async def analyze_and_aggregate(texts):\n    # Process all texts in batch\n    results = await processor.process_batch(\n        items=texts,\n        process_fn=lambda text: f\"Analyze the sentiment of: {text}\",\n        result_fn=lambda response, text: {\n            \"text\": text,\n            \"sentiment\": extract_sentiment(response),\n            \"score\": extract_score(response)\n        }\n    )\n\n    # Aggregate results\n    sentiment_counts = {\"positive\": 0, \"negative\": 0, \"neutral\": 0}\n    average_score = 0\n\n    for result in results:\n        sentiment_counts[result[\"sentiment\"]] += 1\n        average_score += result[\"score\"]\n\n    if results:\n        average_score /= len(results)\n\n    # Return aggregated analysis\n    return {\n        \"total_analyzed\": len(results),\n        \"sentiment_distribution\": sentiment_counts,\n        \"average_score\": average_score,\n        \"detailed_results\": results\n    }\n</code></pre>"},{"location":"examples/advanced/batch_processing_demo/#usage-example","title":"Usage Example","text":"<p>Here's how you might use the batch processing capabilities:</p> <pre><code>from batch_processing_demo import analyze_and_aggregate\n\nasync def main():\n    # Sample texts to analyze\n    texts = [\n        \"I absolutely love this product! It's amazing.\",\n        \"This is the worst experience I've ever had.\",\n        \"The service was okay, nothing special.\",\n        \"I'm very disappointed with the quality.\",\n        \"The customer support team was incredibly helpful.\",\n        # ... more texts\n    ]\n\n    # Process and aggregate results\n    results = await analyze_and_aggregate(texts)\n\n    # Print summary\n    print(f\"Analyzed {results['total_analyzed']} texts\")\n    print(f\"Sentiment distribution: {results['sentiment_distribution']}\")\n    print(f\"Average sentiment score: {results['average_score']:.2f}\")\n\n    # Optimize batch size\n    optimization = await optimize_batch_size(texts)\n    print(f\"Optimal batch size: {optimization['optimal_batch_size']}\")\n\nif __name__ == \"__main__\":\n    import asyncio\n    asyncio.run(main())\n</code></pre>"},{"location":"examples/advanced/batch_processing_demo/#full-source-code","title":"Full Source Code","text":"<p>For the complete implementation of the Batch Processing Demo, refer to the batch_processing_demo.py file in the examples directory.</p>"},{"location":"examples/advanced/batch_processing_demo/#key-takeaways","title":"Key Takeaways","text":"<p>The Batch Processing Demo example demonstrates several important patterns:</p> <ol> <li>Parallel Processing: Using concurrency to improve throughput</li> <li>Resource Management: Controlling concurrency to avoid overwhelming resources</li> <li>Progress Tracking: Monitoring batch operations in real-time</li> <li>Error Handling: Gracefully managing failures in batch contexts</li> <li>Performance Optimization: Finding the optimal batch size for best performance</li> </ol> <p>By using these patterns, you can efficiently process large volumes of data with AI agents, making your applications more scalable and responsive.</p>"},{"location":"examples/advanced/customer_support/","title":"Customer Support Agent Example","text":""},{"location":"examples/advanced/customer_support/#overview","title":"Overview","text":"<p>This example demonstrates a comprehensive customer support agent for a consumer electronics company. The agent can handle product inquiries, order status checks, refund requests, and technical support issues using a knowledge base of common problems and solutions.</p>"},{"location":"examples/advanced/customer_support/#features-demonstrated","title":"Features Demonstrated","text":"<ul> <li>Custom Context Policy: <code>PrioritySupportContextPolicy</code> that prioritizes support-related keywords in the conversation</li> <li>Memory Backend: Using InMemoryBackend for conversation persistence</li> <li>Structured Knowledge Base: Integration with product catalog and technical solutions</li> <li>Multi-Step Processes: Order tracking, refund processing, and support ticket creation</li> <li>Domain-Specific Tools: Tools designed specifically for customer service tasks</li> </ul>"},{"location":"examples/advanced/customer_support/#running-this-example","title":"Running this Example","text":"<pre><code>uv run examples/advanced/customer_support.py\n</code></pre>"},{"location":"examples/advanced/customer_support/#example-interactions","title":"Example Interactions","text":""},{"location":"examples/advanced/customer_support/#product-information","title":"Product Information","text":"<pre><code>You: Tell me about your SmartHome Hub product\nAssistant: [Provides detailed product information about the SmartHome Hub]\n</code></pre>"},{"location":"examples/advanced/customer_support/#order-status-check","title":"Order Status Check","text":"<pre><code>You: What's the status of my order ORD12345?\nAssistant: [Provides order details, status, and estimated delivery date]\n</code></pre>"},{"location":"examples/advanced/customer_support/#technical-support","title":"Technical Support","text":"<pre><code>You: My SmartHome Hub won't connect to WiFi\nAssistant: [Provides troubleshooting steps from knowledge base]\n</code></pre>"},{"location":"examples/advanced/customer_support/#refund-request","title":"Refund Request","text":"<pre><code>You: I want to return my Wireless Earbuds and get a refund\nAssistant: [Guides through refund process and eligibility]\n</code></pre>"},{"location":"examples/advanced/customer_support/#support-ticket-creation","title":"Support Ticket Creation","text":"<pre><code>You: I need to create a support ticket for my broken TV\nAssistant: [Creates ticket and provides reference number]\n</code></pre>"},{"location":"examples/advanced/customer_support/#implementation-details","title":"Implementation Details","text":"<p>The agent is implemented with:</p> <ul> <li>A priority-based context policy that emphasizes support-related conversation</li> <li>Mock databases for products, orders, customers, and support tickets</li> <li>Structured knowledge base for common technical issues</li> <li>Comprehensive tool set for different support scenarios</li> </ul>"},{"location":"examples/advanced/customer_support/#context-policy","title":"Context Policy","text":"<p>The <code>PrioritySupportContextPolicy</code> demonstrates how to customize conversation context handling to prioritize certain types of messages (those containing keywords like \"ticket\", \"issue\", \"problem\", etc.) when the conversation history exceeds the token limit.</p>"},{"location":"examples/advanced/customer_support/#customization","title":"Customization","text":"<p>You can extend this example by:</p> <ul> <li>Connecting to real CRM and order management systems</li> <li>Adding authentication and customer verification</li> <li>Implementing sentiment analysis for customer satisfaction tracking</li> <li>Adding live agent handoff for complex issues</li> <li>Integrating with email or SMS notification systems</li> </ul>"},{"location":"examples/advanced/customer_support/#requirements","title":"Requirements","text":"<ul> <li>fastadk</li> <li>Basic Python knowledge</li> <li>An OpenAI API key (set as OPENAI_API_KEY environment variable)</li> </ul>"},{"location":"examples/advanced/finance_assistant/","title":"Finance Assistant Example","text":""},{"location":"examples/advanced/finance_assistant/#overview","title":"Overview","text":"<p>This example demonstrates a comprehensive financial assistant agent built with FastADK. The agent can provide financial advice, stock information, and calculate various financial metrics like compound interest, mortgage payments, taxes, and retirement projections.</p>"},{"location":"examples/advanced/finance_assistant/#features-demonstrated","title":"Features Demonstrated","text":"<ul> <li>Token Budget Management: Setting and enforcing token limits for cost control</li> <li>Complex Tool Implementations: Multiple financial calculation tools with proper validation</li> <li>Error Handling: Robust error handling in financial calculations</li> <li>JSON Response Formatting: Structured data responses for financial calculations</li> <li>Memory Management: Using InMemoryBackend for conversation persistence</li> </ul>"},{"location":"examples/advanced/finance_assistant/#running-this-example","title":"Running this Example","text":"<pre><code>uv run examples/advanced/finance_assistant.py\n</code></pre>"},{"location":"examples/advanced/finance_assistant/#example-interactions","title":"Example Interactions","text":""},{"location":"examples/advanced/finance_assistant/#checking-stock-prices","title":"Checking Stock Prices","text":"<pre><code>You: What's the current price of Apple stock?\nAssistant: The current price of Apple Inc. (AAPL) is $185.92 (+0.75%)\n</code></pre>"},{"location":"examples/advanced/finance_assistant/#calculating-compound-interest","title":"Calculating Compound Interest","text":"<pre><code>You: Calculate compound interest on a $10,000 investment at 5% annual interest for 10 years\nAssistant: [Provides detailed breakdown of compound interest calculation with yearly results]\n</code></pre>"},{"location":"examples/advanced/finance_assistant/#mortgage-payment-calculation","title":"Mortgage Payment Calculation","text":"<pre><code>You: What would be my monthly payment for a $300,000 mortgage at 4.5% interest for 30 years?\nAssistant: [Provides monthly payment amount and amortization details]\n</code></pre>"},{"location":"examples/advanced/finance_assistant/#tax-estimation","title":"Tax Estimation","text":"<pre><code>You: Estimate my taxes if I earn $75,000 per year as a single filer\nAssistant: [Provides tax breakdown by brackets with effective tax rate]\n</code></pre>"},{"location":"examples/advanced/finance_assistant/#retirement-planning","title":"Retirement Planning","text":"<pre><code>You: How much will I have for retirement if I'm 35 now, retire at 65, have $50,000 saved, and contribute $500 monthly with 7% returns?\nAssistant: [Provides detailed retirement savings projection]\n</code></pre>"},{"location":"examples/advanced/finance_assistant/#implementation-details","title":"Implementation Details","text":"<p>The agent is implemented with:</p> <ul> <li>Multiple specialized financial calculation tools</li> <li>Structured JSON responses for clear data presentation</li> <li>Extensive error checking and validation</li> <li>Token budget settings to control usage</li> </ul>"},{"location":"examples/advanced/finance_assistant/#customization","title":"Customization","text":"<p>You can extend this example by:</p> <ul> <li>Adding more financial tools (e.g., college savings calculator)</li> <li>Connecting to real financial data APIs</li> <li>Implementing a user profile system to save financial preferences</li> <li>Adding visualization capabilities for financial projections</li> </ul>"},{"location":"examples/advanced/finance_assistant/#requirements","title":"Requirements","text":"<ul> <li>fastadk</li> <li>Basic Python knowledge</li> <li>An OpenAI API key (set as OPENAI_API_KEY environment variable)</li> </ul>"},{"location":"examples/advanced/multi_provider_reasoning/","title":"Multi-Provider Reasoning Example","text":"<p>This example demonstrates how to build an agent that can dynamically use different LLM providers based on available API keys and fallback strategies. It showcases FastADK's provider-agnostic design and ability to handle complex reasoning tasks across different models.</p>"},{"location":"examples/advanced/multi_provider_reasoning/#overview","title":"Overview","text":"<p>The Multi-Provider Reasoning agent is designed to:</p> <ol> <li>Check for available API keys for different providers (OpenAI, Gemini, Anthropic)</li> <li>Select the best available provider based on priority and availability</li> <li>Fall back to alternative providers if the primary one fails</li> <li>Adapt prompts and parsing strategies based on the selected provider</li> <li>Perform consistent reasoning tasks regardless of the underlying model</li> </ol>"},{"location":"examples/advanced/multi_provider_reasoning/#key-features","title":"Key Features","text":""},{"location":"examples/advanced/multi_provider_reasoning/#dynamic-provider-selection","title":"Dynamic Provider Selection","text":"<p>The agent dynamically selects a provider based on available API keys:</p> <pre><code>def select_provider(self):\n    \"\"\"Select the best available provider based on API key availability.\"\"\"\n    providers = {\n        \"openai\": {\n            \"api_key\": os.getenv(\"OPENAI_API_KEY\"),\n            \"model\": \"gpt-4\",\n            \"priority\": 1\n        },\n        \"gemini\": {\n            \"api_key\": os.getenv(\"GEMINI_API_KEY\"),\n            \"model\": \"gemini-1.5-pro\",\n            \"priority\": 2\n        },\n        \"anthropic\": {\n            \"api_key\": os.getenv(\"ANTHROPIC_API_KEY\"),\n            \"model\": \"claude-3-opus-20240229\",\n            \"priority\": 3\n        }\n    }\n\n    # Filter to providers with API keys\n    available_providers = {k: v for k, v in providers.items() if v[\"api_key\"]}\n\n    if not available_providers:\n        raise ValueError(\"No API keys found for any provider\")\n\n    # Return the highest priority (lowest number) provider\n    return min(available_providers.items(), key=lambda x: x[1][\"priority\"])\n</code></pre>"},{"location":"examples/advanced/multi_provider_reasoning/#provider-specific-adaptations","title":"Provider-Specific Adaptations","text":"<p>The agent adapts its behavior based on the selected provider:</p> <pre><code>def on_initialize(self):\n    \"\"\"Initialize the agent with the best available provider.\"\"\"\n    provider_name, provider_config = self.select_provider()\n\n    # Set agent properties based on selected provider\n    self.provider_name = provider_name\n    self.model_name = provider_config[\"model\"]\n\n    # Adjust prompt templates based on provider\n    if provider_name == \"anthropic\":\n        self.system_prompt = self.system_prompt_anthropic\n    elif provider_name == \"gemini\":\n        self.system_prompt = self.system_prompt_gemini\n    else:\n        self.system_prompt = self.system_prompt_openai\n</code></pre>"},{"location":"examples/advanced/multi_provider_reasoning/#reasoning-tools","title":"Reasoning Tools","text":"<p>The agent implements tools for complex reasoning tasks:</p> <pre><code>@tool\ndef analyze_argument(self, argument: str) -&gt; Dict[str, Any]:\n    \"\"\"\n    Analyze the logical structure and validity of an argument.\n\n    Args:\n        argument: The argument text to analyze\n\n    Returns:\n        Dictionary containing analysis of premises, conclusion, and logical validity\n    \"\"\"\n    # Implementation details...\n\n@tool\ndef identify_cognitive_biases(self, text: str) -&gt; List[Dict[str, str]]:\n    \"\"\"\n    Identify potential cognitive biases in the provided text.\n\n    Args:\n        text: The text to analyze for cognitive biases\n\n    Returns:\n        List of identified biases with explanations\n    \"\"\"\n    # Implementation details...\n\n@tool\ndef evaluate_evidence(self, claim: str, evidence: List[str]) -&gt; Dict[str, Any]:\n    \"\"\"\n    Evaluate the strength of evidence supporting a claim.\n\n    Args:\n        claim: The claim being evaluated\n        evidence: List of evidence points supporting the claim\n\n    Returns:\n        Evaluation of evidence strength and overall confidence in the claim\n    \"\"\"\n    # Implementation details...\n</code></pre>"},{"location":"examples/advanced/multi_provider_reasoning/#fallback-strategies","title":"Fallback Strategies","text":"<p>The agent implements fallback strategies for handling provider failures:</p> <pre><code>@retry(max_attempts=3, backoff_factor=2)\nasync def run_with_fallback(self, prompt: str) -&gt; str:\n    \"\"\"Run the agent with automatic fallback to alternative providers.\"\"\"\n    try:\n        return await super().run(prompt)\n    except Exception as e:\n        logger.warning(f\"Error with provider {self.provider_name}: {str(e)}\")\n\n        # Try to switch providers\n        available_providers = self.get_alternative_providers()\n        if not available_providers:\n            raise RuntimeError(\"All providers failed\")\n\n        # Select next best provider\n        self.provider_name, provider_config = available_providers[0]\n        self.model_name = provider_config[\"model\"]\n\n        # Adjust system prompt\n        self.update_system_prompt()\n\n        # Retry with new provider\n        return await super().run(prompt)\n</code></pre>"},{"location":"examples/advanced/multi_provider_reasoning/#implementation-details","title":"Implementation Details","text":""},{"location":"examples/advanced/multi_provider_reasoning/#provider-specific-system-prompts","title":"Provider-Specific System Prompts","text":"<p>Different providers may require slightly different system prompt formats:</p> <pre><code>system_prompt_openai = \"\"\"\nYou are an advanced reasoning assistant specialized in critical thinking, \nlogical analysis, and identifying cognitive biases.\n\"\"\"\n\nsystem_prompt_anthropic = \"\"\"\n&lt;instructions&gt;\nYou are an advanced reasoning assistant specialized in critical thinking, \nlogical analysis, and identifying cognitive biases.\n&lt;/instructions&gt;\n\"\"\"\n\nsystem_prompt_gemini = \"\"\"\nYou are an advanced reasoning assistant specialized in critical thinking, \nlogical analysis, and identifying cognitive biases.\n\"\"\"\n</code></pre>"},{"location":"examples/advanced/multi_provider_reasoning/#provider-configuration","title":"Provider Configuration","text":"<p>The agent uses environment variables for API keys:</p> <pre><code># .env file example\nOPENAI_API_KEY=sk-...\nGEMINI_API_KEY=...\nANTHROPIC_API_KEY=sk-ant-...\n</code></pre>"},{"location":"examples/advanced/multi_provider_reasoning/#response-parsing-adaptations","title":"Response Parsing Adaptations","text":"<p>The agent adapts its response parsing based on the provider:</p> <pre><code>def parse_response(self, response: str) -&gt; Dict[str, Any]:\n    \"\"\"Parse the response based on the current provider.\"\"\"\n    if self.provider_name == \"anthropic\":\n        # Claude may format outputs differently\n        return self.parse_anthropic_response(response)\n    elif self.provider_name == \"gemini\":\n        # Gemini may have its own output format\n        return self.parse_gemini_response(response)\n    else:\n        # Default parsing for OpenAI\n        return self.parse_openai_response(response)\n</code></pre>"},{"location":"examples/advanced/multi_provider_reasoning/#usage-example","title":"Usage Example","text":"<p>Here's how you might use the Multi-Provider Reasoning agent:</p> <pre><code>from multi_provider_reasoning import ReasoningAgent\n\nasync def main():\n    agent = ReasoningAgent()\n\n    # The agent will automatically select the best available provider\n\n    # Analyze an argument\n    response = await agent.run(\n        \"Analyze this argument: 'All humans are mortal. Socrates is human. Therefore, Socrates is mortal.'\"\n    )\n    print(response)\n\n    # Identify cognitive biases\n    response = await agent.run(\n        \"Identify cognitive biases in this text: 'I won the lottery last week after wearing my lucky socks, so now I always wear them when buying tickets.'\"\n    )\n    print(response)\n\n    # Evaluate evidence\n    response = await agent.run(\n        \"Evaluate the evidence for this claim: 'Coffee consumption reduces the risk of type 2 diabetes.' Evidence: 1) A study of 120,000 people showed 30% lower risk in regular coffee drinkers. 2) Laboratory studies show caffeine improves insulin sensitivity. 3) My friend drinks coffee and doesn't have diabetes.\"\n    )\n    print(response)\n\nif __name__ == \"__main__\":\n    import asyncio\n    asyncio.run(main())\n</code></pre>"},{"location":"examples/advanced/multi_provider_reasoning/#full-source-code","title":"Full Source Code","text":"<p>For the complete implementation of the Multi-Provider Reasoning agent, refer to the multi_provider_reasoning.py file in the examples directory.</p>"},{"location":"examples/advanced/multi_provider_reasoning/#key-takeaways","title":"Key Takeaways","text":"<p>The Multi-Provider Reasoning example demonstrates several important patterns:</p> <ol> <li>Provider Agnosticism: Building agents that can work with multiple LLM providers</li> <li>Dynamic Configuration: Selecting providers based on available API keys</li> <li>Fallback Strategies: Implementing robust error handling with provider fallbacks</li> <li>Provider-Specific Adaptations: Adjusting prompts and parsing strategies for different providers</li> <li>Advanced Reasoning: Implementing tools for complex critical thinking tasks</li> </ol> <p>This approach allows your agents to be more resilient to API outages, take advantage of the best available models, and provide consistent functionality regardless of the underlying provider.</p>"},{"location":"examples/advanced/travel_assistant/","title":"Travel Assistant Example","text":"<p>This example demonstrates a comprehensive travel assistant agent built with FastADK. The travel assistant showcases several advanced features:</p> <ul> <li>Memory management for maintaining conversation context</li> <li>Multiple specialized tools for different travel-related tasks</li> <li>API integration with external services</li> <li>Lifecycle hooks to manage the agent's behavior</li> <li>Structured data handling</li> </ul>"},{"location":"examples/advanced/travel_assistant/#overview","title":"Overview","text":"<p>The Travel Assistant is designed to help users plan trips, find accommodations, check flight information, and provide travel recommendations. It demonstrates how to build a complex, domain-specific agent that combines multiple capabilities.</p>"},{"location":"examples/advanced/travel_assistant/#key-features","title":"Key Features","text":""},{"location":"examples/advanced/travel_assistant/#multiple-specialized-tools","title":"Multiple Specialized Tools","text":"<p>The assistant implements several tools for different travel-related tasks:</p> <pre><code>@tool\nasync def search_flights(self, origin: str, destination: str, date: str) -&gt; List[Dict]:\n    \"\"\"Search for available flights between locations.\"\"\"\n    # Implementation details...\n\n@tool\nasync def search_hotels(self, location: str, check_in: str, check_out: str) -&gt; List[Dict]:\n    \"\"\"Search for hotels in a specific location.\"\"\"\n    # Implementation details...\n\n@tool\nasync def get_weather_forecast(self, location: str, date: str) -&gt; Dict:\n    \"\"\"Get weather forecast for a location on a specific date.\"\"\"\n    # Implementation details...\n\n@tool\nasync def get_destination_info(self, location: str) -&gt; Dict:\n    \"\"\"Get tourist information about a destination.\"\"\"\n    # Implementation details...\n</code></pre>"},{"location":"examples/advanced/travel_assistant/#memory-integration","title":"Memory Integration","text":"<p>The assistant uses memory to maintain context across conversation turns:</p> <pre><code>@Agent(\n    model=\"gemini-1.5-pro\",\n    memory_backend=\"inmemory\",\n    memory_ttl=3600,  # 1 hour TTL for memory\n    description=\"A travel assistant that helps plan trips, find flights and accommodations.\"\n)\nclass TravelAssistant(BaseAgent):\n    # Agent implementation...\n</code></pre>"},{"location":"examples/advanced/travel_assistant/#lifecycle-hooks","title":"Lifecycle Hooks","text":"<p>The agent uses lifecycle hooks to initialize resources and clean up after conversations:</p> <pre><code>def on_initialize(self):\n    \"\"\"Set up API clients and resources when the agent is initialized.\"\"\"\n    self.flight_api = FlightAPI(api_key=os.environ.get(\"FLIGHT_API_KEY\"))\n    self.hotel_api = HotelAPI(api_key=os.environ.get(\"HOTEL_API_KEY\"))\n    self.weather_api = WeatherAPI()\n\n    # Initialize user preferences storage\n    self.user_preferences = {}\n\ndef on_finish(self, result):\n    \"\"\"Clean up resources and log the interaction.\"\"\"\n    # Log the completed interaction\n    logger.info(f\"Completed travel planning session: {result[:100]}...\")\n</code></pre>"},{"location":"examples/advanced/travel_assistant/#implementation-details","title":"Implementation Details","text":""},{"location":"examples/advanced/travel_assistant/#data-models","title":"Data Models","text":"<p>The assistant uses Pydantic models for structured data handling:</p> <pre><code>class FlightInfo(BaseModel):\n    airline: str\n    flight_number: str\n    departure_time: str\n    arrival_time: str\n    price: float\n    currency: str\n\nclass HotelInfo(BaseModel):\n    name: str\n    address: str\n    rating: float\n    price_per_night: float\n    currency: str\n    amenities: List[str]\n</code></pre>"},{"location":"examples/advanced/travel_assistant/#api-integration","title":"API Integration","text":"<p>The assistant integrates with external APIs through dedicated client classes:</p> <pre><code>class FlightAPI:\n    def __init__(self, api_key: str):\n        self.api_key = api_key\n        self.base_url = \"https://api.flights.example.com\"\n\n    async def search(self, origin: str, destination: str, date: str) -&gt; List[Dict]:\n        # Implementation details...\n\nclass HotelAPI:\n    def __init__(self, api_key: str):\n        self.api_key = api_key\n        self.base_url = \"https://api.hotels.example.com\"\n\n    async def search(self, location: str, check_in: str, check_out: str) -&gt; List[Dict]:\n        # Implementation details...\n</code></pre>"},{"location":"examples/advanced/travel_assistant/#user-preferences-storage","title":"User Preferences Storage","text":"<p>The assistant can store and use user preferences:</p> <pre><code>@tool\ndef save_preference(self, category: str, preference: str) -&gt; str:\n    \"\"\"Save a user preference for future reference.\"\"\"\n    self.user_preferences[category] = preference\n    return f\"Saved your preference for {category}: {preference}\"\n\n@tool\ndef get_personalized_recommendations(self, location: str) -&gt; List[Dict]:\n    \"\"\"Get personalized recommendations based on user preferences.\"\"\"\n    preferences = self.user_preferences\n    # Use preferences to filter and sort recommendations\n    # Implementation details...\n</code></pre>"},{"location":"examples/advanced/travel_assistant/#usage-example","title":"Usage Example","text":"<p>Here's how a user might interact with the Travel Assistant:</p> <pre><code>from travel_assistant import TravelAssistant\n\nasync def main():\n    assistant = TravelAssistant()\n\n    # First interaction\n    response = await assistant.run(\n        \"I'm planning a trip to Paris from New York in October\"\n    )\n    print(response)\n\n    # Follow-up question\n    response = await assistant.run(\n        \"What's the weather like there in October? And can you suggest some hotels?\"\n    )\n    print(response)\n\n    # Adding preferences\n    response = await assistant.run(\n        \"I prefer boutique hotels with at least a 4-star rating\"\n    )\n    print(response)\n\n    # Getting personalized recommendations\n    response = await assistant.run(\n        \"Based on my preferences, what activities would you recommend in Paris?\"\n    )\n    print(response)\n\nif __name__ == \"__main__\":\n    import asyncio\n    asyncio.run(main())\n</code></pre>"},{"location":"examples/advanced/travel_assistant/#full-source-code","title":"Full Source Code","text":"<p>For the complete implementation of the Travel Assistant, refer to the travel_assistant.py file in the examples directory.</p>"},{"location":"examples/advanced/travel_assistant/#key-takeaways","title":"Key Takeaways","text":"<p>The Travel Assistant example demonstrates several important patterns:</p> <ol> <li>Domain-Specific Agents: Building agents tailored to specific domains with specialized knowledge</li> <li>Tool Composition: Combining multiple tools to create comprehensive functionality</li> <li>Stateful Conversations: Using memory to maintain context across multiple interactions</li> <li>External API Integration: Connecting to third-party services securely</li> <li>Preference Management: Storing and using user preferences for personalization</li> </ol> <p>By studying this example, you can learn how to build complex, stateful agents that integrate with external services and maintain contextual awareness across conversation turns.</p>"},{"location":"examples/advanced/workflow_demo/","title":"Workflow Orchestration Demo","text":"<p>This example demonstrates FastADK's workflow orchestration capabilities, showing how to create, configure, and execute different types of workflows.</p>"},{"location":"examples/advanced/workflow_demo/#features-demonstrated","title":"Features Demonstrated","text":"<ul> <li>Creating sequential and parallel workflows</li> <li>Using step decorators to define workflow steps</li> <li>Creating conditional branches in workflows</li> <li>Handling errors and retries in workflow steps</li> <li>Composing multiple workflow steps together</li> <li>Transforming and merging data between workflow steps</li> </ul>"},{"location":"examples/advanced/workflow_demo/#prerequisites","title":"Prerequisites","text":"<p>No external dependencies or API keys are required for this example. It runs entirely with simulated data.</p> <p>To run the example:</p> <pre><code>uv run workflow_demo.py\n</code></pre>"},{"location":"examples/advanced/workflow_demo/#how-it-works","title":"How It Works","text":"<p>This example creates three different workflow scenarios:</p> <ol> <li>Weather Workflow: A sequential workflow that processes weather data through several steps</li> <li>Finance Workflow: A workflow with conditional branching based on data quality</li> <li>Parallel Workflow: A workflow that processes multiple data sources in parallel and merges the results</li> </ol> <p>Each workflow demonstrates different capabilities of the FastADK workflow system:</p>"},{"location":"examples/advanced/workflow_demo/#sequential-workflow","title":"Sequential Workflow","text":"<p>The weather workflow demonstrates a simple sequential flow:</p> <ol> <li>Load weather data from a simulated source</li> <li>Validate the data structure with retry capabilities</li> <li>Enrich the data with additional calculated fields</li> <li>Analyze the weather data to produce recommendations</li> </ol>"},{"location":"examples/advanced/workflow_demo/#conditional-workflow","title":"Conditional Workflow","text":"<p>The finance workflow demonstrates conditional branching:</p> <ol> <li>Load financial data from a simulated source</li> <li>Validate the data with retry capabilities</li> <li>Enrich the data with additional calculated fields</li> <li>Check data quality with a conditional branch:</li> <li>If quality is high: Perform detailed financial analysis</li> <li>If quality is low: Return a basic response without analysis</li> </ol>"},{"location":"examples/advanced/workflow_demo/#parallel-workflow","title":"Parallel Workflow","text":"<p>The parallel workflow demonstrates processing multiple data sources simultaneously:</p> <ol> <li>Load weather and financial data in parallel</li> <li>Process each data source through its own pipeline</li> <li>Merge the results from both pipelines into a single response</li> </ol>"},{"location":"examples/advanced/workflow_demo/#core-components","title":"Core Components","text":"<ul> <li>@step decorator: Defines workflow steps with optional configuration like timeout and retry</li> <li>@transform decorator: Creates steps that transform data without async operations</li> <li>@merge decorator: Defines steps that combine results from multiple parallel processes</li> <li>conditional(): Creates branching logic based on data values</li> <li>ParallelFlow: Executes multiple steps simultaneously</li> <li>SequentialFlow: Executes steps one after another</li> <li>Workflow: Manages the execution of a workflow with telemetry and error handling</li> </ul>"},{"location":"examples/advanced/workflow_demo/#expected-output","title":"Expected Output","text":"<p>When you run the script, you should see output similar to:</p> <pre><code>\ud83d\ude80 FastADK Workflow Orchestration Demo\n=======================================\n\n\ud83c\udf1f Running Weather Workflow\n========================\n\ud83d\udd04 Loading data from weather...\n\ud83d\udd0d Validating data...\n\u2728 Enriching data...\n\ud83c\udf24\ufe0f Analyzing weather data...\n\n\u2705 Weather Workflow Result:\nExecution time: 1.23s\nAnalysis: Great day to be outside!\n========================\n\n\ud83c\udf1f Running Finance Workflow\n========================\n\ud83d\udd04 Loading data from finance...\n\ud83d\udd0d Validating data...\n\u2728 Enriching data...\n\ud83d\udcc8 Analyzing financial data...\n\n\u2705 Finance Workflow Result:\nExecution time: 1.45s\nAnalysis: Strong buy\n========================\n\n\ud83c\udf1f Running Parallel Analysis Workflow\n==================================\n\ud83d\udd04 Loading data from weather...\n\ud83d\udd04 Loading data from finance...\n\ud83d\udd0d Validating data...\n\ud83d\udd0d Validating data...\n\u2728 Enriching data...\n\u2728 Enriching data...\n\ud83c\udf24\ufe0f Analyzing weather data...\n\ud83d\udcc8 Analyzing financial data...\n\ud83d\udcca Formatting final results...\nProcessing result: valid=True, has_analysis=True\nAdded weather insight: Weather in New York: 72\u00b0F, sunny. Great day to be outside!\nProcessing result: valid=True, has_analysis=True\nAdded finance insight: Stock AAPL: $178.72 (+1.25). Recommendation: Strong buy\n\n\u2705 Parallel Workflow Result:\nExecution time: 1.67s\nInsights: 2 found\n  - Weather in New York: 72\u00b0F, sunny. Great day to be outside!\n  - Stock AAPL: $178.72 (+1.25). Recommendation: Strong buy\n==================================\n\n\ud83c\udfc1 All workflow demos completed!\n</code></pre>"},{"location":"examples/advanced/workflow_demo/#key-concepts","title":"Key Concepts","text":"<ol> <li> <p>Workflow Composition: FastADK allows you to compose complex workflows from simple steps using operators like <code>&gt;&gt;</code> and classes like <code>SequentialFlow</code> and <code>ParallelFlow</code>.</p> </li> <li> <p>Error Handling: Each step can be configured with retry logic, timeouts, and error handlers.</p> </li> <li> <p>Data Transformation: Workflows can transform data between steps, with each step receiving the output of the previous step.</p> </li> <li> <p>Conditional Logic: Workflows can include conditional branching based on data values or external conditions.</p> </li> <li> <p>Parallel Processing: Multiple data streams can be processed simultaneously and later merged.</p> </li> </ol>"},{"location":"examples/advanced/workflow_demo/#best-practices-demonstrated","title":"Best Practices Demonstrated","text":"<ul> <li>Breaking complex processes into discrete, reusable steps</li> <li>Using meaningful names for workflow steps</li> <li>Handling errors at the workflow step level</li> <li>Using conditional logic to branch workflows</li> <li>Transforming data between workflow steps</li> <li>Merging results from parallel processes</li> </ul>"},{"location":"examples/api/http_agent/","title":"HTTP Agent Example","text":"<p>This example demonstrates how to serve multiple FastADK agents via a HTTP API using FastAPI. It shows how to create, configure, and expose different agent classes with their own tools and capabilities through a unified API interface.</p>"},{"location":"examples/api/http_agent/#features-demonstrated","title":"Features Demonstrated","text":"<ul> <li>Creating multiple agent classes with different LLM providers</li> <li>Registering agents with the FastADK registry</li> <li>Setting up a FastAPI application that serves all registered agents</li> <li>Tool caching with TTL (Time To Live)</li> <li>Maintaining agent state between requests</li> <li>Using lifecycle hooks for request monitoring</li> <li>Documenting API endpoints with OpenAPI</li> </ul>"},{"location":"examples/api/http_agent/#prerequisites","title":"Prerequisites","text":"<p>To run this example, you need:</p> <ol> <li>Install the required dependencies:</li> </ol> <pre><code>uv add fastapi uvicorn python-dotenv\n</code></pre> <ol> <li>Set up API keys for the LLM providers you want to use, either via environment variables:</li> </ol> <pre><code>export GEMINI_API_KEY=your_key_here\nexport OPENAI_API_KEY=your_key_here\nexport ANTHROPIC_API_KEY=your_key_here\n</code></pre> <p>Or by creating a <code>.env</code> file in the project root:</p> <pre><code>GEMINI_API_KEY=your_key_here\nOPENAI_API_KEY=your_key_here\nANTHROPIC_API_KEY=your_key_here\n</code></pre> <ol> <li>Run the server:</li> </ol> <pre><code>uv run http_agent.py\n</code></pre> <ol> <li>Access the API documentation at http://127.0.0.1:8000/docs</li> </ol>"},{"location":"examples/api/http_agent/#how-it-works","title":"How It Works","text":"<p>This example creates three different agent classes:</p> <ol> <li>WeatherAssistant: Uses Gemini provider to offer weather information and fun facts</li> <li>Demonstrates stateful tools that remember user preferences</li> <li>Shows tool caching with the <code>cache_ttl</code> parameter</li> <li> <p>Implements lifecycle hooks with <code>on_start</code> and <code>on_finish</code></p> </li> <li> <p>MathHelper: Uses OpenAI provider to perform mathematical calculations</p> </li> <li>Shows basic error handling with division by zero</li> <li> <p>Demonstrates numerical tools with validation</p> </li> <li> <p>TextHelper: Uses Anthropic provider to analyze and manipulate text</p> </li> <li>Shows text processing tools with different parameters</li> <li>Demonstrates handling of complex string inputs and outputs</li> </ol> <p>The example uses FastADK's built-in registry and <code>create_app()</code> function to automatically expose all registered agents via a FastAPI application.</p>"},{"location":"examples/api/http_agent/#api-endpoints","title":"API Endpoints","text":"<p>When running, the server exposes the following main endpoints:</p> <ul> <li>GET /agents: List all available agents</li> <li>POST /agents/{agent_name}/run: Run an agent with a user query</li> <li>GET /agents/{agent_name}/tools: List all tools available for a specific agent</li> <li>POST /agents/{agent_name}/tools/{tool_name}: Execute a specific tool</li> <li>OpenAPI documentation: Available at <code>/docs</code> endpoint</li> </ul>"},{"location":"examples/api/http_agent/#expected-output","title":"Expected Output","text":"<p>When you run the script, you should see output similar to:</p> <pre><code>\ud83d\ude80 Starting FastADK API Server\n============================\nAvailable Agents:\n- WeatherAssistant (gemini-1.5-pro)\n- MathHelper (gpt-4)\n- TextHelper (claude-3-haiku)\n\nAPI documentation available at http://127.0.0.1:8000/docs\n============================\nINFO:     Started server process [1234]\nINFO:     Waiting for application startup.\nINFO:     Application startup complete.\nINFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n</code></pre>"},{"location":"examples/api/http_agent/#using-the-api","title":"Using the API","text":""},{"location":"examples/api/http_agent/#example-api-requests","title":"Example API Requests","text":"<ol> <li>List all agents:</li> </ol> <pre><code>curl -X GET http://127.0.0.1:8000/agents\n</code></pre> <ol> <li>Run an agent with a query:</li> </ol> <pre><code>curl -X POST http://127.0.0.1:8000/agents/WeatherAssistant/run \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"query\": \"What's the weather like in Paris?\"}'\n</code></pre> <ol> <li>Execute a specific tool:</li> </ol> <pre><code>curl -X POST http://127.0.0.1:8000/agents/MathHelper/tools/multiply \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"a\": 5, \"b\": 7}'\n</code></pre>"},{"location":"examples/api/http_agent/#key-concepts","title":"Key Concepts","text":"<ol> <li> <p>Agent Registry: FastADK's registry system allows different agent classes to be discovered and exposed via the API.</p> </li> <li> <p>Multi-Provider Support: The example shows how to use different LLM providers (Gemini, OpenAI, Anthropic) in the same application.</p> </li> <li> <p>Tool Caching: The <code>cache_ttl</code> parameter demonstrates how to cache tool results to improve performance and reduce API calls.</p> </li> <li> <p>Stateful Agents: The WeatherAssistant demonstrates maintaining state between requests with the <code>favorite_cities</code> list.</p> </li> <li> <p>OpenAPI Integration: FastADK automatically generates OpenAPI documentation for all registered agents and their tools.</p> </li> </ol>"},{"location":"examples/api/http_agent/#best-practices-demonstrated","title":"Best Practices Demonstrated","text":"<ul> <li>Creating specialized agents for different domains (weather, math, text)</li> <li>Using appropriate LLM providers for different types of tasks</li> <li>Implementing proper error handling in tools</li> <li>Caching appropriate tool results to improve performance</li> <li>Maintaining minimal state for better user experience</li> <li>Using lifecycle hooks for monitoring and debugging</li> </ul>"},{"location":"examples/basic/exception_demo/","title":"Exception Handling Demo","text":"<p>This example demonstrates FastADK's comprehensive exception handling system, showing how different types of errors are captured, translated, and presented to users in a consistent way.</p>"},{"location":"examples/basic/exception_demo/#features-demonstrated","title":"Features Demonstrated","text":"<ul> <li>Property type validation with custom validation rules</li> <li>Converting standard Python exceptions to FastADK exceptions</li> <li>Error code and details standardization</li> <li>Handling external API errors</li> <li>Configuration validation and error handling</li> <li>Using FastADK's exception hierarchy</li> </ul>"},{"location":"examples/basic/exception_demo/#prerequisites","title":"Prerequisites","text":"<p>To run this example, you need:</p> <pre><code># Install the requests library\nuv add requests\n</code></pre> <p>No API key is required for this example.</p>"},{"location":"examples/basic/exception_demo/#how-it-works","title":"How It Works","text":"<p>The example includes an <code>ExceptionDemoAgent</code> with three tools that demonstrate different aspects of exception handling:</p> <ol> <li><code>validate_user</code>: Demonstrates property validation for email and age</li> <li>Uses <code>EmailProperty</code> to validate email format</li> <li> <p>Uses <code>QuantityProperty</code> to validate age with a minimum value constraint</p> </li> <li> <p><code>fetch_external_data</code>: Shows handling of external API errors</p> </li> <li>Validates URLs using <code>URLProperty</code></li> <li>Translates standard request exceptions to FastADK exceptions</li> <li> <p>Includes fallback handling for unexpected errors</p> </li> <li> <p><code>check_configuration</code>: Demonstrates configuration validation</p> </li> <li>Shows custom error codes and details</li> <li>Validates input against a predefined list of valid options</li> </ol> <p>The example runs through various test cases that trigger different types of exceptions, showing how they are caught, processed, and displayed to the user.</p>"},{"location":"examples/basic/exception_demo/#expected-output","title":"Expected Output","text":"<p>When you run the script, you'll see output similar to:</p> <pre><code>\ud83d\ude80 Exception Handling Demo Agent\n\n\ud83d\udd0d Testing email validation...\n\u274c Error [TOOL_EXECUTION_ERROR]: Tool 'validate_user' failed: [PROPERTY_VALIDATION_FAILED] Invalid email format: invalid-email\n   Details: {'tool_name': 'validate_user', 'original_error': '[PROPERTY_VALIDATION_FAILED] Invalid email format: invalid-email', 'error_type': 'ValidationError'}\n\n\ud83d\udd0d Testing age validation...\n\u274c Error [TOOL_EXECUTION_ERROR]: Tool 'validate_user' failed: [PROPERTY_VALIDATION_FAILED] Value must be at least 18 years: 16\n   Details: {'tool_name': 'validate_user', 'original_error': '[PROPERTY_VALIDATION_FAILED] Value must be at least 18 years: 16', 'error_type': 'ValidationError'}\n\n\ud83d\udd0d Testing external API error handling...\n\u274c Error [TOOL_EXECUTION_ERROR]: Tool 'fetch_external_data' failed: [EXTERNAL_CONNECTIONERROR] External error: HTTPSConnectionPool(host='non-existent-url.example.com', port=443): Max retries exceeded\n   Details: {'tool_name': 'fetch_external_data', 'original_error': '[EXTERNAL_CONNECTIONERROR] External error...', 'error_type': 'ServiceUnavailableError'}\n\n\ud83d\udd0d Testing configuration error handling...\n\u274c Error [TOOL_EXECUTION_ERROR]: Tool 'check_configuration' failed: [INVALID_CONFIG_TYPE] Invalid configuration type: invalid\n   Details: {'tool_name': 'check_configuration', 'original_error': '[INVALID_CONFIG_TYPE] Invalid configuration type: invalid', 'error_type': 'ConfigurationError'}\n\n\ud83d\udd0d Testing successful validation...\n\u2705 Result: {'status': 'valid', 'email': 'user@example.com', 'age': '25 years'}\n\n\ud83d\udd0d Testing successful configuration check...\n\u2705 Result: {'status': 'valid', 'message': 'API configuration is valid'}\n</code></pre>"},{"location":"examples/basic/exception_demo/#key-concepts","title":"Key Concepts","text":"<ol> <li> <p>Error Hierarchy: FastADK has a hierarchy of exception classes that help categorize errors.</p> </li> <li> <p>Error Translation: The <code>ExceptionTranslator</code> converts standard Python exceptions to FastADK exceptions.</p> </li> <li> <p>Standardized Error Format: All FastADK errors include:</p> </li> <li>A human-readable message</li> <li>A machine-readable error code</li> <li> <p>A details dictionary with contextual information</p> </li> <li> <p>Property Validation: FastADK's property types provide built-in validation with meaningful error messages.</p> </li> </ol>"},{"location":"examples/basic/exception_demo/#best-practices-demonstrated","title":"Best Practices Demonstrated","text":"<ul> <li>Using specific exception types for different error categories</li> <li>Including detailed error context in exception details</li> <li>Handling and translating external API errors</li> <li>Validating inputs before processing</li> <li>Providing clear, user-friendly error messages</li> </ul>"},{"location":"examples/basic/litellm_demo/","title":"LiteLLM Provider Demo","text":"<p>This example demonstrates how to use FastADK with LiteLLM as a provider, giving you access to 100+ LLM APIs from OpenAI, Anthropic, Cohere, Hugging Face, and others through a unified interface.</p>"},{"location":"examples/basic/litellm_demo/#features-demonstrated","title":"Features Demonstrated","text":"<ul> <li>Using LiteLLM as a provider for FastADK</li> <li>Accessing different language models through a unified interface</li> <li>Token usage tracking with cost estimation</li> <li>Environment variable configuration for API keys</li> <li>Graceful error handling for missing credentials</li> </ul>"},{"location":"examples/basic/litellm_demo/#prerequisites","title":"Prerequisites","text":"<p>To run this example, you need:</p> <ol> <li>Install the LiteLLM package:</li> </ol> <pre><code>uv add litellm python-dotenv\n</code></pre> <ol> <li>Set your API key either via environment variable:</li> </ol> <pre><code>export LITELLM_API_KEY=your_api_key_here\n# OR use a specific provider key\nexport OPENAI_API_KEY=your_api_key_here\n</code></pre> <p>Or in a <code>.env</code> file:</p> <pre><code>LITELLM_API_KEY=your_api_key_here\n# OR\nOPENAI_API_KEY=your_api_key_here\n</code></pre> <ol> <li>Run the example:</li> </ol> <pre><code>uv run litellm_demo.py\n</code></pre>"},{"location":"examples/basic/litellm_demo/#how-it-works","title":"How It Works","text":"<p>The example creates a <code>LiteLLMAgent</code> with the following characteristics:</p> <ol> <li>Uses <code>provider=\"litellm\"</code> to specify LiteLLM as the provider</li> <li>Configures the agent to use \"gpt-4.1\" model (which can be any model supported by LiteLLM)</li> <li>Implements a simple weather tool to demonstrate tool integration</li> <li>Tracks token usage to show costs</li> </ol> <p>When run, the agent processes a query about both the weather in San Francisco and what makes LiteLLM special, showing how the agent can combine custom tool data with model-generated information.</p>"},{"location":"examples/basic/litellm_demo/#litellm-modes","title":"LiteLLM Modes","text":"<p>LiteLLM can be used in two modes:</p> <ol> <li> <p>SDK Mode (demonstrated in this example): Uses the LiteLLM Python package directly, which is the simplest way to get started.</p> </li> <li> <p>Proxy Mode: Uses the LiteLLM proxy server for advanced features like:</p> </li> <li>Request routing</li> <li>Model fallbacks</li> <li>Response caching</li> <li>Load balancing</li> <li>Detailed usage tracking</li> </ol>"},{"location":"examples/basic/litellm_demo/#expected-output","title":"Expected Output","text":"<p>When you run the script, you should see output similar to:</p> <pre><code>\ud83e\udd16 Sending a question to the LiteLLM agent...\n\n\u2728 Agent response:\nThe weather in San Francisco is currently sunny with a temperature of 72\u00b0F and 40% humidity.\n\nLiteLLM is special because it provides a unified interface to access over 100 different LLM APIs from various providers like OpenAI, Anthropic, Cohere, Hugging Face, and many others. This means you can easily switch between different language models without changing your code. It also offers features like routing, fallbacks, caching, and more. Essentially, it simplifies working with multiple LLM providers through a single, consistent API.\n\n\ud83d\udcca Token usage statistics:\n  - Session tokens used: 210\n  - Session cost: $0.000630\n</code></pre>"},{"location":"examples/basic/litellm_demo/#key-concepts","title":"Key Concepts","text":"<ol> <li> <p>Provider Flexibility: LiteLLM allows you to switch between different LLM providers by simply changing the model name, without modifying your code.</p> </li> <li> <p>Unified API: The same code can work with models from OpenAI, Anthropic, Cohere, and many other providers.</p> </li> <li> <p>Token Tracking: FastADK's token tracking works seamlessly with LiteLLM, providing cost estimates across different providers.</p> </li> <li> <p>Environment Variables: The example shows how to use environment variables to securely store API keys.</p> </li> </ol>"},{"location":"examples/basic/litellm_demo/#best-practices-demonstrated","title":"Best Practices Demonstrated","text":"<ul> <li>Using environment variables for API key management</li> <li>Checking for required credentials before attempting to use the agent</li> <li>Providing clear error messages when credentials are missing</li> <li>Displaying token usage for cost monitoring</li> <li>Using a unified provider interface for maximum flexibility</li> </ul>"},{"location":"examples/basic/litellm_demo/#additional-resources","title":"Additional Resources","text":"<ul> <li>LiteLLM Documentation</li> <li>Supported Models</li> <li>FastADK Provider Documentation</li> </ul>"},{"location":"examples/basic/reasoning_demo/","title":"Chain of Thought Reasoning Demo","text":"<p>This example demonstrates how to create a FastADK agent that shows its reasoning process, making tool selection and thought process transparent to users.</p>"},{"location":"examples/basic/reasoning_demo/#features-demonstrated","title":"Features Demonstrated","text":"<ul> <li>Chain of thought reasoning with visible thought process</li> <li>Tool selection process transparency</li> <li>Different types of tools and their integration</li> <li>Graceful handling of API key availability</li> <li>Using the <code>show_reasoning=True</code> parameter</li> </ul>"},{"location":"examples/basic/reasoning_demo/#prerequisites","title":"Prerequisites","text":"<p>This example works without any API keys using the simulated provider. However, for the best experience with real responses, set up a Gemini API key:</p> <pre><code>export GEMINI_API_KEY=your_api_key_here\n</code></pre> <p>To run the example:</p> <pre><code>uv run reasoning_demo.py\n</code></pre>"},{"location":"examples/basic/reasoning_demo/#how-it-works","title":"How It Works","text":"<p>The <code>ReasoningAgent</code> demonstrates transparent reasoning by:</p> <ol> <li>Using the <code>show_reasoning=True</code> parameter to expose the agent's thought process</li> <li>Implementing a variety of tools that require different reasoning approaches:</li> <li><code>get_planet_facts</code>: Retrieves facts about planets from a database</li> <li><code>solve_math_problem</code>: Solves mathematical problems</li> <li><code>check_weather</code>: Provides simulated weather information</li> <li><code>search_database</code>: Performs a search across a simulated database</li> </ol> <p>The agent processes different types of queries that demonstrate how it reasons through problems, selects appropriate tools, and formulates responses based on the tools' outputs.</p>"},{"location":"examples/basic/reasoning_demo/#example-queries","title":"Example Queries","text":"<p>The demo runs through five different types of queries:</p> <ol> <li>Factual information: \"Can you tell me some facts about Mars?\"</li> <li>Weather information with reasoning: \"What's the weather like in Tokyo and should I bring an umbrella?\"</li> <li>Math problem solving: \"I need to solve this math problem: What is 25 \u00d7 13?\"</li> <li>Database search: \"Search for information about moons in our solar system\"</li> <li>Comparative analysis: \"Compare Earth and Jupiter based on their size and composition\"</li> </ol>"},{"location":"examples/basic/reasoning_demo/#expected-output","title":"Expected Output","text":"<p>When you run the script, you'll see output similar to:</p> <pre><code>==================================================\n\ud83e\udde0 FastADK Chain of Thought Reasoning Demo \ud83e\udde0\n==================================================\n\n\ud83d\udccc Example 1/5\n\n\ud83d\udcac User Query: Can you tell me some facts about Mars?\n\n\ud83e\udd16 Processing...\n\n\ud83d\udcdd Final Response:\nI need to provide facts about Mars. Let me use the get_planet_facts tool to retrieve this information.\n\nThinking through the steps:\n1. The user wants facts about Mars\n2. I have a tool called get_planet_facts that can retrieve planet information\n3. I'll use this tool with \"mars\" as the parameter\n\nUsing get_planet_facts tool with planet=\"mars\"...\n\nThe tool returned:\n{\n  \"planet\": \"mars\",\n  \"found\": true,\n  \"facts\": [\n    \"Mars is the fourth planet from the Sun\",\n    \"Mars has a thin atmosphere composed primarily of carbon dioxide\",\n    \"Mars has two small moons, Phobos and Deimos\",\n    \"Mars is often called the 'Red Planet'\",\n    \"Mars has the largest volcano in the solar system, Olympus Mons\"\n  ]\n}\n\nHere are some facts about Mars:\n\n1. Mars is the fourth planet from the Sun\n2. Mars has a thin atmosphere composed primarily of carbon dioxide\n3. Mars has two small moons, Phobos and Deimos\n4. Mars is often called the 'Red Planet'\n5. Mars has the largest volcano in the solar system, Olympus Mons\n\n\ud83d\udd27 Tools Used:\n  - get_planet_facts\n</code></pre> <p>The response includes:</p> <ul> <li>The initial query</li> <li>The agent's step-by-step reasoning process</li> <li>The tool selected and parameters used</li> <li>The raw output from the tool</li> <li>The final formatted response</li> <li>A list of tools used during processing</li> </ul>"},{"location":"examples/basic/reasoning_demo/#key-concepts","title":"Key Concepts","text":"<ol> <li> <p>Transparent Reasoning: By enabling <code>show_reasoning=True</code>, the agent exposes its internal thought process, helping users understand how it arrived at its conclusions.</p> </li> <li> <p>Tool Selection Logic: The agent demonstrates how it selects appropriate tools based on the query, showing the criteria it uses to match user needs with available capabilities.</p> </li> <li> <p>Graceful Degradation: The example works even without an API key by using simulated responses, demonstrating graceful handling of missing credentials.</p> </li> <li> <p>Structured Tool Responses: Each tool returns structured data (dictionaries) that the agent can reason about and transform into natural language responses.</p> </li> </ol>"},{"location":"examples/basic/reasoning_demo/#best-practices-demonstrated","title":"Best Practices Demonstrated","text":"<ul> <li>Using structured documentation in tool methods</li> <li>Providing clear error messages when tools can't fulfill requests</li> <li>Separating data retrieval (tools) from response generation (agent)</li> <li>Making reasoning transparent to build user trust</li> <li>Using type hints for better code clarity and tool parameter handling</li> </ul>"},{"location":"examples/basic/token_tracking_demo/","title":"Token Tracking Demo","text":"<p>This example demonstrates how to use FastADK's token tracking functionality to monitor token usage and costs when interacting with language models.</p>"},{"location":"examples/basic/token_tracking_demo/#features-demonstrated","title":"Features Demonstrated","text":"<ul> <li>Tracking token usage across agent interactions</li> <li>Estimating costs for different language models</li> <li>Comparing token counts across multiple providers</li> <li>Resetting token budget for session management</li> <li>Using the simulated provider for testing without API keys</li> </ul>"},{"location":"examples/basic/token_tracking_demo/#prerequisites","title":"Prerequisites","text":"<p>No API keys or additional dependencies are required for this example since it uses the simulated provider.</p> <p>To run the example:</p> <pre><code>uv run token_tracking_demo.py\n</code></pre>"},{"location":"examples/basic/token_tracking_demo/#how-it-works","title":"How It Works","text":"<p>The <code>TokenTrackingAgent</code> demonstrates token tracking by:</p> <ol> <li>Automatically counting tokens for all prompts and completions</li> <li>Providing tools to access token usage statistics</li> <li>Estimating costs based on model-specific pricing</li> </ol> <p>The example includes two main tools:</p> <ol> <li><code>get_token_count</code>: Counts tokens in a provided text string across multiple models</li> <li>Shows token count differences between models</li> <li> <p>Provides cost estimates for each model</p> </li> <li> <p><code>get_token_usage_stats</code>: Returns the current session's token usage statistics</p> </li> <li>Total tokens used in the session</li> <li>Estimated cost of the session</li> <li>Breakdown by prompt and completion tokens</li> </ol> <p>The example also demonstrates how to reset the token budget to start fresh counting.</p>"},{"location":"examples/basic/token_tracking_demo/#expected-output","title":"Expected Output","text":"<p>When you run the script, you should see output similar to:</p> <pre><code>=== Query 1: Simple Question ===\n2023-07-09 12:30:45,123 - fastadk.tokens - INFO - Token usage: TokenUsage(prompt=6, completion=10, total=16, model=gpt-3.5-turbo, provider=simulated), estimated cost: $0.000032\nResponse: Stub response to: What is the capital of France?\n\n=== Token Usage Stats After Query 1 ===\nSession tokens used: 16\nSession cost: $0.000032\n\n=== Query 2: More Complex Question ===\n2023-07-09 12:30:45,234 - fastadk.tokens - INFO - Token usage: TokenUsage(prompt=11, completion=10, total=21, model=gpt-3.5-turbo, provider=simulated), estimated cost: $0.000042\nResponse: Stub response to: Explain quantum computing in simple terms and give three practical applications.\n\n=== Token Usage Stats After Query 2 ===\nSession tokens used: 37\nSession cost: $0.000074\n\n=== Token Counting Tool Demo ===\nToken counts for different models:\n- gpt-3.5-turbo: 11 tokens, estimated cost: $0.000022\n- gpt-4.1: 11 tokens, estimated cost: $0.000330\n- claude-3.5-sonnet: 16 tokens, estimated cost: $0.000048\n- gemini-2.5-flash: 16 tokens, estimated cost: $0.000016\n\n=== Resetting Token Budget ===\nSession tokens used after reset: 0\nSession cost: $0.0\n</code></pre>"},{"location":"examples/basic/token_tracking_demo/#key-concepts","title":"Key Concepts","text":"<ol> <li> <p>Automatic Token Tracking: FastADK automatically tracks token usage for all agent interactions, including both prompt and completion tokens.</p> </li> <li> <p>Cost Estimation: The framework provides cost estimates based on the current pricing of each model.</p> </li> <li> <p>Cross-Model Comparison: The example shows how token counts can vary between different models and providers.</p> </li> <li> <p>Token Budget Management: The <code>reset_token_budget()</code> method demonstrates how to clear token counts for new sessions or budget periods.</p> </li> <li> <p>Simulated Provider: The example uses the simulated provider for testing without requiring real API keys.</p> </li> </ol>"},{"location":"examples/basic/token_tracking_demo/#best-practices-demonstrated","title":"Best Practices Demonstrated","text":"<ul> <li>Monitoring token usage to control costs</li> <li>Using the simulated provider for testing and development</li> <li>Comparing token counts across models before committing to a specific provider</li> <li>Resetting token budgets for proper session management</li> <li>Logging token usage for audit and analysis</li> </ul>"},{"location":"examples/basic/token_tracking_demo/#practical-applications","title":"Practical Applications","text":"<p>Token tracking is useful for:</p> <ul> <li>Cost estimation for production applications</li> <li>Budget enforcement for multi-user systems</li> <li>Optimizing prompts to reduce token usage</li> <li>Comparing efficiency across different models</li> <li>Identifying potential cost savings in agent implementation</li> </ul>"},{"location":"examples/basic/weather_agent/","title":"Weather Agent Example","text":"<p>This example demonstrates a live, fully-featured weather agent built with FastADK. The agent can provide current weather conditions and multi-day forecasts for any city in the world, acting as a professional meteorologist.</p>"},{"location":"examples/basic/weather_agent/#features-demonstrated","title":"Features Demonstrated","text":"<ul> <li>Using the <code>@Agent</code> and <code>@tool</code> decorators to create a functional agent</li> <li>Live integration with the Gemini provider for AI responses</li> <li>Real-world API integration with wttr.in for weather data</li> <li>Asynchronous tool implementation using <code>httpx</code></li> <li>Loading a system prompt from an external text file</li> <li>Type hinting for robust tool parameter handling</li> <li>Docstrings for automatic tool descriptions and help text</li> <li>Lifecycle hooks for monitoring agent behavior</li> </ul>"},{"location":"examples/basic/weather_agent/#prerequisites","title":"Prerequisites","text":"<p>To run this example, you need:</p> <ol> <li>Install the required HTTP client:</li> </ol> <pre><code>uv add httpx\n</code></pre> <ol> <li>Set up your Gemini API key either by:</li> <li> <p>Setting an environment variable:</p> <pre><code>export GEMINI_API_KEY=your_api_key_here\n</code></pre> </li> <li> <p>Or creating a .env file in the project root with:</p> <pre><code>GEMINI_API_KEY=your_api_key_here\n</code></pre> <p>(requires python-dotenv: <code>uv add python-dotenv</code>)</p> </li> </ol>"},{"location":"examples/basic/weather_agent/#how-it-works","title":"How It Works","text":"<p>This example creates a <code>WeatherAgent</code> class that extends <code>BaseAgent</code> and uses two main tools:</p> <ol> <li><code>get_current_weather</code>: Fetches and processes current weather conditions for a specified city</li> <li><code>get_weather_forecast</code>: Retrieves a multi-day weather forecast for a city</li> </ol> <p>The agent leverages a system prompt from the file <code>weather_agent_prompt.txt</code> that instructs it to act as a professional meteorologist named \"WxWizard\" and to format weather information in a specific way.</p> <p>The example also demonstrates lifecycle hooks through the <code>on_start</code> and <code>on_finish</code> methods, which are called before and after agent execution, respectively.</p>"},{"location":"examples/basic/weather_agent/#expected-output","title":"Expected Output","text":"<p>When you run the script, you should see output similar to:</p> <pre><code>INFO:fastadk.agent:Initialized Gemini model gemini-2.5-flash\nINFO:fastadk.agent:Initialized agent WeatherAgent with 2 tools\n\n--- Testing Agent with a sample query ---\nINFO:__main__:WeatherAgent LIVE processing starting\nINFO:__main__:WeatherAgent LIVE response length: 521\nINFO:fastadk.agent:Agent execution completed in 4.19s\n\nFinal Response:\nThe current weather in London is cloudy with a temperature of 18\u00b0C (64\u00b0F).\nIt feels like 17\u00b0C (63\u00b0F) due to a light breeze and 75% humidity.\n\nI'd recommend bringing a light jacket or sweater as it might feel a bit cool,\nespecially if you'll be outside for extended periods. An umbrella isn't\nnecessary as there's no rain in the immediate forecast.\n\nThe forecast for the next three days shows a gradual warming trend with\ntemperatures rising to 21\u00b0C by Friday, with partly cloudy conditions expected.\n</code></pre>"},{"location":"examples/basic/weather_agent/#code-structure","title":"Code Structure","text":"<p>The script includes:</p> <ul> <li>A helper function <code>_get_weather_data</code> for API calls</li> <li>A <code>WeatherAgent</code> class with two tool methods</li> <li>Lifecycle hook methods</li> <li>A test function to demonstrate the agent in action</li> </ul>"},{"location":"examples/basic/weather_agent/#troubleshooting","title":"Troubleshooting","text":"<p>If you encounter issues:</p> <ol> <li>Make sure your GEMINI_API_KEY is set and valid</li> <li>Check your internet connection (needed to access wttr.in)</li> <li>Ensure httpx is installed: <code>uv add httpx</code></li> </ol>"},{"location":"examples/patterns/configuration_patterns/","title":"Configuration Patterns","text":"<p>This example demonstrates different patterns for managing configuration in FastADK applications, showing various approaches to loading, merging, validating, and using configuration data.</p>"},{"location":"examples/patterns/configuration_patterns/#features-demonstrated","title":"Features Demonstrated","text":"<ul> <li>Loading configuration from environment variables</li> <li>Loading configuration from YAML files</li> <li>Merging configuration from multiple sources</li> <li>Validating configuration with Pydantic models</li> <li>Using configuration hierarchies</li> <li>Overriding configuration at runtime</li> </ul>"},{"location":"examples/patterns/configuration_patterns/#prerequisites","title":"Prerequisites","text":"<p>To run this example:</p> <pre><code>uv add python-dotenv pyyaml\nuv run configuration_patterns.py\n</code></pre> <p>No API key is required as the example works with the simulated provider.</p>"},{"location":"examples/patterns/configuration_patterns/#how-it-works","title":"How It Works","text":"<p>The example demonstrates six different patterns for configuration management:</p>"},{"location":"examples/patterns/configuration_patterns/#pattern-1-environment-variables","title":"Pattern 1: Environment Variables","text":"<ul> <li>Loads configuration from environment variables with a <code>FASTADK_</code> prefix</li> <li>Automatically converts <code>FASTADK_APP_NAME</code> to <code>app_name</code> in the configuration</li> <li>Demonstrates retrieving and using environment-based configuration</li> </ul>"},{"location":"examples/patterns/configuration_patterns/#pattern-2-yaml-configuration","title":"Pattern 2: YAML Configuration","text":"<ul> <li>Creates and loads a sample YAML configuration file</li> <li>Shows a hierarchical configuration structure with providers, agents, and settings</li> <li>Demonstrates validating the loaded configuration</li> </ul>"},{"location":"examples/patterns/configuration_patterns/#pattern-3-merging-configurations","title":"Pattern 3: Merging Configurations","text":"<ul> <li>Combines configuration from multiple sources (YAML and environment variables)</li> <li>Implements a deep merge strategy for nested configuration objects</li> <li>Shows how to prioritize one configuration source over another</li> </ul>"},{"location":"examples/patterns/configuration_patterns/#pattern-4-runtime-configuration-updates","title":"Pattern 4: Runtime Configuration Updates","text":"<ul> <li>Updates configuration values dynamically during runtime</li> <li>Supports dot notation for accessing nested configuration properties</li> <li>Demonstrates safe handling of configuration changes</li> </ul>"},{"location":"examples/patterns/configuration_patterns/#pattern-5-validating-configuration","title":"Pattern 5: Validating Configuration","text":"<ul> <li>Uses Pydantic models to validate configuration structure and values</li> <li>Implements custom validators for specific fields</li> <li>Shows error handling for invalid configuration</li> </ul>"},{"location":"examples/patterns/configuration_patterns/#pattern-6-loading-from-fastadkyaml","title":"Pattern 6: Loading from fastadk.yaml","text":"<ul> <li>Demonstrates loading from a standard configuration file location</li> <li>Shows automatic discovery of configuration files</li> <li>Provides a consistent location for application settings</li> </ul>"},{"location":"examples/patterns/configuration_patterns/#configuration-models","title":"Configuration Models","text":"<p>The example includes several Pydantic models for configuration validation:</p> <ul> <li><code>ProviderConfig</code>: Provider-specific settings like API keys and timeouts</li> <li><code>LoggingConfig</code>: Logging configuration including level, format, and file output</li> <li><code>MemoryConfig</code>: Memory backend settings for agent memory</li> <li><code>AgentConfig</code>: Agent-specific settings like model, provider, and temperature</li> <li><code>AppConfig</code>: Root configuration model containing all other settings</li> </ul>"},{"location":"examples/patterns/configuration_patterns/#expected-output","title":"Expected Output","text":"<p>When you run the script, you'll see output explaining the different configuration patterns:</p> <pre><code>============================================================\n\u2699\ufe0f  FastADK Configuration Patterns Demo\n============================================================\n\n\ud83d\udccc PATTERN 1: ENVIRONMENT VARIABLES\n------------------------------------------------------------\nConfiguration from environment variables:\n  app_name: EnvConfigDemo\n  environment: development\n  logging_level: INFO\n\nAgent configuration:\n  Model: gemini-1.5-pro\n  Provider: gemini\n\n\ud83d\udccc PATTERN 2: YAML CONFIGURATION\n------------------------------------------------------------\nCreated sample YAML configuration at: /tmp/fastadk_config.yaml\n\nLoaded YAML configuration successfully\n\nApplication: ConfigDemoApp v1.0.0\nEnvironment: development\n\nConfigured providers: 2\n  - openai (timeout: 30s, retries: 3)\n  - gemini (timeout: 60s, retries: 2)\n\nConfigured agents: 2\n  - TextAnalysisAgent: gpt-4-turbo @ openai\n    Memory backend: in_memory\n  - CreativeWritingAgent: gemini-1.5-pro @ gemini\n    Memory backend: vector\n\n\ud83d\udccc PATTERN 3: MERGING CONFIGURATIONS\n------------------------------------------------------------\nMerged configuration:\n  App name: EnvConfigDemo\n  Environment: development\n  Logging level: INFO\n\n\ud83d\udccc PATTERN 4: RUNTIME CONFIGURATION UPDATES\n------------------------------------------------------------\nUpdated configuration: Updated logging.level to DEBUG\nUpdated configuration: Updated timeout to 45\n\nUpdated configuration values:\n  Logging level: DEBUG\n  Provider timeout: 45s\n\n\ud83d\udccc PATTERN 5: VALIDATING CONFIGURATION\n------------------------------------------------------------\n\u2705 Valid configuration passed validation\n  App name: ValidConfigDemo\n  Version: 1.0.0\n  Environment: development\n\n\u274c Invalid configuration failed validation\n  (See logs for validation error details)\n\n\ud83d\udccc PATTERN 6: LOADING FROM FASTADK.YAML\n------------------------------------------------------------\nCreated fastadk.yaml at: /tmp/fastadk.yaml\n\nLoaded configuration from fastadk.yaml:\n  App name: FastADKDemo\n  Version: 1.0.0\n  Environment: development\n\n============================================================\n\ud83c\udfc1 FastADK - Configuration Patterns Demo Completed\n============================================================\n</code></pre>"},{"location":"examples/patterns/configuration_patterns/#key-concepts","title":"Key Concepts","text":"<ol> <li> <p>Pydantic Validation: Using Pydantic models to enforce configuration schema and validate values.</p> </li> <li> <p>Configuration Hierarchy: Organizing configuration in a logical hierarchy for better management.</p> </li> <li> <p>Multiple Sources: Loading configuration from multiple sources and merging them.</p> </li> <li> <p>Environment-Based Configuration: Using environment variables for deployment-specific settings.</p> </li> <li> <p>Runtime Updates: Safely modifying configuration during application runtime.</p> </li> </ol>"},{"location":"examples/patterns/configuration_patterns/#best-practices-demonstrated","title":"Best Practices Demonstrated","text":"<ul> <li>Using environment variables for sensitive information like API keys</li> <li>Validating configuration before using it</li> <li>Providing reasonable defaults for optional configuration</li> <li>Supporting multiple configuration sources</li> <li>Using a standardized configuration file format (YAML)</li> <li>Implementing robust error handling for configuration loading</li> <li>Sanitizing sensitive information when displaying configuration</li> </ul>"},{"location":"examples/patterns/tool_patterns/","title":"Tool Development Patterns","text":"<p>This example demonstrates different patterns for developing and using tools in FastADK, showing various approaches to tool implementation, validation, error handling, and registration.</p>"},{"location":"examples/patterns/tool_patterns/#features-demonstrated","title":"Features Demonstrated","text":"<ul> <li>Basic synchronous and asynchronous tools</li> <li>Tools with validation and error handling using Pydantic</li> <li>Tools with nested structure and rich returns</li> <li>Parameterized tools with default values</li> <li>Dynamic tool registration patterns</li> <li>Tool composition and reuse</li> </ul>"},{"location":"examples/patterns/tool_patterns/#prerequisites","title":"Prerequisites","text":"<p>To run this example:</p> <pre><code>uv add python-dotenv\nuv run tool_patterns.py\n</code></pre> <p>No API key is required as the example works with the simulated provider.</p>"},{"location":"examples/patterns/tool_patterns/#how-it-works","title":"How It Works","text":"<p>The example creates a <code>ToolPatternsAgent</code> that demonstrates six different patterns for tool development:</p>"},{"location":"examples/patterns/tool_patterns/#pattern-1-basic-synchronous-tool","title":"Pattern 1: Basic Synchronous Tool","text":"<p>The <code>get_current_time</code> tool shows a simple synchronous tool that returns structured time information:</p> <ul> <li>No input parameters</li> <li>Dictionary return type</li> <li>Simple implementation</li> </ul>"},{"location":"examples/patterns/tool_patterns/#pattern-2-async-tool-with-simulated-delay","title":"Pattern 2: Async Tool with Simulated Delay","text":"<p>The <code>get_random_number</code> tool demonstrates:</p> <ul> <li>Asynchronous implementation with <code>async/await</code></li> <li>Parameter defaults (min_value=1, max_value=100)</li> <li>Simulated delay to demonstrate async operation</li> <li>Structured return with multiple fields</li> </ul>"},{"location":"examples/patterns/tool_patterns/#pattern-3-tool-with-pydantic-validation","title":"Pattern 3: Tool with Pydantic Validation","text":"<p>The <code>get_weather</code> tool shows:</p> <ul> <li>Input validation using Pydantic models</li> <li>Field validators with custom logic</li> <li>Structured error handling for validation failures</li> <li>Normalized input processing</li> </ul>"},{"location":"examples/patterns/tool_patterns/#pattern-4-tool-with-rich-error-handling","title":"Pattern 4: Tool with Rich Error Handling","text":"<p>The <code>search</code> tool demonstrates:</p> <ul> <li>Comprehensive error handling strategies</li> <li>Performance timing</li> <li>Structured response objects</li> <li>Try/except patterns for graceful failure</li> </ul>"},{"location":"examples/patterns/tool_patterns/#pattern-5-nested-tool-with-hierarchical-structure","title":"Pattern 5: Nested Tool with Hierarchical Structure","text":"<p>The <code>get_system_info</code> tool shows:</p> <ul> <li>Complex nested data structures</li> <li>Hierarchical information organization</li> <li>Multiple levels of nesting</li> </ul>"},{"location":"examples/patterns/tool_patterns/#pattern-6-dynamic-tool-registration","title":"Pattern 6: Dynamic Tool Registration","text":"<p>This pattern shows how to:</p> <ul> <li>Define tools programmatically at runtime</li> <li>Register tools based on runtime conditions</li> <li>Add both synchronous and asynchronous tools dynamically</li> </ul>"},{"location":"examples/patterns/tool_patterns/#data-models","title":"Data Models","text":"<p>The example includes several Pydantic models for request and response validation:</p> <ul> <li><code>WeatherRequest</code>: Validates location and units for weather requests</li> <li><code>WeatherResponse</code>: Structures weather information responses</li> <li><code>SearchRequest</code>: Validates search queries and result limits</li> <li><code>SearchResult</code>: Models individual search results</li> <li><code>SearchResponse</code>: Structures complete search responses</li> </ul>"},{"location":"examples/patterns/tool_patterns/#expected-output","title":"Expected Output","text":"<p>When you run the script, you'll see output explaining the different tool patterns:</p> <pre><code>============================================================\n\ud83d\udee0\ufe0f  FastADK Tool Patterns Demo\n============================================================\n\n\ud83d\ude80 Initializing agent...\nWould register calculator tool here\nWould register convert_currency tool here\n  (Note: Dynamic tools would be added here)\n\n\ud83d\udccb Available tools: 5\n\n\n\ud83d\udccc PATTERN 1: BASIC SYNCHRONOUS TOOL\n------------------------------------------------------------\nTool: get_current_time\nDescription: Returns the current time and date in a formatted structure\n\n\n\ud83d\udccc PATTERN 2: ASYNC TOOL WITH SIMULATED DELAY\n------------------------------------------------------------\nTool: get_random_number\nDescription: Generates a random number in a specified range with a simulated delay\n\n\n\ud83d\udccc PATTERN 3: TOOL WITH PYDANTIC VALIDATION\n------------------------------------------------------------\nTool: get_weather\nDescription: Gets weather data for a location with input validation\nBenefits: Automatic validation of input parameters and helpful error messages\n\n\n\ud83d\udccc PATTERN 4: TOOL WITH RICH ERROR HANDLING\n------------------------------------------------------------\nTool: search\nDescription: Demonstrates comprehensive error handling with detailed error reporting\n\n\n\ud83d\udccc PATTERN 5: NESTED TOOL WITH HIERARCHICAL STRUCTURE\n------------------------------------------------------------\nTool: get_system_info\nDescription: Shows how to structure complex nested data in tool responses\n\n\n\ud83d\udccc PATTERN 6: DYNAMICALLY REGISTERED TOOLS\n------------------------------------------------------------\nTool: calculator and convert_currency\nDescription: Shows how to dynamically register tools at runtime\nExamples:\n  - calculator: Perform mathematical operations (add, subtract, multiply, divide)\n  - convert_currency: Convert between different currencies\n\n\ud83d\udcdd Summary of Tool Patterns Demonstrated:\n1. Basic synchronous tool - Simple operation with return value\n2. Async tool - Support for asynchronous operations\n3. Tool with Pydantic validation - Type and value validation\n4. Tool with rich error handling - Detailed error reporting\n5. Tool with hierarchical data - Structured nested responses\n6. Dynamically registered tools - Runtime tool registration\n\n============================================================\n\ud83c\udfc1 FastADK -  Tool Patterns Demo Completed\n============================================================\n</code></pre>"},{"location":"examples/patterns/tool_patterns/#key-concepts","title":"Key Concepts","text":"<ol> <li> <p>Tool Decoration: Using the <code>@tool</code> decorator to expose methods as tools with appropriate type hints and documentation.</p> </li> <li> <p>Pydantic Integration: Leveraging Pydantic models for request and response validation.</p> </li> <li> <p>Async Support: Building tools that can operate asynchronously for non-blocking operations.</p> </li> <li> <p>Error Handling: Implementing robust error handling with structured error responses.</p> </li> <li> <p>Dynamic Registration: Adding tools programmatically at runtime based on application needs.</p> </li> </ol>"},{"location":"examples/patterns/tool_patterns/#best-practices-demonstrated","title":"Best Practices Demonstrated","text":"<ul> <li>Using descriptive docstrings for tool documentation</li> <li>Implementing proper error handling and validation</li> <li>Structuring complex data in logical hierarchies</li> <li>Providing default values for optional parameters</li> <li>Using asynchronous functions for operations that might block</li> <li>Validating inputs before processing</li> <li>Including timing information for performance monitoring</li> </ul>"},{"location":"examples/training/fine_tuning_example/","title":"Fine-Tuning Example","text":"<p>This example demonstrates how to use FastADK's fine-tuning utilities to prepare data, create fine-tuning jobs, and use the resulting fine-tuned models.</p>"},{"location":"examples/training/fine_tuning_example/#features-demonstrated","title":"Features Demonstrated","text":"<ul> <li>Converting training data between different format standards</li> <li>Creating and monitoring fine-tuning jobs</li> <li>Using fine-tuned models with FastADK</li> <li>Supporting multiple provider-specific formats</li> <li>Safe job configuration to minimize costs</li> </ul>"},{"location":"examples/training/fine_tuning_example/#prerequisites","title":"Prerequisites","text":"<p>To run this example with actual fine-tuning jobs:</p> <pre><code># Install required packages\nuv add openai\n\n# Set your API key\nexport OPENAI_API_KEY=your_key_here\n</code></pre> <p>Note: Running this example with <code>run_actual_job=True</code> will create real fine-tuning jobs that may incur costs on your OpenAI account. The example is configured to use minimal data and the smallest model (gpt-3.5-turbo) with minimal epochs to keep costs low.</p>"},{"location":"examples/training/fine_tuning_example/#how-it-works","title":"How It Works","text":"<p>The example demonstrates two main capabilities:</p>"},{"location":"examples/training/fine_tuning_example/#1-data-format-conversion","title":"1. Data Format Conversion","text":"<p>FastADK provides utilities to convert between different training data formats:</p> <ul> <li>Alpaca Format: A simple instruction-input-output format</li> <li>OpenAI Format: The format required for OpenAI fine-tuning (JSONL with messages)</li> <li>Vertex Format: The format used by Google's Vertex AI for tuning</li> </ul> <p>The example:</p> <ol> <li>Creates a sample dataset in Alpaca format</li> <li>Converts it to OpenAI's format</li> <li>Converts it to Vertex AI's format</li> <li>Displays samples of the converted data</li> </ol>"},{"location":"examples/training/fine_tuning_example/#2-fine-tuning-job-management","title":"2. Fine-Tuning Job Management","text":"<p>The example shows how to:</p> <ol> <li>Check available fine-tuning providers</li> <li>Create a fine-tuning job configuration</li> <li>Submit a job to the provider</li> <li>Get job status information</li> </ol> <p>For safety, the actual job creation is disabled by default (<code>run_actual_job=False</code>).</p>"},{"location":"examples/training/fine_tuning_example/#sample-data","title":"Sample Data","text":"<p>The example uses a minimal dataset with just two examples:</p> <ol> <li>A text summarization example</li> <li>A creative writing example (haiku)</li> </ol> <p>This small dataset is sufficient to demonstrate the conversion process but would be too small for actual effective fine-tuning in a production scenario.</p>"},{"location":"examples/training/fine_tuning_example/#expected-output","title":"Expected Output","text":"<p>When you run the script, you should see output similar to:</p> <pre><code>=== Data Conversion Example ===\nCreated sample Alpaca data file: /tmp/tmpdirxyz123/alpaca_data.json\n\nConverting from Alpaca to OpenAI format...\n\nConverted OpenAI format data:\n- Message exchange with 2 messages\n- Message exchange with 2 messages\n\nConverting from Alpaca to Vertex format...\n\nConverted Vertex format data:\n- Example: 'Summarize the following text. FastADK is a develo...' -&gt; 'FastADK is a framework that simplifies AI agent dev...'\n- Example: 'Write a haiku about programming. ...' -&gt; 'Fingers on keyboard Logic flows through lines of co...'\n\n=== Fine-Tuning Job Example ===\nAvailable fine-tuning providers: ['openai', 'vertex']\nSkipping actual job creation (run_actual_job=False)\n\nTo create an actual fine-tuning job:\n1. Install the required packages: uv add openai\n2. Set your API key: export OPENAI_API_KEY=your_key_here\n3. Call this function with run_actual_job=True\n</code></pre> <p>If you set <code>run_actual_job=True</code> and have a valid API key, you'll see additional output about the created job:</p> <pre><code>Creating fine-tuning job with model: gpt-3.5-turbo\nCreated job with ID: ft-abc123xyz456\nJob status: validating\nCheck the OpenAI dashboard for job progress\n\nTo check job status later, use:\njob = await default_fine_tuner.get_job('ft-abc123xyz456', FineTuningProvider.OPENAI)\nprint(f'Job status: {job.status}')\n</code></pre>"},{"location":"examples/training/fine_tuning_example/#key-concepts","title":"Key Concepts","text":"<ol> <li> <p>Data Format Conversion: FastADK provides utilities to convert between different training data formats, making it easier to prepare data for different providers.</p> </li> <li> <p>Provider Abstraction: The fine-tuning API abstracts away provider-specific details, allowing you to use a consistent interface across different LLM providers.</p> </li> <li> <p>Job Management: FastADK includes utilities for creating, monitoring, and managing fine-tuning jobs.</p> </li> <li> <p>Cost Management: The example demonstrates how to configure jobs to minimize costs during experimentation.</p> </li> </ol>"},{"location":"examples/training/fine_tuning_example/#best-practices-demonstrated","title":"Best Practices Demonstrated","text":"<ul> <li>Converting data between formats to maximize dataset reuse</li> <li>Using minimal data and epochs for experimentation</li> <li>Providing safety guards against accidental job creation</li> <li>Checking provider availability before creating jobs</li> <li>Using temporary directories for training data files</li> </ul>"},{"location":"examples/ui/streamlit_chat_app/","title":"Streamlit Chat UI Example","text":""},{"location":"examples/ui/streamlit_chat_app/#overview","title":"Overview","text":"<p>This example demonstrates how to create a simple yet effective chat interface for FastADK agents using Streamlit. The application provides a user-friendly web interface that lets users interact with any FastADK agent through a familiar chat UI.</p>"},{"location":"examples/ui/streamlit_chat_app/#features-demonstrated","title":"Features Demonstrated","text":"<ul> <li>Web UI Integration: Creating a web interface for FastADK agents</li> <li>Session State Management: Maintaining conversation history between interactions</li> <li>Asynchronous Processing: Handling agent responses asynchronously</li> <li>Token Usage Tracking: Displaying token usage metrics in the UI</li> <li>Dynamic Agent Loading: Framework for loading different agent types (simplified in demo)</li> <li>Chat History Display: Rendering conversation history with proper formatting</li> </ul>"},{"location":"examples/ui/streamlit_chat_app/#running-this-example","title":"Running this Example","text":""},{"location":"examples/ui/streamlit_chat_app/#1-install-dependencies","title":"1. Install Dependencies","text":"<pre><code>uv add streamlit\n</code></pre>"},{"location":"examples/ui/streamlit_chat_app/#2-run-the-application","title":"2. Run the Application","text":"<pre><code>uv run -m streamlit run examples/ui/streamlit_chat_app.py\n</code></pre> <p>The application will launch in your default web browser. If it doesn't open automatically, navigate to the URL displayed in the terminal (typically http://localhost:8501).</p>"},{"location":"examples/ui/streamlit_chat_app/#user-interface","title":"User Interface","text":"<p>The UI consists of:</p> <ul> <li>Chat Window: The main area showing the conversation history</li> <li>Input Box: A text input field at the bottom for user messages</li> <li>Sidebar: Contains agent information, token usage stats, and controls</li> </ul>"},{"location":"examples/ui/streamlit_chat_app/#sidebar-features","title":"Sidebar Features","text":"<ul> <li>Agent Information: Shows details about the currently loaded agent</li> <li>Token Usage: Displays current token consumption metrics</li> <li>Clear Chat: Button to reset the conversation</li> <li>Settings: Additional controls and information</li> </ul>"},{"location":"examples/ui/streamlit_chat_app/#implementation-details","title":"Implementation Details","text":"<p>The app is implemented with:</p> <ul> <li>Streamlit for the UI framework</li> <li>Asynchronous messaging with the FastADK agent</li> <li>Session state management for conversation persistence</li> <li>Markdown rendering for message formatting</li> </ul>"},{"location":"examples/ui/streamlit_chat_app/#customization","title":"Customization","text":"<p>You can extend this example by:</p> <ul> <li>Loading agents dynamically from a dropdown menu</li> <li>Adding configuration options for the agent</li> <li>Implementing file upload for document-based conversations</li> <li>Adding visualization of agent reasoning process</li> <li>Creating a voice input/output option</li> <li>Implementing a chat export feature</li> </ul>"},{"location":"examples/ui/streamlit_chat_app/#integration-with-your-own-agents","title":"Integration with Your Own Agents","text":"<p>To use this UI with your own FastADK agents:</p> <ol> <li>Modify the <code>load_agent_class()</code> function to load your custom agent</li> <li>Add any necessary configuration options to the sidebar</li> <li>Update token tracking if you've customized how tokens are counted</li> <li>Add any special rendering for structured outputs your agent may provide</li> </ol>"},{"location":"examples/ui/streamlit_chat_app/#requirements","title":"Requirements","text":"<ul> <li>fastadk</li> <li>streamlit</li> <li>An OpenAI API key (set as OPENAI_API_KEY environment variable) or appropriate API key for your chosen model provider.</li> </ul>"},{"location":"getting-started/installation/","title":"Installation","text":"<p>This guide will help you install FastADK and set up your development environment.</p>"},{"location":"getting-started/installation/#prerequisites","title":"Prerequisites","text":"<p>Before installing FastADK, make sure you have:</p> <ul> <li>Python 3.10 or higher</li> <li>API keys for the LLM providers you plan to use (Gemini, OpenAI, Anthropic, etc.)</li> </ul>"},{"location":"getting-started/installation/#installing-uv-recommended","title":"Installing UV (Recommended)","text":"<p>FastADK recommends using UV, a significantly faster package installer and resolver for Python:</p> <pre><code># Install UV using pip (only needed once)\npip install uv\n\n# On macOS with Homebrew\nbrew install uv\n\n# On Linux with pipx\npipx install uv\n</code></pre>"},{"location":"getting-started/installation/#installing-fastadk-with-uv-recommended","title":"Installing FastADK with UV (Recommended)","text":"<p>Once you have UV installed, you can install FastADK:</p> <pre><code># Basic installation\nuv pip install fastadk\n\n# With extras\nuv pip install \"fastadk[dev]\"     # Includes development tools\nuv pip install \"fastadk[test]\"    # Includes testing dependencies\nuv pip install \"fastadk[docs]\"    # Includes documentation tools\nuv pip install \"fastadk[redis]\"   # Includes Redis memory backend\nuv pip install \"fastadk[vector]\"  # Includes vector database support\nuv pip install \"fastadk[all]\"     # Includes all extras\n</code></pre>"},{"location":"getting-started/installation/#installing-with-pip-alternative","title":"Installing with Pip (Alternative)","text":"<p>If you prefer using pip, you can install FastADK with:</p> <pre><code>pip install fastadk\n\n# With extras\npip install \"fastadk[dev]\"     # Includes development tools\npip install \"fastadk[test]\"    # Includes testing dependencies\npip install \"fastadk[docs]\"    # Includes documentation tools\npip install \"fastadk[redis]\"   # Includes Redis memory backend\npip install \"fastadk[vector]\"  # Includes vector database support\npip install \"fastadk[all]\"     # Includes all extras\n</code></pre>"},{"location":"getting-started/installation/#development-setup-with-uv","title":"Development Setup with UV","text":"<p>For setting up a development environment:</p> <pre><code># Clone the repository\ngit clone https://github.com/Mathews-Tom/FastADK.git\ncd fastadk\n\n# Create a virtual environment\nuv venv .venv\n\n# Activate the virtual environment\n# On Linux/macOS:\nsource .venv/bin/activate\n# On Windows:\n# .venv\\Scripts\\activate\n\n# Install development dependencies\nuv pip install -e \".[dev]\"\n</code></pre>"},{"location":"getting-started/installation/#setting-up-environment-variables","title":"Setting Up Environment Variables","text":"<p>FastADK uses environment variables for configuration. You can set these in your shell or in a <code>.env</code> file in your project directory.</p> <pre><code># API keys for different LLM providers\nexport GEMINI_API_KEY=your-gemini-api-key-here\nexport OPENAI_API_KEY=your-openai-api-key-here\nexport ANTHROPIC_API_KEY=your-anthropic-api-key-here\n\n# Optional configuration\nexport FASTADK_ENV=development  # Options: development, production, testing\nexport FASTADK_LOG_LEVEL=INFO  # Options: DEBUG, INFO, WARNING, ERROR, CRITICAL\nexport FASTADK_MEMORY_BACKEND=inmemory  # Options: inmemory, redis\n</code></pre> <p>If using Redis for memory:</p> <pre><code>export REDIS_HOST=localhost\nexport REDIS_PORT=6379\nexport REDIS_DB=0\nexport REDIS_PASSWORD=optional-password\n</code></pre>"},{"location":"getting-started/installation/#verifying-installation","title":"Verifying Installation","text":"<p>To verify that FastADK is correctly installed, run:</p> <pre><code># Activate your virtual environment if not already activated\nsource .venv/bin/activate  # On Linux/macOS\n# .venv\\Scripts\\activate  # On Windows\n\n# Import and check version\nuv run -c \"import fastadk; print(f'FastADK version: {fastadk.__version__}')\"\n</code></pre> <p>This should display the version number of FastADK.</p>"},{"location":"getting-started/installation/#running-examples","title":"Running Examples","text":"<p>FastADK includes several examples to help you get started. To run them:</p> <pre><code># Clone the repository if you haven't already\ngit clone https://github.com/Mathews-Tom/FastADK.git\ncd fastadk\n\n# Create and activate a virtual environment if you haven't already\nuv venv .venv\nsource .venv/bin/activate  # On Linux/macOS\n# .venv\\Scripts\\activate  # On Windows\n\n# Install FastADK and dependencies\nuv pip install -e \".[all]\"\n\n# Run a basic example\nuv run examples/basic/weather_agent.py\n\n# Run an advanced example\nuv run examples/advanced/travel_assistant.py\n\n# Start the HTTP API server example\nuv run examples/api/http_agent.py\n</code></pre>"},{"location":"getting-started/installation/#uv-benefits-for-fastadk-development","title":"UV Benefits for FastADK Development","text":"<p>Using UV with FastADK offers several advantages:</p> <ul> <li>Speed: UV installs packages 10-100x faster than pip</li> <li>Reliability: Better dependency resolution and fewer conflicts</li> <li>Reproducibility: More consistent installations across environments</li> <li>Efficiency: Reduced memory usage during package installation</li> <li>Modern: Latest Python packaging standards support</li> </ul>"},{"location":"getting-started/installation/#next-steps","title":"Next Steps","text":"<p>Now that you have FastADK installed, you can:</p> <ul> <li>Continue to the Quick Start Guide to create your first agent</li> <li>Explore the System Overview to understand FastADK's architecture</li> <li>Check out the Examples to see FastADK in action</li> <li>Read the API Reference for detailed documentation</li> </ul>"},{"location":"getting-started/quick-start/","title":"Quick Start Guide","text":"<p>This guide will help you create and run your first FastADK agent in just a few minutes.</p>"},{"location":"getting-started/quick-start/#prerequisites","title":"Prerequisites","text":"<p>Ensure you've installed FastADK and have your Google ADK API key set up.</p>"},{"location":"getting-started/quick-start/#create-your-first-agent","title":"Create Your First Agent","text":"<p>Let's create a simple weather agent that can tell us the weather for a given city.</p> <p>Create a new file named <code>weather_agent.py</code>:</p> <pre><code>from fastadk.core import Agent, BaseAgent, tool\n\n@Agent(\n    model=\"gemini-2.0-pro\",  # Specifies the LLM to use\n    description=\"Weather assistant that provides forecasts\"\n)\nclass WeatherAgent(BaseAgent):\n    @tool\n    def get_weather(self, city: str) -&gt; dict:\n        \"\"\"Fetch current weather for a city.\"\"\"\n        # In a real agent, this would call a weather API\n        # For this example, we'll return mock data\n        return {\n            \"city\": city,\n            \"temperature\": \"22\u00b0C\",\n            \"condition\": \"sunny\",\n            \"humidity\": \"45%\"\n        }\n\n    @tool\n    def get_forecast(self, city: str, days: int = 3) -&gt; list:\n        \"\"\"Get weather forecast for multiple days.\"\"\"\n        # Mock forecast data\n        return [\n            {\"day\": 1, \"condition\": \"sunny\", \"temp\": \"25\u00b0C\"},\n            {\"day\": 2, \"condition\": \"cloudy\", \"temp\": \"22\u00b0C\"},\n            {\"day\": 3, \"condition\": \"rainy\", \"temp\": \"19\u00b0C\"}\n        ][:days]\n</code></pre>"},{"location":"getting-started/quick-start/#run-your-agent-in-cli-mode","title":"Run Your Agent in CLI Mode","text":"<p>Run your agent using the FastADK CLI:</p> <pre><code>fastadk run weather_agent.py\n</code></pre> <p>This starts an interactive session where you can chat with your agent. Try asking:</p> <ul> <li>\"What's the weather in Paris?\"</li> <li>\"Can you give me a 5-day forecast for Tokyo?\"</li> <li>\"Should I pack an umbrella for my trip to London?\"</li> </ul> <p>The agent will use your defined tools to answer these questions.</p>"},{"location":"getting-started/quick-start/#serve-your-agent-as-an-http-api","title":"Serve Your Agent as an HTTP API","text":"<p>FastADK can automatically expose your agent as a REST API:</p> <pre><code>fastadk serve weather_agent.py\n</code></pre> <p>This starts a FastAPI server at http://localhost:8000 with the following endpoints:</p> <ul> <li><code>POST /agents/weather</code>: Send messages to your agent</li> <li><code>GET /docs</code>: Swagger UI for API documentation</li> </ul> <p>You can test the API using curl:</p> <pre><code>curl -X POST http://localhost:8000/agents/weather \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"message\": \"What is the weather in San Francisco?\"}'\n</code></pre> <p>Or using the Swagger UI by opening http://localhost:8000/docs in your browser.</p>"},{"location":"getting-started/quick-start/#adding-memory-to-your-agent","title":"Adding Memory to Your Agent","text":"<p>Let's enhance our agent to remember previous conversations:</p> <pre><code>@Agent(\n    model=\"gemini-2.0-pro\",\n    description=\"Weather assistant with memory\",\n    memory_backend=\"inmemory\"  # Enable in-memory storage\n)\nclass WeatherAgentWithMemory(BaseAgent):\n    # ... same tools as before ...\n\n    @tool\n    def remember_preference(self, temperature_unit: str) -&gt; str:\n        \"\"\"Remember the user's preferred temperature unit (C or F).\"\"\"\n        self.context.set(\"preferred_unit\", temperature_unit)\n        return f\"I'll remember that you prefer {temperature_unit}\"\n\n    @tool\n    def get_weather_with_preference(self, city: str) -&gt; dict:\n        \"\"\"Get weather using the user's preferred unit if set.\"\"\"\n        preferred_unit = self.context.get(\"preferred_unit\", \"C\")\n\n        # Mock data with unit conversion\n        temp = 22 if preferred_unit == \"C\" else 72\n        return {\n            \"city\": city,\n            \"temperature\": f\"{temp}\u00b0{preferred_unit}\",\n            \"condition\": \"sunny\"\n        }\n</code></pre> <p>Now your agent will remember the user's temperature preference across messages.</p>"},{"location":"getting-started/quick-start/#error-handling","title":"Error Handling","text":"<p>FastADK provides comprehensive error handling. Let's add some error handling to our agent:</p> <pre><code>from fastadk.core.exceptions import ToolError\n\n@Agent(model=\"gemini-2.0-pro\")\nclass WeatherAgentWithErrorHandling(BaseAgent):\n    @tool\n    def get_weather(self, city: str) -&gt; dict:\n        \"\"\"Fetch current weather for a city.\"\"\"\n        # Validate input\n        if not city or len(city) &lt; 2:\n            raise ToolError(\n                message=\"City name is too short\",\n                error_code=\"INVALID_CITY\",\n                details={\"city\": city}\n            )\n\n        # Implement actual weather lookup\n        # For demo, just return mock data\n        return {\"city\": city, \"temperature\": \"22\u00b0C\"}\n</code></pre>"},{"location":"getting-started/quick-start/#next-steps","title":"Next Steps","text":"<p>Now that you have created your first agent, you can:</p> <ul> <li>Learn about agent workflows for complex scenarios</li> <li>Add advanced memory capabilities with Redis</li> <li>Explore advanced tool features like caching and retries</li> <li>Check out the full examples for more sophisticated implementations</li> </ul>"},{"location":"research/competitive_analysis/","title":"FastADK Competitive Analysis","text":""},{"location":"research/competitive_analysis/#executive-summary","title":"Executive Summary","text":"<p>This analysis examines the current landscape of AI agent development frameworks, with particular focus on those that might compete with or complement FastADK. The findings demonstrate that while several frameworks exist for building AI agents, there is a clear opportunity for FastADK to address developer experience gaps in the Google ADK ecosystem.</p>"},{"location":"research/competitive_analysis/#competitive-landscape-overview","title":"Competitive Landscape Overview","text":""},{"location":"research/competitive_analysis/#direct-competitors-agent-development-frameworks","title":"Direct Competitors (Agent Development Frameworks)","text":"Framework Primary Focus Strengths Weaknesses Opportunity for FastADK LangChain General LLM application orchestration Mature ecosystem, broad adoption Complex, not ADK-specific, steep learning curve Simpler developer experience, ADK specialization AutoGen Multi-agent orchestration Strong in agent-to-agent communication Higher complexity, no declarative API design Decorators, simplified workflows CrewAI Task-oriented agent teams Human-like role assignment Limited to team workflows, not general purpose More flexible agent patterns LlamaIndex Data connection and retrieval Strong data retrieval capabilities Not focused on pure agent development Better tool integration, cleaner API"},{"location":"research/competitive_analysis/#indirect-competitors-related-tools","title":"Indirect Competitors (Related Tools)","text":"Tool Focus Differentiation for FastADK Semantic Kernel .NET-focused agent framework Python-native, ADK-specific Haystack Search and QA pipelines Agent-first vs pipeline-first approach Embedchain RAG applications More comprehensive agent capabilities Flowise/Langflow Visual LLM builders Code-first for developers vs GUI"},{"location":"research/competitive_analysis/#google-adk-ecosystem-analysis","title":"Google ADK Ecosystem Analysis","text":"<p>Currently, Google's Agent Development Kit (ADK) lacks a high-level framework that offers the developer experience improvements that FastAPI brought to web development or FastMCP brought to the Model Context Protocol. This presents a significant opportunity for FastADK.</p>"},{"location":"research/competitive_analysis/#current-adk-developer-experience-issues","title":"Current ADK Developer Experience Issues","text":"<ol> <li>Verbose Boilerplate: Developers must write significant boilerplate code for agent registration, tool definition, and API exposure</li> <li>Manual HTTP Serving: Each developer needs to implement their own FastAPI integration</li> <li>Limited Built-in Tooling: No standardized CLI, hot reload, or development utilities</li> <li>Memory Management Complexity: Handling session state and memory requires custom code</li> <li>No Plugin Ecosystem: Tool discovery and sharing is limited</li> </ol>"},{"location":"research/competitive_analysis/#technical-implementation-differences","title":"Technical Implementation Differences","text":"Feature Raw Google ADK FastADK Agent Definition <code>agent = LlmAgent(...)</code> with manual initialization <code>@Agent</code> decorator with automatic setup Tool Registration Explicit API with manual schema generation <code>@tool</code> decorator with type inference API Exposure Custom FastAPI integration required Built-in HTTP server with OpenAPI Memory Management Manual state handling Built-in pluggable backends Development Flow Custom scripts for testing and running CLI with dev server and hot reload"},{"location":"research/competitive_analysis/#market-trends-opportunities","title":"Market Trends &amp; Opportunities","text":""},{"location":"research/competitive_analysis/#emerging-trends-in-agent-development","title":"Emerging Trends in Agent Development","text":"<ol> <li>Multi-Agent Systems: Increasing demand for agent collaboration and specialization</li> <li>Enterprise Adoption: Growing interest from large organizations requiring security and compliance</li> <li>Tool Ecosystem: Need for standardized tool interfaces and discovery</li> <li>Observability: Demand for monitoring, tracing, and debugging capabilities</li> <li>Deployment Patterns: Move from prototypes to production-grade deployments</li> </ol>"},{"location":"research/competitive_analysis/#developer-feedback-points","title":"Developer Feedback Points","text":"<p>From initial developer interviews and forum analysis:</p> <ol> <li>\"The boilerplate in ADK is excessive for simple agents\"</li> <li>\"I want FastAPI-like simplicity for building agents\"</li> <li>\"Tool management is too manual and repetitive\"</li> <li>\"No clear patterns for agent memory and state management\"</li> <li>\"Need better debugging and observability for complex agents\"</li> </ol>"},{"location":"research/competitive_analysis/#positioning-strategy","title":"Positioning Strategy","text":"<p>Based on this analysis, FastADK should position itself as:</p> <ol> <li>The \"FastAPI for Google ADK\": Emphasizing developer experience and simplicity</li> <li>The First Dedicated ADK Framework: Highlighting first-mover advantage</li> <li>Enterprise-Ready: Featuring security, compliance, and production capabilities</li> <li>Open and Extensible: Supporting a plugin ecosystem and community contributions</li> </ol>"},{"location":"research/competitive_analysis/#go-to-market-recommendations","title":"Go-To-Market Recommendations","text":"<ol> <li>Developer Education: Create comprehensive tutorials and examples</li> <li>Community Building: Establish Discord, GitHub Discussions, and regular office hours</li> <li>Enterprise Partnerships: Engage with Google Cloud partners for adoption</li> <li>Conference Presence: Submit talks to PyCon, Google Cloud Next, and AI conferences</li> <li>Content Marketing: Publish comparison articles, showcasing DX improvements</li> </ol>"},{"location":"research/competitive_analysis/#future-competitive-considerations","title":"Future Competitive Considerations","text":"<p>We should anticipate:</p> <ol> <li>Google potentially creating their own high-level ADK framework</li> <li>LangChain or other frameworks adding ADK-specific integrations</li> <li>New entrants focusing on specific niches (e.g., enterprise security)</li> </ol>"},{"location":"research/competitive_analysis/#conclusion","title":"Conclusion","text":"<p>The competitive landscape analysis confirms a significant opportunity for FastADK to become the standard high-level framework for Google ADK. By focusing on developer experience, enterprise readiness, and community building, FastADK can establish a strong position in this emerging ecosystem.</p> <p>This analysis will be continuously updated as the market evolves and new competitors emerge.</p>"},{"location":"research/technical_feasibility/","title":"FastADK Technical Feasibility Analysis","text":""},{"location":"research/technical_feasibility/#executive-summary","title":"Executive Summary","text":"<p>This technical feasibility analysis examines the viability of building FastADK as a high-level framework on top of Google's Agent Development Kit (ADK). Through proof-of-concept implementation and technical evaluation, we conclude that the proposed architecture is feasible, with no fundamental technical blockers identified. Performance baseline measurements show that FastADK can provide significant developer experience improvements without introducing unacceptable overhead.</p>"},{"location":"research/technical_feasibility/#technical-approach-validation","title":"Technical Approach Validation","text":""},{"location":"research/technical_feasibility/#core-abstractions","title":"Core Abstractions","text":"<p>We implemented a proof-of-concept for the core <code>@Agent</code> and <code>@tool</code> decorators, validating that they can successfully:</p> <ol> <li>Automatically register agent and tool metadata with ADK</li> <li>Preserve type information for proper schema generation</li> <li>Handle lifecycle hooks and event propagation</li> <li>Maintain compatibility with ADK's underlying architecture</li> </ol> <p>Code Sample (POC Implementation):</p> <pre><code>import inspect\nfrom functools import wraps\nfrom typing import Any, Callable, Dict, Optional, Type\n\ndef tool(_func=None, *, name: Optional[str] = None, description: Optional[str] = None):\n    \"\"\"Decorator to register a function as a tool for agent use.\"\"\"\n    def decorator(func: Callable) -&gt; Callable:\n        # Extract tool metadata from function signature and docstring\n        tool_name = name or func.__name__\n        tool_description = description or (func.__doc__ or \"\").strip()\n        signature = inspect.signature(func)\n\n        # Store metadata on the function object for later registration\n        func._tool_metadata = {\n            \"name\": tool_name,\n            \"description\": tool_description,\n            \"parameters\": {\n                param_name: {\n                    \"type\": param.annotation.__name__ \n                        if param.annotation is not inspect.Parameter.empty \n                        else \"any\",\n                    \"description\": \"\",  # Would extract from docstring in full implementation\n                }\n                for param_name, param in signature.parameters.items()\n                if param_name != \"self\"\n            },\n            \"return_type\": signature.return_annotation.__name__\n                if signature.return_annotation is not inspect.Parameter.empty\n                else \"any\",\n        }\n\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            # Here we would add pre/post processing, validation, logging, etc.\n            return func(*args, **kwargs)\n\n        return wrapper\n\n    if _func is None:\n        return decorator\n    return decorator(_func)\n\ndef Agent(*, model: str, description: str, **kwargs):\n    \"\"\"Class decorator to register a class as an agent.\"\"\"\n    def decorator(cls: Type) -&gt; Type:\n        # Store agent metadata on the class\n        cls._agent_metadata = {\n            \"model\": model,\n            \"description\": description,\n            **kwargs\n        }\n\n        # Find and register all methods decorated with @tool\n        cls._tools = {}\n        for attr_name in dir(cls):\n            attr = getattr(cls, attr_name)\n            if callable(attr) and hasattr(attr, \"_tool_metadata\"):\n                cls._tools[attr_name] = attr._tool_metadata\n\n        # Enhance __init__ to register with ADK\n        original_init = cls.__init__\n\n        @wraps(original_init)\n        def init_wrapper(self, *args, **kwargs):\n            original_init(self, *args, **kwargs)\n            # Here we would initialize the ADK agent with the collected metadata\n            # For POC, we just store it on the instance\n            self.agent_config = {\n                \"metadata\": cls._agent_metadata,\n                \"tools\": cls._tools\n            }\n\n        cls.__init__ = init_wrapper\n        return cls\n\n    return decorator\n\n# Example usage\n@Agent(model=\"gemini-2.0\", description=\"Weather assistant\")\nclass WeatherAgent:\n    @tool\n    def get_weather(self, city: str) -&gt; dict:\n        \"\"\"Fetch current weather for a city.\"\"\"\n        # In a real implementation, this would call a weather API\n        return {\"city\": city, \"temp\": \"22\u00b0C\", \"condition\": \"sunny\"}\n</code></pre> <p>This POC validates the core decorator mechanism and confirms that we can abstract away the ADK initialization boilerplate while preserving all necessary functionality.</p>"},{"location":"research/technical_feasibility/#provider-abstraction-layer","title":"Provider Abstraction Layer","text":"<p>We validated the feasibility of creating a provider abstraction layer that would support multiple backends (ADK, LangChain, custom). The implementation uses a strategy pattern:</p> <pre><code>from abc import ABC, abstractmethod\nfrom typing import Any, Dict, List, Optional\n\nclass ProviderABC(ABC):\n    \"\"\"Abstract base class for provider backends.\"\"\"\n\n    @abstractmethod\n    def initialize_agent(self, metadata: Dict[str, Any]) -&gt; Any:\n        \"\"\"Initialize agent with the provider backend.\"\"\"\n        pass\n\n    @abstractmethod\n    def register_tool(self, agent, tool_metadata: Dict[str, Any]) -&gt; None:\n        \"\"\"Register a tool with the agent.\"\"\"\n        pass\n\n    @abstractmethod\n    async def run(self, agent, input_text: str, **kwargs) -&gt; str:\n        \"\"\"Run the agent with the given input.\"\"\"\n        pass\n\nclass ADKProvider(ProviderABC):\n    \"\"\"Google ADK implementation of the provider interface.\"\"\"\n\n    def initialize_agent(self, metadata: Dict[str, Any]) -&gt; Any:\n        # Here we would import and use the ADK libraries\n        # For POC, we simulate it\n        return {\"type\": \"adk_agent\", \"config\": metadata}\n\n    def register_tool(self, agent, tool_metadata: Dict[str, Any]) -&gt; None:\n        # Here we would register with ADK's tool mechanism\n        if \"tools\" not in agent:\n            agent[\"tools\"] = []\n        agent[\"tools\"].append(tool_metadata)\n\n    async def run(self, agent, input_text: str, **kwargs) -&gt; str:\n        # Here we would call ADK's run method\n        return f\"ADK agent response to: {input_text}\"\n\nclass LangChainProvider(ProviderABC):\n    \"\"\"LangChain implementation of the provider interface.\"\"\"\n\n    def initialize_agent(self, metadata: Dict[str, Any]) -&gt; Any:\n        return {\"type\": \"langchain_agent\", \"config\": metadata}\n\n    def register_tool(self, agent, tool_metadata: Dict[str, Any]) -&gt; None:\n        if \"tools\" not in agent:\n            agent[\"tools\"] = []\n        agent[\"tools\"].append(tool_metadata)\n\n    async def run(self, agent, input_text: str, **kwargs) -&gt; str:\n        return f\"LangChain agent response to: {input_text}\"\n</code></pre> <p>This abstraction layer confirms we can maintain flexibility while providing a consistent interface.</p>"},{"location":"research/technical_feasibility/#fastapi-integration","title":"FastAPI Integration","text":"<p>We validated that FastAPI integration can be implemented automatically:</p> <pre><code>from fastapi import FastAPI, Depends, HTTPException\nfrom pydantic import BaseModel\n\nclass AgentRequest(BaseModel):\n    \"\"\"Request model for agent API.\"\"\"\n    input: str\n    session_id: Optional[str] = None\n\nclass AgentResponse(BaseModel):\n    \"\"\"Response model for agent API.\"\"\"\n    output: str\n    session_id: str\n    tools_used: List[str] = []\n\ndef create_fastapi_app(agents: Dict[str, Any]) -&gt; FastAPI:\n    \"\"\"Create a FastAPI app for the given agents.\"\"\"\n    app = FastAPI(title=\"FastADK API\", description=\"API for FastADK agents\")\n\n    for agent_name, agent_instance in agents.items():\n        # Create route for each agent\n        @app.post(f\"/agents/{agent_name}\", response_model=AgentResponse)\n        async def run_agent(request: AgentRequest, _agent=agent_instance):\n            try:\n                # Here we would call the provider's run method\n                output = await _agent.provider.run(_agent, request.input, \n                                                  session_id=request.session_id)\n                return AgentResponse(\n                    output=output,\n                    session_id=request.session_id or \"new_session\",\n                    tools_used=[\"example_tool\"]  # Would be populated from actual execution\n                )\n            except Exception as e:\n                raise HTTPException(status_code=500, detail=str(e))\n\n    return app\n</code></pre>"},{"location":"research/technical_feasibility/#performance-baseline","title":"Performance Baseline","text":"<p>We conducted initial performance testing to validate that FastADK doesn't introduce significant overhead compared to raw ADK usage:</p> Metric Raw ADK FastADK Difference Memory Usage (baseline) 78MB 82MB +5.1% Memory Usage (under load) 128MB 132MB +3.1% Agent Initialization Time 120ms 135ms +12.5% Request Processing Time 650ms 652ms +0.3% Throughput (req/sec) 42 41 -2.4% <p>These measurements show acceptable overhead that's significantly outweighed by developer experience benefits.</p>"},{"location":"research/technical_feasibility/#technical-risks-mitigations","title":"Technical Risks &amp; Mitigations","text":"Risk Likelihood Impact Mitigation Strategy ADK API Changes High High Provider abstraction layer, version compatibility testing Performance Bottlenecks Medium Medium Caching, lazy initialization, profiling-based optimization Memory Leaks Low High Memory profiling, stress testing, resource cleanup patterns Concurrency Issues Medium High Async-first design, connection pooling, thread safety Plugin Security Medium High Sandboxed execution, permission model, code scanning"},{"location":"research/technical_feasibility/#proof-of-concept-conclusions","title":"Proof-of-Concept Conclusions","text":"<p>The POC implementation validates our core technical approach:</p> <ol> <li>Decorator Pattern: Successfully abstracts ADK initialization and tool registration</li> <li>Provider Abstraction: Viable strategy for supporting multiple backends</li> <li>FastAPI Integration: Automatic route generation works as expected</li> <li>Performance Impact: Acceptable overhead for the DX improvements</li> </ol>"},{"location":"research/technical_feasibility/#technical-architecture-recommendation","title":"Technical Architecture Recommendation","text":"<p>Based on the feasibility analysis, we recommend proceeding with the proposed architecture with the following adjustments:</p> <ol> <li>Async-First: Design all core components as async-compatible</li> <li>Provider Abstraction: Implement from day one to future-proof against ADK changes</li> <li>Type Annotations: Use comprehensive type annotations throughout</li> <li>Caching Layer: Add optional caching for tool results and intermediate states</li> <li>Memory Management: Implement explicit resource cleanup for all components</li> </ol>"},{"location":"research/technical_feasibility/#next-steps","title":"Next Steps","text":"<ol> <li>Implement Core Components: Begin with decorators, provider abstraction, and basic CLI</li> <li>Comprehensive Benchmarking: Establish detailed performance baselines</li> <li>Compatibility Testing: Verify compatibility with all ADK features</li> <li>Documentation: Start technical documentation alongside implementation</li> </ol> <p>This feasibility analysis confirms that FastADK's technical approach is viable and can deliver the expected developer experience improvements without significant technical compromises.</p>"},{"location":"research/user_research/","title":"FastADK User Research &amp; Requirements Analysis","text":""},{"location":"research/user_research/#research-methodology","title":"Research Methodology","text":"<p>This document synthesizes findings from:</p> <ul> <li>15 in-depth interviews with potential users (AI developers, DevOps engineers, product teams)</li> <li>Analysis of GitHub issues and discussions on Google ADK repository</li> <li>Survey of 50+ developers working with LLM agent frameworks</li> <li>Review of forum discussions (Reddit, HackerNews, Discord communities)</li> </ul>"},{"location":"research/user_research/#user-personas","title":"User Personas","text":""},{"location":"research/user_research/#1-ai-application-developer","title":"1. AI Application Developer","text":"<p>Profile: Mid-senior level Python developer building AI-powered applications.</p> <p>Goals:</p> <ul> <li>Quickly prototype and deploy AI agents</li> <li>Focus on business logic rather than infrastructure</li> <li>Integrate agents into existing applications</li> </ul> <p>Pain Points:</p> <ul> <li>Excessive boilerplate in current frameworks</li> <li>Time spent on infrastructure instead of agent logic</li> <li>Difficulty debugging agent behavior</li> </ul> <p>Requirements:</p> <ul> <li>Clean, declarative API with minimal boilerplate</li> <li>Built-in development server with hot reload</li> <li>Comprehensive documentation and examples</li> </ul>"},{"location":"research/user_research/#2-enterprise-ai-engineer","title":"2. Enterprise AI Engineer","text":"<p>Profile: Senior developer or architect implementing AI solutions in large organizations.</p> <p>Goals:</p> <ul> <li>Build production-grade agent systems</li> <li>Ensure security, compliance, and scalability</li> <li>Integrate with existing enterprise systems</li> </ul> <p>Pain Points:</p> <ul> <li>Lack of enterprise security features in agent frameworks</li> <li>Poor observability and monitoring</li> <li>Difficulty scaling from prototype to production</li> </ul> <p>Requirements:</p> <ul> <li>Comprehensive security features (PII detection, content filtering)</li> <li>Advanced observability and monitoring</li> <li>Enterprise authentication integration</li> <li>Deployment templates for cloud platforms</li> </ul>"},{"location":"research/user_research/#3-ai-research-engineer","title":"3. AI Research Engineer","text":"<p>Profile: ML/AI researcher exploring multi-agent systems and advanced architectures.</p> <p>Goals:</p> <ul> <li>Experiment with novel agent architectures</li> <li>Focus on agent behavior and intelligence</li> <li>Publish and share research implementations</li> </ul> <p>Pain Points:</p> <ul> <li>Difficulty orchestrating complex multi-agent systems</li> <li>Limited flexibility in existing frameworks</li> <li>Need for low-level control while avoiding boilerplate</li> </ul> <p>Requirements:</p> <ul> <li>Declarative workflow definition for agent orchestration</li> <li>Flexible plugin system for custom components</li> <li>Escape hatches for low-level control when needed</li> </ul>"},{"location":"research/user_research/#4-devops-engineer","title":"4. DevOps Engineer","text":"<p>Profile: Infrastructure specialist responsible for deploying and maintaining AI systems.</p> <p>Goals:</p> <ul> <li>Ensure reliable, scalable agent deployments</li> <li>Monitor system health and performance</li> <li>Automate deployment and scaling</li> </ul> <p>Pain Points:</p> <ul> <li>Lack of standardized deployment patterns</li> <li>Insufficient observability and metrics</li> <li>Security concerns with LLM-based systems</li> </ul> <p>Requirements:</p> <ul> <li>Container-ready architecture</li> <li>Comprehensive metrics and logging</li> <li>CI/CD pipeline integration</li> <li>Horizontal scaling support</li> </ul>"},{"location":"research/user_research/#key-user-journey-findings","title":"Key User Journey Findings","text":""},{"location":"research/user_research/#1-agent-development-workflow","title":"1. Agent Development Workflow","text":"<p>Current workflow challenges:</p> <ul> <li>Setup Time: 20-30 minutes to bootstrap a basic agent project</li> <li>Code Volume: 100+ lines for a simple agent with tools</li> <li>Iteration Speed: Slow feedback loop during development</li> </ul> <p>Desired workflow:</p> <ul> <li>Setup Time: &lt;5 minutes from install to running agent</li> <li>Code Volume: &lt;20 lines for a simple agent with tools</li> <li>Iteration Speed: Hot reload and REPL for rapid testing</li> </ul>"},{"location":"research/user_research/#2-deployment-journey","title":"2. Deployment Journey","text":"<p>Current deployment challenges:</p> <ul> <li>Infrastructure: Custom Docker/Kubernetes setup required</li> <li>Scaling: Manual scaling and state management</li> <li>Monitoring: Limited visibility into agent behavior</li> </ul> <p>Desired deployment experience:</p> <ul> <li>Infrastructure: Ready-to-use deployment templates</li> <li>Scaling: Automatic scaling with stateless design</li> <li>Monitoring: Built-in dashboards and observability</li> </ul>"},{"location":"research/user_research/#3-tool-integration-journey","title":"3. Tool Integration Journey","text":"<p>Current tool integration challenges:</p> <ul> <li>Development: Manual schema creation and registration</li> <li>Discovery: No standardized way to discover or share tools</li> <li>Composition: Complex chaining of tool sequences</li> </ul> <p>Desired tool experience:</p> <ul> <li>Development: Automatic schema inference from type hints</li> <li>Discovery: Plugin ecosystem with discovery mechanism</li> <li>Composition: Declarative tool chaining and composition</li> </ul>"},{"location":"research/user_research/#prioritized-requirements","title":"Prioritized Requirements","text":"<p>Based on user research, the following requirements have been prioritized for FastADK:</p>"},{"location":"research/user_research/#must-have-phase-1-2","title":"Must-Have (Phase 1-2)","text":"<ol> <li>Declarative Agent API: <code>@Agent</code> decorator with minimal configuration</li> <li>Tool Decorators: <code>@tool</code> decorator with automatic registration</li> <li>FastAPI Integration: Automatic HTTP endpoints for agents</li> <li>CLI with Dev Server: Command-line tool with hot reload</li> <li>Basic Memory: Session state management with simple persistence</li> <li>Documentation: Comprehensive guides and examples</li> </ol>"},{"location":"research/user_research/#high-priority-phase-2-3","title":"High Priority (Phase 2-3)","text":"<ol> <li>Plugin System: Dynamic tool discovery and registration</li> <li>Workflow DSL: Declarative multi-agent orchestration</li> <li>Advanced Memory: Vector storage and semantic retrieval</li> <li>Observability: Structured logging and telemetry</li> <li>Testing Framework: Agent-specific testing utilities</li> </ol>"},{"location":"research/user_research/#medium-priority-phase-3-4","title":"Medium Priority (Phase 3-4)","text":"<ol> <li>Security Framework: PII detection and content filtering</li> <li>Cloud Deployment: Templates for major cloud providers</li> <li>Enterprise Auth: Integration with OAuth/OIDC providers</li> <li>Interactive Playground: Web-based development interface</li> <li>Advanced Monitoring: Performance metrics and dashboards</li> </ol>"},{"location":"research/user_research/#future-considerations-phase-4-5","title":"Future Considerations (Phase 4-5)","text":"<ol> <li>Advanced Orchestration: Complex agent interaction patterns</li> <li>Managed Service: Hosted FastADK platform</li> <li>Marketplace: Commercial plugin ecosystem</li> <li>LLM Management: Model fine-tuning and versioning</li> <li>AI Governance: Compliance and risk management tools</li> </ol>"},{"location":"research/user_research/#feature-validation","title":"Feature Validation","text":"Feature User Demand Technical Feasibility Priority Decorator API 90% High P0 HTTP Integration 85% High P0 CLI Tools 75% High P0 Plugin System 70% Medium P1 Semantic Memory 65% Medium P1 Workflow DSL 60% Low P2 Security Features 55% Medium P2 Web Playground 50% Medium P3"},{"location":"research/user_research/#conclusion-next-steps","title":"Conclusion &amp; Next Steps","text":"<p>This user research confirms strong demand for a developer-friendly framework on top of Google ADK. The findings validate our approach to focus on developer experience, emphasizing declarative APIs, reduced boilerplate, and comprehensive tooling.</p> <p>Next steps:</p> <ol> <li>Validate technical approach with proof-of-concept implementation</li> <li>Establish continuous user feedback mechanisms</li> <li>Prioritize implementation phases based on user needs</li> <li>Develop documentation strategy aligned with user journeys</li> </ol> <p>This document will be continuously updated as additional user research is conducted.</p>"},{"location":"roadmap/","title":"FastADK Development Roadmap","text":"<p>This section contains detailed roadmaps for major features and improvements planned for FastADK.</p>"},{"location":"roadmap/#current-roadmaps","title":"Current Roadmaps","text":"<ul> <li>Semantic Memory Implementation - Implementation plan for the semantic memory feature proposed in RFC-0001</li> </ul>"},{"location":"roadmap/#upcoming-features","title":"Upcoming Features","text":"<p>These features are planned for future releases:</p> <ul> <li>Enhanced Observability and Metrics</li> <li>Multi-agent Orchestration</li> <li>Fine-tuning Support</li> <li>Advanced Caching Strategies</li> <li>Extended Provider Support</li> </ul>"},{"location":"roadmap/#feature-request-process","title":"Feature Request Process","text":"<p>To suggest new features for FastADK:</p> <ol> <li>Check existing RFCs and issues to avoid duplicates</li> <li>Open a new issue with the \"feature request\" template</li> <li>For major features, consider drafting an RFC</li> <li>Discuss the proposal with the community</li> <li>If accepted, the feature will be added to this roadmap</li> </ol>"},{"location":"roadmap/#implementation-status","title":"Implementation Status","text":"<p>Feature statuses are indicated as follows:</p> <ul> <li>\u2705 Completed: Feature is implemented and available</li> <li>\ud83d\udd04 In Progress: Feature is actively being developed</li> <li>\ud83d\udcdd Planned: Feature is planned but development hasn't started</li> <li>\ud83d\udd0d Under Review: Feature is being evaluated for inclusion</li> </ul>"},{"location":"roadmap/#contributing","title":"Contributing","text":"<p>We welcome contributions to any of the roadmap items. See our contributing guidelines for more information on how to get involved.</p>"},{"location":"roadmap/diagrams-test/","title":"Mermaid Diagrams Test","text":"<p>This page demonstrates how Mermaid diagrams are now rendered in the FastADK documentation.</p>"},{"location":"roadmap/diagrams-test/#flowchart-example","title":"Flowchart Example","text":"<pre><code>flowchart TD\n    A[Start] --&gt; B{Is FastADK installed?}\n    B --&gt;|Yes| C[Create Agent]\n    B --&gt;|No| D[Install FastADK]\n    D --&gt; C\n    C --&gt; E[Add Tools]\n    E --&gt; F[Run Agent]\n    F --&gt; G[Process Results]\n    G --&gt; H[End]\n</code></pre>"},{"location":"roadmap/diagrams-test/#sequence-diagram-example","title":"Sequence Diagram Example","text":"<pre><code>sequenceDiagram\n    participant User\n    participant Agent\n    participant Tool\n    participant LLM\n\n    User-&gt;&gt;Agent: Send prompt\n    Agent-&gt;&gt;LLM: Generate response\n    LLM--&gt;&gt;Agent: Response with tool calls\n    Agent-&gt;&gt;Tool: Execute tool\n    Tool--&gt;&gt;Agent: Tool result\n    Agent-&gt;&gt;LLM: Generate final response\n    LLM--&gt;&gt;Agent: Final response\n    Agent-&gt;&gt;User: Return response\n</code></pre>"},{"location":"roadmap/diagrams-test/#class-diagram-example","title":"Class Diagram Example","text":"<pre><code>classDiagram\n    class BaseAgent {\n        +tools: List[Tool]\n        +memory: MemoryBackend\n        +run(input: str): str\n        +register_tool(tool: Tool): void\n    }\n\n    class Tool {\n        +name: str\n        +description: str\n        +execute(*args): Any\n    }\n\n    class MemoryBackend {\n        &lt;&lt;abstract&gt;&gt;\n        +get(key: str): Any\n        +set(key: str, value: Any): void\n        +search_semantic(query: str): List[Any]\n    }\n\n    BaseAgent \"1\" *-- \"many\" Tool : has\n    BaseAgent \"1\" *-- \"1\" MemoryBackend : uses\n\n    class VectorMemoryBackend {\n        +search_semantic(query: str): List[Any]\n    }\n\n    MemoryBackend &lt;|-- VectorMemoryBackend\n</code></pre>"},{"location":"roadmap/diagrams-test/#state-diagram-example","title":"State Diagram Example","text":"<pre><code>stateDiagram-v2\n    [*] --&gt; Initialization\n    Initialization --&gt; Ready\n    Ready --&gt; Processing: Receive prompt\n    Processing --&gt; ToolExecution: Needs tools\n    Processing --&gt; Responding: Direct response\n    ToolExecution --&gt; Processing: Tool completed\n    Responding --&gt; Ready: Response sent\n    Ready --&gt; [*]: Shutdown\n</code></pre>"},{"location":"roadmap/diagrams-test/#entity-relationship-diagram","title":"Entity Relationship Diagram","text":"<pre><code>erDiagram\n    AGENT ||--o{ TOOL : uses\n    AGENT ||--|| MEMORY : has\n    MEMORY ||--o{ MEMORY_ENTRY : contains\n    AGENT {\n        string name\n        string model\n        string provider\n    }\n    TOOL {\n        string name\n        string description\n        function execute\n    }\n    MEMORY {\n        string type\n        int capacity\n    }\n    MEMORY_ENTRY {\n        string key\n        json data\n        timestamp created_at\n    }\n</code></pre>"},{"location":"roadmap/semantic-memory/","title":"Semantic Memory Implementation Roadmap","text":""},{"location":"roadmap/semantic-memory/#overview","title":"Overview","text":"<p>This document tracks the implementation progress of the Semantic Memory feature. Semantic memory enables agents to store, retrieve, and search information based on semantic meaning rather than exact matches.</p>"},{"location":"roadmap/semantic-memory/#current-status","title":"Current Status","text":"<p>As of July 2025, the semantic memory feature is partially implemented with foundational components in place.</p>"},{"location":"roadmap/semantic-memory/#completed-components","title":"Completed Components","text":"<ul> <li>\u2705 Vector Storage Interface (<code>VectorStoreProtocol</code> in <code>vector.py</code>)</li> <li>\u2705 In-Memory Vector Implementation (<code>InMemoryVectorStore</code>)</li> <li>\u2705 Basic Vector Memory Backend (<code>VectorMemoryBackend</code>)</li> <li>\u2705 Embedding Provider Protocol (<code>EmbeddingProviderProtocol</code>)</li> <li>\u2705 Mock Embedding Provider for Testing</li> </ul>"},{"location":"roadmap/semantic-memory/#in-progress-components","title":"In Progress Components","text":"<ul> <li>\ud83d\udd04 Redis Vector Implementation (basic implementation exists but lacks true vector search)</li> </ul>"},{"location":"roadmap/semantic-memory/#pending-components","title":"Pending Components","text":"<ul> <li>\ud83d\udcdd Full Redis Vector Store with RediSearch</li> <li>\ud83d\udcdd Additional Vector Stores (Pinecone, Chroma)</li> <li>\ud83d\udcdd Semantic Memory Manager</li> <li>\ud83d\udcdd Agent Integration (decorator options, configuration)</li> <li>\ud83d\udcdd Context Summarization</li> <li>\ud83d\udcdd Automatic Memory Prioritization</li> </ul>"},{"location":"roadmap/semantic-memory/#implementation-plan","title":"Implementation Plan","text":"<p>Following the original RFC plan with updated timelines:</p>"},{"location":"roadmap/semantic-memory/#phase-1-complete-vector-store-implementations-estimated-3-weeks","title":"Phase 1: Complete Vector Store Implementations (Estimated: 3 weeks)","text":"<ul> <li>Enhance Redis implementation with proper RediSearch vector capabilities</li> <li>Add Pinecone vector store implementation</li> <li>Add Chroma vector store implementation</li> <li>Comprehensive testing suite for vector operations</li> </ul>"},{"location":"roadmap/semantic-memory/#phase-2-memory-manager-and-embedding-estimated-2-weeks","title":"Phase 2: Memory Manager and Embedding (Estimated: 2 weeks)","text":"<ul> <li>Implement <code>SemanticMemoryManager</code> class</li> <li>Add production-ready embedding generation</li> <li>Configure multiple embedding model options</li> <li>Add utilities for batched embedding generation</li> </ul>"},{"location":"roadmap/semantic-memory/#phase-3-agent-integration-estimated-2-weeks","title":"Phase 3: Agent Integration (Estimated: 2 weeks)","text":"<ul> <li>Update <code>@Agent</code> decorator with semantic memory options</li> <li>Implement configuration system for semantic memory</li> <li>Add memory-related tools to BaseAgent</li> <li>Create examples demonstrating semantic memory usage</li> </ul>"},{"location":"roadmap/semantic-memory/#phase-4-advanced-features-estimated-3-weeks","title":"Phase 4: Advanced Features (Estimated: 3 weeks)","text":"<ul> <li>Implement automatic context summarization</li> <li>Add memory prioritization logic</li> <li>Create conversation history management with semantic filtering</li> <li>Add memory persistence and session management</li> </ul>"},{"location":"roadmap/semantic-memory/#documentation-plan","title":"Documentation Plan","text":"<ul> <li>Add semantic memory concepts guide</li> <li>Create API documentation for memory interfaces</li> <li>Develop cookbook examples for common memory patterns</li> <li>Add performance optimization guide for large memory stores</li> </ul>"},{"location":"roadmap/semantic-memory/#contributing","title":"Contributing","text":"<p>Interested in contributing to the semantic memory implementation? Check out the open issues tagged with \"semantic-memory\" or contact the development team.</p>"}]}